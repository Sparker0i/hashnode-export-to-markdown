{"posts":[{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"_id":"6821a6985006bd988f7f9344","createdAt":"2025-05-12T07:43:20.582Z","updatedAt":"2025-05-12T08:56:26.768Z","views":23,"isActive":true,"hasLatex":false,"popularity":7511.6578,"discussionScore":0,"enableToc":true,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":true,"disableComments":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"slugOverridden":true,"tweetOptions":{"enabled":false},"title":"How to Identify and Refactor Code Smells for Better Code Quality","subtitle":"Practical Techniques for Spotting Bad Code Patterns and Cleaning Up Your Codebase","cuid":"cmaks0b2c004109lhdcbtayfe","dateAdded":"2025-05-12T07:43:20.580Z","isCoverAttributionHidden":false,"coverImageAttribution":"","coverImagePhotographer":"","stickCoverToBottom":true,"slug":"identify-and-refactor-code-smells-for-better-code-quality","toc":[[{"id":"2d2d2e74-ed24-4122-9fcc-abc16955b6c5","level":2,"previousLevel":null,"parentId":null,"slug":"why-code-smells-matter","title":"Why Code Smells matter?"}],[{"id":"aa72d936-702e-4050-b837-969ea948a829","level":2,"previousLevel":2,"parentId":null,"slug":"basic-code-smells-amp-refactorings","title":"Basic Code Smells &amp; Refactorings"}],[{"id":"49a7f9ef-0127-4ba2-b6ef-f9df75a50107","level":3,"previousLevel":2,"parentId":"aa72d936-702e-4050-b837-969ea948a829","slug":"long-method","title":"Long Method"}],[{"id":"1fd15325-a60a-46d2-b9b9-6b6c2147a554","level":3,"previousLevel":3,"parentId":"aa72d936-702e-4050-b837-969ea948a829","slug":"duplicated-code","title":"Duplicated Code"}],[{"id":"8fa36f41-96b2-4877-b46d-2083472f9825","level":3,"previousLevel":3,"parentId":"aa72d936-702e-4050-b837-969ea948a829","slug":"long-parameter-list","title":"Long Parameter List"}],[{"id":"6cc7f559-eb36-47e6-94f0-323362155c82","level":3,"previousLevel":3,"parentId":"aa72d936-702e-4050-b837-969ea948a829","slug":"divergent-change","title":"Divergent Change"}],[{"id":"26f07e08-4d90-4885-ab93-45acc37ef98c","level":3,"previousLevel":3,"parentId":"aa72d936-702e-4050-b837-969ea948a829","slug":"feature-envy","title":"Feature Envy"}],[{"id":"5650d5ae-05c9-4d04-af70-42fcf8aa826c","level":3,"previousLevel":3,"parentId":"aa72d936-702e-4050-b837-969ea948a829","slug":"shotgun-surgery","title":"Shotgun Surgery"}],[{"id":"c72037db-d375-4743-a7fc-420a7ef6a437","level":3,"previousLevel":3,"parentId":"aa72d936-702e-4050-b837-969ea948a829","slug":"primitive-obsession","title":"Primitive Obsession"}],[{"id":"b35dbb3c-07b9-490f-ac7b-92b1497bf9ee","level":3,"previousLevel":3,"parentId":"aa72d936-702e-4050-b837-969ea948a829","slug":"replace-temp-with-query","title":"Replace Temp with Query"}],[{"id":"d5bc3af5-5b6f-48db-a965-6c8132d9c7e4","level":3,"previousLevel":3,"parentId":"aa72d936-702e-4050-b837-969ea948a829","slug":"replace-conditional-with-polymorphism","title":"Replace Conditional with Polymorphism"}],[{"id":"601d21a0-68d1-4a3d-82cd-150c4096b096","level":3,"previousLevel":3,"parentId":"aa72d936-702e-4050-b837-969ea948a829","slug":"data-clumps","title":"Data Clumps"}],[{"id":"b830e526-ba50-4517-bec7-f3ef0a9c5979","level":2,"previousLevel":3,"parentId":null,"slug":"general-refactoring-best-practices","title":"General Refactoring Best Practices"}],[{"id":"0f3e11a4-b9c4-4405-82e2-a89e99f42120","level":2,"previousLevel":2,"parentId":null,"slug":"conclusion","title":"Conclusion"}]],"content":"<p>Code is more than just instructions for a machine - it’s a form of communication with your future self and teammates. Yet all too often, codebases accumulate hidden “stinkers” that slow down development, introduce bugs, and frustrate newcomers. These are <strong>code smells</strong>: surface indicators that something deeper in the design or implementation needs attention. In this post, we’ll explore a comprehensive catalog of common smells and walk through concrete refactoring - complete with before/after snippets (in Go, but the logic can be applied to any language)- to help you keep your codebase clean, maintainable, and a joy to work with.</p>\n<h2 id=\"heading-why-code-smells-matter\">Why Code Smells matter?</h2>\n<ul>\n<li><p><strong>Readability &amp; Onboarding</strong>: Long, tangled methods or duplicated logic force readers to mentally untangle intent from implementation. New team members spend hours deciphering what should’ve been clear.</p>\n</li>\n<li><p><strong>Bug Rate</strong>: Smelly code often has hidden dependencies or unexpected side effects. One small change can ripple out, breaking functionality in multiple places.</p>\n</li>\n<li><p><strong>Confidence to Change</strong>: When refactoring feels risky, teams delay improvements, leading to technical debt escalation. Over time, even minor enhancements require heroic effort.</p>\n</li>\n</ul>\n<blockquote>\n<p><strong>Personal Anecdote</strong>: During the early stages of my career I inherited a 5k line class handling everything from fetching data then transforming it and loading it somewhere. This class was growing exponentially with every sprint/iteration, and soon risked crossing 10k lines. Every change required a full regression suite and lots of manual testing. After identifying just three key smells - Long Method, Feature Envy, and Primitive Obsession - we applied targeted refactorings that reduced that class to under 1000 lines and we were easily able to extend our codebase.</p>\n</blockquote>\n<h2 id=\"heading-basic-code-smells-amp-refactorings\"><strong>Basic Code Smells &amp; Refactorings</strong></h2>\n<h3 id=\"heading-long-method\">Long Method</h3>\n<p><strong>What it is:</strong> A method or function that spans many lines - often 200+ - and tries to do too much: input validation, business logic, data transformation, persistence, side-effects, and user interaction all in one place.</p>\n<p><strong>Why it matters</strong></p>\n<ul>\n<li><p><strong>Cognitive Load</strong>: Readers must keep many moving parts and intents in mind at once.</p>\n</li>\n<li><p><strong>Hard to Test</strong>: You can’t isolate pieces easily for unit tests.</p>\n</li>\n<li><p><strong>Change Risk</strong>: A tweak for one concern can inadvertently break another.</p>\n</li>\n</ul>\n<p><strong>How to spot it</strong></p>\n<ul>\n<li><p>Look for methods longer than a screen.</p>\n</li>\n<li><p>Multiple comments like // validate, // compute, // persist in one block.</p>\n</li>\n<li><p>Deep nesting of conditionals and loops.</p>\n</li>\n</ul>\n<p><strong>Refactoring</strong>: Use Extract Method</p>\n<ol>\n<li><p>Identify a coherent chunk: it does one logical sub-task.</p>\n</li>\n<li><p>Give it a descriptive name.</p>\n</li>\n<li><p>Replace the chunk with a call to the new method.</p>\n</li>\n</ol>\n<p>Example: Before</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">Checkout</span><span class=\"hljs-params\">(cart Cart)</span></span> {\n    <span class=\"hljs-comment\">// 1. Validate</span>\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(cart.Items) == <span class=\"hljs-number\">0</span> { log.Error(<span class=\"hljs-string\">\"empty cart\"</span>); <span class=\"hljs-keyword\">return</span> }\n    <span class=\"hljs-comment\">// 2. Sum prices</span>\n    sum := <span class=\"hljs-number\">0.0</span>\n    <span class=\"hljs-keyword\">for</span> _, i := <span class=\"hljs-keyword\">range</span> cart.Items { sum += i.Price * <span class=\"hljs-keyword\">float64</span>(i.Qty) }\n    <span class=\"hljs-comment\">// 3. Apply discount</span>\n    <span class=\"hljs-keyword\">if</span> cart.Customer.IsVIP { sum *= <span class=\"hljs-number\">0.9</span> }\n    <span class=\"hljs-comment\">// 4. Log &amp; persist</span>\n    log.Printf(<span class=\"hljs-string\">\"Total: %.2f\"</span>, sum)\n    db.Save(cart, sum)\n    <span class=\"hljs-comment\">// 5. Send email</span>\n    emailService.Send(cart.Customer.Email, sum)\n}\n</code></pre>\n<p>Example: After</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">Checkout</span><span class=\"hljs-params\">(cart Cart)</span></span> {\n    <span class=\"hljs-keyword\">if</span> err := validate(cart); err != <span class=\"hljs-literal\">nil</span> {\n        log.Error(err); <span class=\"hljs-keyword\">return</span>\n    }\n    total := calculateTotal(cart.Items)\n    total = applyDiscount(total, cart.Customer)\n    finalizeOrder(cart, total)\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">validate</span><span class=\"hljs-params\">(cart Cart)</span> <span class=\"hljs-title\">error</span></span> {\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(cart.Items) == <span class=\"hljs-number\">0</span> { <span class=\"hljs-keyword\">return</span> fmt.Errorf(<span class=\"hljs-string\">\"cart empty\"</span>) }\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">nil</span>\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">calculateTotal</span><span class=\"hljs-params\">(items []Item)</span> <span class=\"hljs-title\">float64</span></span> { … }\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">applyDiscount</span><span class=\"hljs-params\">(total <span class=\"hljs-keyword\">float64</span>, c Customer)</span> <span class=\"hljs-title\">float64</span></span> { … }\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">finalizeOrder</span><span class=\"hljs-params\">(cart Cart, total <span class=\"hljs-keyword\">float64</span>)</span></span> {\n    log.Printf(<span class=\"hljs-string\">\"Total: %.2f\"</span>, total)\n    db.Save(cart, total)\n    emailService.Send(cart.Customer.Email, total)\n}\n</code></pre>\n<h3 id=\"heading-duplicated-code\">Duplicated Code</h3>\n<p><strong>What it is</strong>: Slivers of nearly identical logic appear in two or more locations - copy-paste programming.</p>\n<p><strong>Why it matters</strong></p>\n<ul>\n<li><p><strong>Maintenance Hell</strong>: Fixing a bug requires updating every copy.</p>\n</li>\n<li><p><strong>Divergence</strong>: Over time, copies drift apart, hiding inconsistent behavior.</p>\n</li>\n</ul>\n<p><strong>How to spot it</strong></p>\n<ul>\n<li><p>Search for the same loop, conditional, or calculation in multiple files.</p>\n</li>\n<li><p>In code reviews, ask “Have we done this before?”</p>\n</li>\n</ul>\n<p><strong>Refactoring Options</strong></p>\n<ul>\n<li><p>Pull shared logic into a single helper function.</p>\n</li>\n<li><p>Replace all occurrences with calls to that helper</p>\n</li>\n</ul>\n<p>Example: Before</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">CalculateTaxA</span><span class=\"hljs-params\">(order Order)</span> <span class=\"hljs-title\">float64</span></span> {\n    tax := <span class=\"hljs-number\">0.0</span>\n    <span class=\"hljs-keyword\">for</span> _, item := <span class=\"hljs-keyword\">range</span> order.Items {\n        tax += item.Price * <span class=\"hljs-keyword\">float64</span>(item.Quantity) * <span class=\"hljs-number\">0.08</span>\n    }\n    <span class=\"hljs-keyword\">return</span> tax\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">CalculateTaxB</span><span class=\"hljs-params\">(invoice Invoice)</span> <span class=\"hljs-title\">float64</span></span> {\n    tax := <span class=\"hljs-number\">0.0</span>\n    <span class=\"hljs-keyword\">for</span> _, line := <span class=\"hljs-keyword\">range</span> invoice.Lines {\n        tax += line.UnitPrice * <span class=\"hljs-keyword\">float64</span>(line.Count) * <span class=\"hljs-number\">0.08</span>\n    }\n    <span class=\"hljs-keyword\">return</span> tax\n}\n</code></pre>\n<p>Example: After</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">calculateTax</span><span class=\"hljs-params\">(subtotal <span class=\"hljs-keyword\">float64</span>)</span> <span class=\"hljs-title\">float64</span></span> {\n    <span class=\"hljs-keyword\">return</span> subtotal * <span class=\"hljs-number\">0.08</span>\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">CalculateTaxA</span><span class=\"hljs-params\">(order Order)</span> <span class=\"hljs-title\">float64</span></span> {\n    subtotal := sumPrices(order.Items)\n    <span class=\"hljs-keyword\">return</span> calculateTax(subtotal)\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">CalculateTaxB</span><span class=\"hljs-params\">(inv Invoice)</span> <span class=\"hljs-title\">float64</span></span> {\n    subtotal := sumInvoiceLines(inv.Lines)\n    <span class=\"hljs-keyword\">return</span> calculateTax(subtotal)\n}\n\n<span class=\"hljs-comment\">// Shared helpers</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">sumPrices</span><span class=\"hljs-params\">(items []Item)</span> <span class=\"hljs-title\">float64</span></span> {\n    total := <span class=\"hljs-number\">0.0</span>\n    <span class=\"hljs-keyword\">for</span> _, i := <span class=\"hljs-keyword\">range</span> items {\n        total += i.Price * <span class=\"hljs-keyword\">float64</span>(i.Quantity)\n    }\n    <span class=\"hljs-keyword\">return</span> total\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">sumInvoiceLines</span><span class=\"hljs-params\">(lines []Line)</span> <span class=\"hljs-title\">float64</span></span> {\n    total := <span class=\"hljs-number\">0.0</span>\n    <span class=\"hljs-keyword\">for</span> _, l := <span class=\"hljs-keyword\">range</span> lines {\n        total += l.UnitPrice * <span class=\"hljs-keyword\">float64</span>(l.Count)\n    }\n    <span class=\"hljs-keyword\">return</span> total\n}\n</code></pre>\n<h3 id=\"heading-long-parameter-list\">Long Parameter List</h3>\n<p><strong>What it is</strong>: Methods that accept many parameters - often over five - making calls verbose and error-prone.</p>\n<p><strong>Why it matters</strong></p>\n<ul>\n<li><p>Hard to Remember Order: Callers mix up parameters.</p>\n</li>\n<li><p><strong>Low Cohesion</strong>: Signals multiple responsibilities or data clumps.</p>\n</li>\n</ul>\n<p><strong>How to spot it</strong></p>\n<ul>\n<li><p>Method signatures with more than 4 arguments.</p>\n</li>\n<li><p>Frequent use of null or default values to skip parameters.</p>\n</li>\n</ul>\n<p><strong>Refactoring</strong>: Introduce Parameter Object</p>\n<ol>\n<li><p>Identify parameters that form a logical group.</p>\n</li>\n<li><p>Create a class/struct to hold them.</p>\n</li>\n<li><p>Replace the parameter list with the new object.</p>\n</li>\n</ol>\n<p>Example: Before</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">CreateUser</span><span class=\"hljs-params\">(firstName, lastName, email, phone, role <span class=\"hljs-keyword\">string</span>, isActive <span class=\"hljs-keyword\">bool</span>)</span></span> {\n    <span class=\"hljs-comment\">// ...</span>\n}\n</code></pre>\n<p>After:</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-keyword\">type</span> CreateUserRequest <span class=\"hljs-keyword\">struct</span> {\n    FirstName <span class=\"hljs-keyword\">string</span>\n    LastName  <span class=\"hljs-keyword\">string</span>\n    Email     <span class=\"hljs-keyword\">string</span>\n    Phone     <span class=\"hljs-keyword\">string</span>\n    Role      <span class=\"hljs-keyword\">string</span>\n    IsActive  <span class=\"hljs-keyword\">bool</span>\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">CreateUser</span><span class=\"hljs-params\">(req CreateUserRequest)</span></span> {\n    <span class=\"hljs-comment\">// ...</span>\n}\n</code></pre>\n<h3 id=\"heading-divergent-change\">Divergent Change</h3>\n<p><strong>What it is</strong>: A single class or module is edited for many unrelated reasons—bug fixes, UI tweaks, business-rule updates—indicating mixed responsibilities.</p>\n<p><strong>Why it matters</strong></p>\n<ul>\n<li><p><strong>Fragile</strong>: Changes for one concern can break another.</p>\n</li>\n<li><p><strong>Violates SRP</strong>: Violates the Single Responsibility Principle.</p>\n</li>\n</ul>\n<p><strong>How to spot it</strong></p>\n<ul>\n<li><p>Version-control history shows one file modified by many tickets of different types.</p>\n</li>\n<li><p>Code reviewers comment: “Why are we touching this here?”</p>\n</li>\n</ul>\n<p><strong>Refactoring</strong></p>\n<ul>\n<li><p>Identify distinct responsibilities and extract them into new types.</p>\n</li>\n<li><p>Move methods closer to the data they operate on.</p>\n</li>\n</ul>\n<p>Example: Before – one class handles both user validation and reporting logic:</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-keyword\">type</span> UserService <span class=\"hljs-keyword\">struct</span>{}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(s *UserService)</span> <span class=\"hljs-title\">Validate</span><span class=\"hljs-params\">(u User)</span> <span class=\"hljs-title\">error</span></span> {\n    <span class=\"hljs-keyword\">if</span> u.Email == <span class=\"hljs-string\">\"\"</span> {\n        <span class=\"hljs-keyword\">return</span> fmt.Errorf(<span class=\"hljs-string\">\"email required\"</span>)\n    }\n    <span class=\"hljs-comment\">// … many more checks …</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">nil</span>\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(s *UserService)</span> <span class=\"hljs-title\">GenerateReport</span><span class=\"hljs-params\">(u User)</span> <span class=\"hljs-title\">Report</span></span> {\n    <span class=\"hljs-comment\">// mixing data access and formatting…</span>\n    <span class=\"hljs-keyword\">return</span> Report{<span class=\"hljs-comment\">/* … */</span>}\n}\n</code></pre>\n<p>Example: After – split responsibilities into two classes:</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-keyword\">type</span> UserValidator <span class=\"hljs-keyword\">struct</span>{}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(v *UserValidator)</span> <span class=\"hljs-title\">Validate</span><span class=\"hljs-params\">(u User)</span> <span class=\"hljs-title\">error</span></span> {\n    <span class=\"hljs-keyword\">if</span> u.Email == <span class=\"hljs-string\">\"\"</span> {\n        <span class=\"hljs-keyword\">return</span> fmt.Errorf(<span class=\"hljs-string\">\"email required\"</span>)\n    }\n    <span class=\"hljs-comment\">// … other checks …</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">nil</span>\n}\n\n<span class=\"hljs-keyword\">type</span> UserReportService <span class=\"hljs-keyword\">struct</span>{}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(r *UserReportService)</span> <span class=\"hljs-title\">Generate</span><span class=\"hljs-params\">(u User)</span> <span class=\"hljs-title\">Report</span></span> {\n    report := Report{<span class=\"hljs-comment\">/* … focused report generation… */</span>}\n    <span class=\"hljs-keyword\">return</span> report\n}\n</code></pre>\n<h3 id=\"heading-feature-envy\">Feature Envy</h3>\n<p><strong>What it is</strong>: A method in one type heavily accesses fields or methods of another type - more than its own - indicating misplaced behavior.</p>\n<p><strong>Why it matters</strong></p>\n<ul>\n<li><p><strong>Tight Coupling</strong>: Class A becomes tightly coupled to B’s internals.</p>\n</li>\n<li><p><strong>Poor Encapsulation</strong>: Behavior isn’t located where the data resides.</p>\n</li>\n</ul>\n<p><strong>How to spot it</strong></p>\n<ul>\n<li>A method’s code reads like b.getX(), b.getY(), b.computeZ() repeatedly.</li>\n</ul>\n<p><strong>Refactoring</strong></p>\n<ul>\n<li><p><strong>Move Method</strong>: Shift the method into Class B.</p>\n</li>\n<li><p><strong>Extract Method</strong>: If only part of the code envies B, extract that fragment into a helper on B.</p>\n</li>\n</ul>\n<p>Example: Before – a method in <code>InvoiceService</code> reaching into <code>Order</code> internals:</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-keyword\">type</span> InvoiceService <span class=\"hljs-keyword\">struct</span>{}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(s *InvoiceService)</span> <span class=\"hljs-title\">TotalWithTax</span><span class=\"hljs-params\">(o Order)</span> <span class=\"hljs-title\">float64</span></span> {\n    sum := <span class=\"hljs-number\">0.0</span>\n    <span class=\"hljs-keyword\">for</span> _, item := <span class=\"hljs-keyword\">range</span> o.Items {\n        sum += item.Price * <span class=\"hljs-keyword\">float64</span>(item.Quantity)\n    }\n    rate := o.Customer.State.TaxRate\n    <span class=\"hljs-keyword\">return</span> sum * (<span class=\"hljs-number\">1</span> + rate)\n}\n</code></pre>\n<p>Example: After – move the logic into <code>Order</code>:</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(o Order)</span> <span class=\"hljs-title\">TotalWithTax</span><span class=\"hljs-params\">()</span> <span class=\"hljs-title\">float64</span></span> {\n    sum := <span class=\"hljs-number\">0.0</span>\n    <span class=\"hljs-keyword\">for</span> _, item := <span class=\"hljs-keyword\">range</span> o.Items {\n        sum += item.Price * <span class=\"hljs-keyword\">float64</span>(item.Quantity)\n    }\n    <span class=\"hljs-keyword\">return</span> sum * (<span class=\"hljs-number\">1</span> + o.Customer.State.TaxRate)\n}\n\n<span class=\"hljs-keyword\">type</span> InvoiceService <span class=\"hljs-keyword\">struct</span>{}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(s *InvoiceService)</span> <span class=\"hljs-title\">TotalWithTax</span><span class=\"hljs-params\">(o Order)</span> <span class=\"hljs-title\">float64</span></span> {\n    <span class=\"hljs-keyword\">return</span> o.TotalWithTax()\n}\n</code></pre>\n<h3 id=\"heading-shotgun-surgery\">Shotgun Surgery</h3>\n<p><strong>What it is</strong>: A small change requires edits in many different places - scattered across classes or modules.</p>\n<p><strong>Why it matters</strong></p>\n<ul>\n<li><p><strong>Error-Prone</strong>: Easy to miss one location.</p>\n</li>\n<li><p><strong>Discourages Change</strong>: Teams avoid improvements.</p>\n</li>\n</ul>\n<p><strong>How to spot it</strong>: Search-and-replace touches dozens of files for a single concept.</p>\n<p><strong>Refactoring</strong></p>\n<ul>\n<li><p><strong>Introduce Facade</strong>: Centralize calls behind one interface.</p>\n</li>\n<li><p><strong>Move Related Behavior</strong>: Co-locate methods and data so that a change is</p>\n</li>\n</ul>\n<p>Example: Before</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">OnboardUser</span><span class=\"hljs-params\">(userID <span class=\"hljs-keyword\">string</span>)</span></span> {\n    data := db.FetchUserData(userID)\n    processed := processor.Process(data)\n    notifier.SendWelcome(userID, processed.Summary)\n}\n</code></pre>\n<p>Example: After</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-keyword\">type</span> OnboardingFacade <span class=\"hljs-keyword\">struct</span> {\n    DB        Database\n    Processor Processor\n    Notifier  Notifier\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(f *OnboardingFacade)</span> <span class=\"hljs-title\">Onboard</span><span class=\"hljs-params\">(userID <span class=\"hljs-keyword\">string</span>)</span></span> {\n    data := f.DB.FetchUserData(userID)\n    summary := f.Processor.Process(data).Summary\n    f.Notifier.SendWelcome(userID, summary)\n}\n\n<span class=\"hljs-comment\">// Client:</span>\nfacade := OnboardingFacade{db, processor, notifier}\nfacade.Onboard(<span class=\"hljs-string\">\"user123\"</span>)\n</code></pre>\n<h3 id=\"heading-primitive-obsession\">Primitive Obsession</h3>\n<p><strong>What it is</strong>: Overusing built-in types (String, int, bool) for domain concepts instead of small dedicated classes or value objects.</p>\n<p><strong>Why it matters</strong></p>\n<ul>\n<li><p><strong>Scattering of Validation</strong>: Every user-input string is validated in ad-hoc ways.</p>\n</li>\n<li><p><strong>Duplication</strong>: Parsing and formatting logic repeated.</p>\n</li>\n</ul>\n<p><strong>How to spot it</strong></p>\n<ul>\n<li>Method signatures full of String parameters representing distinct concepts (e.g., email, phone, address).</li>\n</ul>\n<p><strong>Refactoring</strong></p>\n<ul>\n<li>Replace Primitive with Value Object: Create classes like <code>EmailAddress</code>, <code>PhoneNumber</code> that encapsulate format checks and domain logic.</li>\n</ul>\n<p>Example: Before</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">ConvertAmount</span><span class=\"hljs-params\">(amount <span class=\"hljs-keyword\">float64</span>, fromCurrency, toCurrency <span class=\"hljs-keyword\">string</span>)</span> <span class=\"hljs-title\">float64</span></span> {\n    rate := lookupRate(fromCurrency, toCurrency)\n    <span class=\"hljs-keyword\">return</span> amount * rate\n}\n</code></pre>\n<p>Example: After</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-keyword\">type</span> Currency <span class=\"hljs-keyword\">string</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(c Currency)</span> <span class=\"hljs-title\">RateTo</span><span class=\"hljs-params\">(other Currency)</span> <span class=\"hljs-title\">float64</span></span> {\n    <span class=\"hljs-keyword\">return</span> lookupRate(<span class=\"hljs-keyword\">string</span>(c), <span class=\"hljs-keyword\">string</span>(other))\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">ConvertAmount</span><span class=\"hljs-params\">(amount <span class=\"hljs-keyword\">float64</span>, from, to Currency)</span> <span class=\"hljs-title\">float64</span></span> {\n    <span class=\"hljs-keyword\">return</span> amount * from.RateTo(to)\n}\n</code></pre>\n<h3 id=\"heading-replace-temp-with-query\">Replace Temp with Query</h3>\n<p><strong>What it is</strong>: Temporary variables hold intermediate calculation results, cluttering the method body.</p>\n<p><strong>Why it matters</strong></p>\n<ul>\n<li><p><strong>Readability</strong>: Readers must track variables and their transformations.</p>\n</li>\n<li><p><strong>Duplication</strong>: The same calculation might reappear elsewhere.</p>\n</li>\n</ul>\n<p><strong>How to spot it</strong></p>\n<ul>\n<li>Sequences like temp = expr; … use temp; … modify temp.</li>\n</ul>\n<p><strong>Refactoring</strong></p>\n<ul>\n<li>Encapsulate the expression in a well-named query method, then call it directly.</li>\n</ul>\n<p>Example: Before</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">FinalPrice</span><span class=\"hljs-params\">(o Order)</span> <span class=\"hljs-title\">float64</span></span> {\n    basePrice := <span class=\"hljs-keyword\">float64</span>(o.Quantity) * o.UnitPrice\n    discount := <span class=\"hljs-number\">0.0</span>\n    <span class=\"hljs-keyword\">if</span> basePrice &gt; <span class=\"hljs-number\">1000</span> {\n        discount = basePrice * <span class=\"hljs-number\">0.05</span>\n    }\n    <span class=\"hljs-keyword\">return</span> basePrice - discount\n}\n</code></pre>\n<p>Example: After</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">FinalPrice</span><span class=\"hljs-params\">(o Order)</span> <span class=\"hljs-title\">float64</span></span> {\n    <span class=\"hljs-keyword\">return</span> calculateBase(o) - calculateDiscount(o)\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">calculateBase</span><span class=\"hljs-params\">(o Order)</span> <span class=\"hljs-title\">float64</span></span> {\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">float64</span>(o.Quantity) * o.UnitPrice\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">calculateDiscount</span><span class=\"hljs-params\">(o Order)</span> <span class=\"hljs-title\">float64</span></span> {\n    base := calculateBase(o)\n    <span class=\"hljs-keyword\">if</span> base &gt; <span class=\"hljs-number\">1000</span> {\n        <span class=\"hljs-keyword\">return</span> base * <span class=\"hljs-number\">0.05</span>\n    }\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>\n}\n</code></pre>\n<h3 id=\"heading-replace-conditional-with-polymorphism\">Replace Conditional with Polymorphism</h3>\n<p><strong>What it is</strong>: Extensive <code>if-else</code> or <code>switch</code> blocks that dispatch based on type codes or flags.</p>\n<p><strong>Why it matters</strong></p>\n<ul>\n<li><p><strong>Open/Closed Violation</strong>: Every time you add a new type, you modify the conditional.</p>\n</li>\n<li><p><strong>Readability</strong>: Logic spread across a tangled conditional.</p>\n</li>\n</ul>\n<p><strong>How to spot it</strong></p>\n<ul>\n<li>Large switch(order.type) { case A:…; case B:… } constructs.</li>\n</ul>\n<p><strong>Refactoring</strong></p>\n<ul>\n<li>Strategy Pattern or Class Hierarchy: Define a common interface and let each subtype implement its behavior.</li>\n</ul>\n<p>Example: Before</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">SendNotification</span><span class=\"hljs-params\">(u User, method <span class=\"hljs-keyword\">string</span>)</span></span> {\n    <span class=\"hljs-keyword\">if</span> method == <span class=\"hljs-string\">\"email\"</span> {\n        sendEmail(u.Email, <span class=\"hljs-string\">\"Hello!\"</span>)\n    } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> method == <span class=\"hljs-string\">\"sms\"</span> {\n        sendSMS(u.Phone, <span class=\"hljs-string\">\"Hello!\"</span>)\n    } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> method == <span class=\"hljs-string\">\"push\"</span> {\n        sendPush(u.DeviceToken, <span class=\"hljs-string\">\"Hello!\"</span>)\n    }\n}\n</code></pre>\n<p>Example: After</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-keyword\">type</span> Notifier <span class=\"hljs-keyword\">interface</span> {\n    Notify(User)\n}\n\n<span class=\"hljs-keyword\">type</span> EmailNotifier <span class=\"hljs-keyword\">struct</span>{}\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(EmailNotifier)</span> <span class=\"hljs-title\">Notify</span><span class=\"hljs-params\">(u User)</span></span> { sendEmail(u.Email, <span class=\"hljs-string\">\"Hello!\"</span>) }\n\n<span class=\"hljs-keyword\">type</span> SMSNotifier <span class=\"hljs-keyword\">struct</span>{}\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(SMSNotifier)</span> <span class=\"hljs-title\">Notify</span><span class=\"hljs-params\">(u User)</span></span> { sendSMS(u.Phone, <span class=\"hljs-string\">\"Hello!\"</span>) }\n\n<span class=\"hljs-keyword\">type</span> PushNotifier <span class=\"hljs-keyword\">struct</span>{}\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(PushNotifier)</span> <span class=\"hljs-title\">Notify</span><span class=\"hljs-params\">(u User)</span></span> { sendPush(u.DeviceToken, <span class=\"hljs-string\">\"Hello!\"</span>) }\n\n<span class=\"hljs-keyword\">var</span> notifierMap = <span class=\"hljs-keyword\">map</span>[<span class=\"hljs-keyword\">string</span>]Notifier{\n    <span class=\"hljs-string\">\"email\"</span>: EmailNotifier{},\n    <span class=\"hljs-string\">\"sms\"</span>:   SMSNotifier{},\n    <span class=\"hljs-string\">\"push\"</span>:  PushNotifier{},\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">SendNotification</span><span class=\"hljs-params\">(u User, method <span class=\"hljs-keyword\">string</span>)</span></span> {\n    <span class=\"hljs-keyword\">if</span> n, ok := notifierMap[method]; ok {\n        n.Notify(u)\n    }\n}\n</code></pre>\n<h3 id=\"heading-data-clumps\">Data Clumps</h3>\n<p><strong>What it is</strong>: Groups of variables that always appear together—e.g., x, y, z coordinates, street, city, zip.</p>\n<p><strong>Why it matters</strong></p>\n<ul>\n<li><p><strong>Duplication</strong>: Same parameter list repeated.</p>\n</li>\n<li><p><strong>Cohesion</strong>: Related data isn’t grouped.</p>\n</li>\n</ul>\n<p><strong>How to spot it</strong></p>\n<ul>\n<li>Method after method accepting the same set of parameters.</li>\n</ul>\n<p><strong>Refactoring</strong></p>\n<ul>\n<li>Introduce Parameter Object or Data Class to bundle related fields into one type.</li>\n</ul>\n<p>Example: Before</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">DrawLine</span><span class=\"hljs-params\">(x1, y1, x2, y2 <span class=\"hljs-keyword\">float64</span>, color <span class=\"hljs-keyword\">string</span>)</span></span> {\n    ctx.SetStrokeColor(color)\n    ctx.MoveTo(x1, y1)\n    ctx.LineTo(x2, y2)\n    ctx.Stroke()\n}\n</code></pre>\n<p>Example: After</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-keyword\">type</span> Point <span class=\"hljs-keyword\">struct</span>{ X, Y <span class=\"hljs-keyword\">float64</span> }\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">DrawLine</span><span class=\"hljs-params\">(p1, p2 Point, color <span class=\"hljs-keyword\">string</span>)</span></span> {\n    ctx.SetStrokeColor(color)\n    ctx.MoveTo(p1.X, p1.Y)\n    ctx.LineTo(p2.X, p2.Y)\n    ctx.Stroke()\n}\n\n<span class=\"hljs-comment\">// Usage</span>\nDrawLine(Point{<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">20</span>}, Point{<span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">40</span>}, <span class=\"hljs-string\">\"red\"</span>)\n</code></pre>\n<h2 id=\"heading-general-refactoring-best-practices\">General Refactoring Best Practices</h2>\n<ol>\n<li><p><strong>Test Coverage First</strong>: Ensure you have reliable unit and integration tests before refactoring.</p>\n</li>\n<li><p><strong>Tiny, Safe Steps</strong>: Change one thing at a time; run tests after each change to catch regressions early.</p>\n</li>\n<li><p><strong>IDE Assistance</strong>: Leverage built-in refactorings—Extract Method, Rename, Inline—to minimize manual edits.</p>\n</li>\n<li><p><strong>Code Reviews with Smell Checks</strong>: Add “smell spotting” to your review checklist to catch issues collaboratively.</p>\n</li>\n<li><p><strong>Continuous Refactoring</strong>: Make cleanup part of your regular workflow and Definition of Done, not a separate “cleanup sprint.”</p>\n</li>\n</ol>\n<h2 id=\"heading-conclusion\">Conclusion</h2>\n<p>Code smells are inevitable, but they need not become insurmountable technical debt. By recognizing these ten patterns and applying targeted refactorings, you’ll cultivate a codebase that’s more understandable, safer to change, and more enjoyable for your entire team. Start small, build momentum with quick wins like Extract Method, then tackle more advanced refactorings. Your future self (and teammates) will thank you.</p>\n","contentMarkdown":"Code is more than just instructions for a machine - it’s a form of communication with your future self and teammates. Yet all too often, codebases accumulate hidden “stinkers” that slow down development, introduce bugs, and frustrate newcomers. These are **code smells**: surface indicators that something deeper in the design or implementation needs attention. In this post, we’ll explore a comprehensive catalog of common smells and walk through concrete refactoring - complete with before/after snippets (in Go, but the logic can be applied to any language)- to help you keep your codebase clean, maintainable, and a joy to work with.\n\n## Why Code Smells matter?\n\n* **Readability & Onboarding**: Long, tangled methods or duplicated logic force readers to mentally untangle intent from implementation. New team members spend hours deciphering what should’ve been clear.\n    \n* **Bug Rate**: Smelly code often has hidden dependencies or unexpected side effects. One small change can ripple out, breaking functionality in multiple places.\n    \n* **Confidence to Change**: When refactoring feels risky, teams delay improvements, leading to technical debt escalation. Over time, even minor enhancements require heroic effort.\n    \n\n> **Personal Anecdote**: During the early stages of my career I inherited a 5k line class handling everything from fetching data then transforming it and loading it somewhere. This class was growing exponentially with every sprint/iteration, and soon risked crossing 10k lines. Every change required a full regression suite and lots of manual testing. After identifying just three key smells - Long Method, Feature Envy, and Primitive Obsession - we applied targeted refactorings that reduced that class to under 1000 lines and we were easily able to extend our codebase.\n\n## **Basic Code Smells & Refactorings**\n\n### Long Method\n\n**What it is:** A method or function that spans many lines - often 200+ - and tries to do too much: input validation, business logic, data transformation, persistence, side-effects, and user interaction all in one place.\n\n**Why it matters**\n\n* **Cognitive Load**: Readers must keep many moving parts and intents in mind at once.\n    \n* **Hard to Test**: You can’t isolate pieces easily for unit tests.\n    \n* **Change Risk**: A tweak for one concern can inadvertently break another.\n    \n\n**How to spot it**\n\n* Look for methods longer than a screen.\n    \n* Multiple comments like // validate, // compute, // persist in one block.\n    \n* Deep nesting of conditionals and loops.\n    \n\n**Refactoring**: Use Extract Method\n\n1. Identify a coherent chunk: it does one logical sub-task.\n    \n2. Give it a descriptive name.\n    \n3. Replace the chunk with a call to the new method.\n    \n\nExample: Before\n\n```go\nfunc Checkout(cart Cart) {\n    // 1. Validate\n    if len(cart.Items) == 0 { log.Error(\"empty cart\"); return }\n    // 2. Sum prices\n    sum := 0.0\n    for _, i := range cart.Items { sum += i.Price * float64(i.Qty) }\n    // 3. Apply discount\n    if cart.Customer.IsVIP { sum *= 0.9 }\n    // 4. Log & persist\n    log.Printf(\"Total: %.2f\", sum)\n    db.Save(cart, sum)\n    // 5. Send email\n    emailService.Send(cart.Customer.Email, sum)\n}\n```\n\nExample: After\n\n```go\nfunc Checkout(cart Cart) {\n    if err := validate(cart); err != nil {\n        log.Error(err); return\n    }\n    total := calculateTotal(cart.Items)\n    total = applyDiscount(total, cart.Customer)\n    finalizeOrder(cart, total)\n}\n\nfunc validate(cart Cart) error {\n    if len(cart.Items) == 0 { return fmt.Errorf(\"cart empty\") }\n    return nil\n}\n\nfunc calculateTotal(items []Item) float64 { … }\n\nfunc applyDiscount(total float64, c Customer) float64 { … }\n\nfunc finalizeOrder(cart Cart, total float64) {\n    log.Printf(\"Total: %.2f\", total)\n    db.Save(cart, total)\n    emailService.Send(cart.Customer.Email, total)\n}\n```\n\n### Duplicated Code\n\n**What it is**: Slivers of nearly identical logic appear in two or more locations - copy-paste programming.\n\n**Why it matters**\n\n* **Maintenance Hell**: Fixing a bug requires updating every copy.\n    \n* **Divergence**: Over time, copies drift apart, hiding inconsistent behavior.\n    \n\n**How to spot it**\n\n* Search for the same loop, conditional, or calculation in multiple files.\n    \n* In code reviews, ask “Have we done this before?”\n    \n\n**Refactoring Options**\n\n* Pull shared logic into a single helper function.\n    \n* Replace all occurrences with calls to that helper\n    \n\nExample: Before\n\n```go\nfunc CalculateTaxA(order Order) float64 {\n    tax := 0.0\n    for _, item := range order.Items {\n        tax += item.Price * float64(item.Quantity) * 0.08\n    }\n    return tax\n}\n\nfunc CalculateTaxB(invoice Invoice) float64 {\n    tax := 0.0\n    for _, line := range invoice.Lines {\n        tax += line.UnitPrice * float64(line.Count) * 0.08\n    }\n    return tax\n}\n```\n\nExample: After\n\n```go\nfunc calculateTax(subtotal float64) float64 {\n    return subtotal * 0.08\n}\n\nfunc CalculateTaxA(order Order) float64 {\n    subtotal := sumPrices(order.Items)\n    return calculateTax(subtotal)\n}\n\nfunc CalculateTaxB(inv Invoice) float64 {\n    subtotal := sumInvoiceLines(inv.Lines)\n    return calculateTax(subtotal)\n}\n\n// Shared helpers\nfunc sumPrices(items []Item) float64 {\n    total := 0.0\n    for _, i := range items {\n        total += i.Price * float64(i.Quantity)\n    }\n    return total\n}\n\nfunc sumInvoiceLines(lines []Line) float64 {\n    total := 0.0\n    for _, l := range lines {\n        total += l.UnitPrice * float64(l.Count)\n    }\n    return total\n}\n```\n\n### Long Parameter List\n\n**What it is**: Methods that accept many parameters - often over five - making calls verbose and error-prone.\n\n**Why it matters**\n\n* Hard to Remember Order: Callers mix up parameters.\n    \n* **Low Cohesion**: Signals multiple responsibilities or data clumps.\n    \n\n**How to spot it**\n\n* Method signatures with more than 4 arguments.\n    \n* Frequent use of null or default values to skip parameters.\n    \n\n**Refactoring**: Introduce Parameter Object\n\n1. Identify parameters that form a logical group.\n    \n2. Create a class/struct to hold them.\n    \n3. Replace the parameter list with the new object.\n    \n\nExample: Before\n\n```go\nfunc CreateUser(firstName, lastName, email, phone, role string, isActive bool) {\n    // ...\n}\n```\n\nAfter:\n\n```go\ntype CreateUserRequest struct {\n    FirstName string\n    LastName  string\n    Email     string\n    Phone     string\n    Role      string\n    IsActive  bool\n}\n\nfunc CreateUser(req CreateUserRequest) {\n    // ...\n}\n```\n\n### Divergent Change\n\n**What it is**: A single class or module is edited for many unrelated reasons—bug fixes, UI tweaks, business-rule updates—indicating mixed responsibilities.\n\n**Why it matters**\n\n* **Fragile**: Changes for one concern can break another.\n    \n* **Violates SRP**: Violates the Single Responsibility Principle.\n    \n\n**How to spot it**\n\n* Version-control history shows one file modified by many tickets of different types.\n    \n* Code reviewers comment: “Why are we touching this here?”\n    \n\n**Refactoring**\n\n* Identify distinct responsibilities and extract them into new types.\n    \n* Move methods closer to the data they operate on.\n    \n\nExample: Before – one class handles both user validation and reporting logic:\n\n```go\ntype UserService struct{}\n\nfunc (s *UserService) Validate(u User) error {\n    if u.Email == \"\" {\n        return fmt.Errorf(\"email required\")\n    }\n    // … many more checks …\n    return nil\n}\n\nfunc (s *UserService) GenerateReport(u User) Report {\n    // mixing data access and formatting…\n    return Report{/* … */}\n}\n```\n\nExample: After – split responsibilities into two classes:\n\n```go\ntype UserValidator struct{}\n\nfunc (v *UserValidator) Validate(u User) error {\n    if u.Email == \"\" {\n        return fmt.Errorf(\"email required\")\n    }\n    // … other checks …\n    return nil\n}\n\ntype UserReportService struct{}\n\nfunc (r *UserReportService) Generate(u User) Report {\n    report := Report{/* … focused report generation… */}\n    return report\n}\n```\n\n### Feature Envy\n\n**What it is**: A method in one type heavily accesses fields or methods of another type - more than its own - indicating misplaced behavior.\n\n**Why it matters**\n\n* **Tight Coupling**: Class A becomes tightly coupled to B’s internals.\n    \n* **Poor Encapsulation**: Behavior isn’t located where the data resides.\n    \n\n**How to spot it**\n\n* A method’s code reads like b.getX(), b.getY(), b.computeZ() repeatedly.\n    \n\n**Refactoring**\n\n* **Move Method**: Shift the method into Class B.\n    \n* **Extract Method**: If only part of the code envies B, extract that fragment into a helper on B.\n    \n\nExample: Before – a method in `InvoiceService` reaching into `Order` internals:\n\n```go\ntype InvoiceService struct{}\n\nfunc (s *InvoiceService) TotalWithTax(o Order) float64 {\n    sum := 0.0\n    for _, item := range o.Items {\n        sum += item.Price * float64(item.Quantity)\n    }\n    rate := o.Customer.State.TaxRate\n    return sum * (1 + rate)\n}\n```\n\nExample: After – move the logic into `Order`:\n\n```go\nfunc (o Order) TotalWithTax() float64 {\n    sum := 0.0\n    for _, item := range o.Items {\n        sum += item.Price * float64(item.Quantity)\n    }\n    return sum * (1 + o.Customer.State.TaxRate)\n}\n\ntype InvoiceService struct{}\n\nfunc (s *InvoiceService) TotalWithTax(o Order) float64 {\n    return o.TotalWithTax()\n}\n```\n\n### Shotgun Surgery\n\n**What it is**: A small change requires edits in many different places - scattered across classes or modules.\n\n**Why it matters**\n\n* **Error-Prone**: Easy to miss one location.\n    \n* **Discourages Change**: Teams avoid improvements.\n    \n\n**How to spot it**: Search-and-replace touches dozens of files for a single concept.\n\n**Refactoring**\n\n* **Introduce Facade**: Centralize calls behind one interface.\n    \n* **Move Related Behavior**: Co-locate methods and data so that a change is\n    \n\nExample: Before\n\n```go\nfunc OnboardUser(userID string) {\n    data := db.FetchUserData(userID)\n    processed := processor.Process(data)\n    notifier.SendWelcome(userID, processed.Summary)\n}\n```\n\nExample: After\n\n```go\ntype OnboardingFacade struct {\n    DB        Database\n    Processor Processor\n    Notifier  Notifier\n}\n\nfunc (f *OnboardingFacade) Onboard(userID string) {\n    data := f.DB.FetchUserData(userID)\n    summary := f.Processor.Process(data).Summary\n    f.Notifier.SendWelcome(userID, summary)\n}\n\n// Client:\nfacade := OnboardingFacade{db, processor, notifier}\nfacade.Onboard(\"user123\")\n```\n\n### Primitive Obsession\n\n**What it is**: Overusing built-in types (String, int, bool) for domain concepts instead of small dedicated classes or value objects.\n\n**Why it matters**\n\n* **Scattering of Validation**: Every user-input string is validated in ad-hoc ways.\n    \n* **Duplication**: Parsing and formatting logic repeated.\n    \n\n**How to spot it**\n\n* Method signatures full of String parameters representing distinct concepts (e.g., email, phone, address).\n    \n\n**Refactoring**\n\n* Replace Primitive with Value Object: Create classes like `EmailAddress`, `PhoneNumber` that encapsulate format checks and domain logic.\n    \n\nExample: Before\n\n```go\nfunc ConvertAmount(amount float64, fromCurrency, toCurrency string) float64 {\n    rate := lookupRate(fromCurrency, toCurrency)\n    return amount * rate\n}\n```\n\nExample: After\n\n```go\ntype Currency string\n\nfunc (c Currency) RateTo(other Currency) float64 {\n    return lookupRate(string(c), string(other))\n}\n\nfunc ConvertAmount(amount float64, from, to Currency) float64 {\n    return amount * from.RateTo(to)\n}\n```\n\n### Replace Temp with Query\n\n**What it is**: Temporary variables hold intermediate calculation results, cluttering the method body.\n\n**Why it matters**\n\n* **Readability**: Readers must track variables and their transformations.\n    \n* **Duplication**: The same calculation might reappear elsewhere.\n    \n\n**How to spot it**\n\n* Sequences like temp = expr; … use temp; … modify temp.\n    \n\n**Refactoring**\n\n* Encapsulate the expression in a well-named query method, then call it directly.\n    \n\nExample: Before\n\n```go\nfunc FinalPrice(o Order) float64 {\n    basePrice := float64(o.Quantity) * o.UnitPrice\n    discount := 0.0\n    if basePrice > 1000 {\n        discount = basePrice * 0.05\n    }\n    return basePrice - discount\n}\n```\n\nExample: After\n\n```go\nfunc FinalPrice(o Order) float64 {\n    return calculateBase(o) - calculateDiscount(o)\n}\n\nfunc calculateBase(o Order) float64 {\n    return float64(o.Quantity) * o.UnitPrice\n}\n\nfunc calculateDiscount(o Order) float64 {\n    base := calculateBase(o)\n    if base > 1000 {\n        return base * 0.05\n    }\n    return 0\n}\n```\n\n### Replace Conditional with Polymorphism\n\n**What it is**: Extensive `if-else` or `switch` blocks that dispatch based on type codes or flags.\n\n**Why it matters**\n\n* **Open/Closed Violation**: Every time you add a new type, you modify the conditional.\n    \n* **Readability**: Logic spread across a tangled conditional.\n    \n\n**How to spot it**\n\n* Large switch(order.type) { case A:…; case B:… } constructs.\n    \n\n**Refactoring**\n\n* Strategy Pattern or Class Hierarchy: Define a common interface and let each subtype implement its behavior.\n    \n\nExample: Before\n\n```go\nfunc SendNotification(u User, method string) {\n    if method == \"email\" {\n        sendEmail(u.Email, \"Hello!\")\n    } else if method == \"sms\" {\n        sendSMS(u.Phone, \"Hello!\")\n    } else if method == \"push\" {\n        sendPush(u.DeviceToken, \"Hello!\")\n    }\n}\n```\n\nExample: After\n\n```go\ntype Notifier interface {\n    Notify(User)\n}\n\ntype EmailNotifier struct{}\nfunc (EmailNotifier) Notify(u User) { sendEmail(u.Email, \"Hello!\") }\n\ntype SMSNotifier struct{}\nfunc (SMSNotifier) Notify(u User) { sendSMS(u.Phone, \"Hello!\") }\n\ntype PushNotifier struct{}\nfunc (PushNotifier) Notify(u User) { sendPush(u.DeviceToken, \"Hello!\") }\n\nvar notifierMap = map[string]Notifier{\n    \"email\": EmailNotifier{},\n    \"sms\":   SMSNotifier{},\n    \"push\":  PushNotifier{},\n}\n\nfunc SendNotification(u User, method string) {\n    if n, ok := notifierMap[method]; ok {\n        n.Notify(u)\n    }\n}\n```\n\n### Data Clumps\n\n**What it is**: Groups of variables that always appear together—e.g., x, y, z coordinates, street, city, zip.\n\n**Why it matters**\n\n* **Duplication**: Same parameter list repeated.\n    \n* **Cohesion**: Related data isn’t grouped.\n    \n\n**How to spot it**\n\n* Method after method accepting the same set of parameters.\n    \n\n**Refactoring**\n\n* Introduce Parameter Object or Data Class to bundle related fields into one type.\n    \n\nExample: Before\n\n```go\nfunc DrawLine(x1, y1, x2, y2 float64, color string) {\n    ctx.SetStrokeColor(color)\n    ctx.MoveTo(x1, y1)\n    ctx.LineTo(x2, y2)\n    ctx.Stroke()\n}\n```\n\nExample: After\n\n```go\ntype Point struct{ X, Y float64 }\n\nfunc DrawLine(p1, p2 Point, color string) {\n    ctx.SetStrokeColor(color)\n    ctx.MoveTo(p1.X, p1.Y)\n    ctx.LineTo(p2.X, p2.Y)\n    ctx.Stroke()\n}\n\n// Usage\nDrawLine(Point{10, 20}, Point{30, 40}, \"red\")\n```\n\n## General Refactoring Best Practices\n\n1. **Test Coverage First**: Ensure you have reliable unit and integration tests before refactoring.\n    \n2. **Tiny, Safe Steps**: Change one thing at a time; run tests after each change to catch regressions early.\n    \n3. **IDE Assistance**: Leverage built-in refactorings—Extract Method, Rename, Inline—to minimize manual edits.\n    \n4. **Code Reviews with Smell Checks**: Add “smell spotting” to your review checklist to catch issues collaboratively.\n    \n5. **Continuous Refactoring**: Make cleanup part of your regular workflow and Definition of Done, not a separate “cleanup sprint.”\n    \n\n## Conclusion\n\nCode smells are inevitable, but they need not become insurmountable technical debt. By recognizing these ten patterns and applying targeted refactorings, you’ll cultivate a codebase that’s more understandable, safer to change, and more enjoyable for your entire team. Start small, build momentum with quick wins like Extract Method, then tackle more advanced refactorings. Your future self (and teammates) will thank you.","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1747033669754/9c2794ee-9a67-4f1c-81f9-f9baf6b5c65e.jpeg","brief":"Code is more than just instructions for a machine - it’s a form of communication with your future self and teammates. Yet all too often, codebases accumulate hidden “stinkers” that slow down development, introduce bugs, and frustrate newcomers. These...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":false,"readTime":10,"draft":"6820eafe73ee2f26c1ce80f0","tags":[],"publication":"5cdd04921a7cb8b20267646b","metaTitle":"Refactor Code Smells for Quality Improvements","metaDescription":"Identify and refactor code smells to improve code quality and maintainability for a cleaner, more effective codebase","isNewsletterActivated":true,"coAuthors":[],"dateUpdated":"2025-05-12T08:56:26.768Z","pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"6821a6985006bd988f7f9344"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"67cbf99efca581965cde6fca","createdAt":"2025-03-08T08:02:38.007Z","updatedAt":"2025-05-12T08:56:26.788Z","views":62,"isActive":true,"hasLatex":false,"popularity":7387.8835,"discussionScore":0,"enableToc":false,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":10,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"disableComments":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"slugOverridden":true,"tweetOptions":{"enabled":false},"title":"Why Every Developer Should Care About Design Patterns: A Deep Dive","cuid":"cm7zx2qt2000709jsbw380fsl","dateAdded":"2025-03-08T08:02:38.006Z","isCoverAttributionHidden":false,"coverImageAttribution":"","coverImagePhotographer":"","stickCoverToBottom":false,"slug":"why-every-developer-should-care-about-design-patterns","content":"<p>Imagine you're building furniture. You could design each piece from scratch, figuring out how legs connect to tabletops or how drawers slide in and out. Or, you could use tried-and-tested blueprints that woodworkers have refined over generations.</p>\n<p>In software development, design patterns are these blueprints. They represent elegant solutions to common coding problems that developers have encountered repeatedly over decades. And whether you're just starting your coding journey or you're a seasoned developer, understanding these patterns can dramatically improve your programming skills.</p>\n<h2 id=\"heading-what-are-design-patterns-really\">What Are Design Patterns, Really?</h2>\n<p>At their core, design patterns are reusable solutions to problems that occur frequently in software design. Think of them as templates that can be applied to different situations, saving you from reinventing the wheel each time you face a familiar challenge.</p>\n<p>The concept was popularized in 1994 when four authors (often called the \"Gang of Four\" or GoF) published the book \"Design Patterns: Elements of Reusable Object-Oriented Software.\" This landmark text identified 23 patterns that addressed common problems in object-oriented programming.</p>\n<h2 id=\"heading-the-three-categories-of-design-patterns\">The Three Categories of Design Patterns</h2>\n<p>Design patterns generally fall into three categories, each addressing a different aspect of software design:</p>\n<h3 id=\"heading-1-creational-patterns\">1. Creational Patterns</h3>\n<p>These patterns deal with object creation mechanisms, trying to create objects in a manner suitable to the situation.</p>\n<p><strong>Example: The Factory Pattern</strong></p>\n<p>Imagine you're developing a game with different character types (warrior, mage, archer). Instead of writing code like this everywhere:</p>\n<pre><code class=\"lang-java\">Character character;\n<span class=\"hljs-keyword\">if</span> (type.equals(<span class=\"hljs-string\">\"warrior\"</span>)) {\n    character = <span class=\"hljs-keyword\">new</span> Warrior();\n} <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(type.equals(<span class=\"hljs-string\">\"mage\"</span>)) {\n    character = <span class=\"hljs-keyword\">new</span> Mage();\n} <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(type.equals(<span class=\"hljs-string\">\"archer\"</span>)) {\n    character = <span class=\"hljs-keyword\">new</span> Archer();\n}\n</code></pre>\n<p>You could use a Factory pattern:</p>\n<pre><code class=\"lang-java\">Character character = CharacterFactory.createCharacter(type);\n</code></pre>\n<p>The factory handles the complex creation logic, making your code cleaner and more maintainable. If you add a new character type later, you only need to modify the factory, not every place characters are created.</p>\n<h3 id=\"heading-2-structural-patterns\">2. Structural Patterns</h3>\n<p>These patterns focus on how classes and objects are composed to form larger structures.</p>\n<p><strong>Example: The Adapter Pattern</strong></p>\n<p>Imagine you have a new library that tracks user analytics, but its interface doesn't match what your application expects:</p>\n<pre><code class=\"lang-java\"><span class=\"hljs-comment\">// Your application expects:</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">interface</span> <span class=\"hljs-title\">OldAnalytics</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">trackEvent</span><span class=\"hljs-params\">(String name, Map&lt;String, String&gt; data)</span></span>;\n}\n\n<span class=\"hljs-comment\">// But the new library uses:</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">NewAnalyticsLibrary</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">logActivity</span><span class=\"hljs-params\">(String activityName, JSONObject attributes)</span> </span>{\n        <span class=\"hljs-comment\">// Implementation</span>\n    }\n}\n</code></pre>\n<p>Instead of changing your entire codebase, you can create an adapter:</p>\n<pre><code class=\"lang-java\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">AnalyticsAdapter</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">OldAnalytics</span> </span>{\n    <span class=\"hljs-keyword\">private</span> NewAnalyticsLibrary newAnalytics = <span class=\"hljs-keyword\">new</span> NewAnalyticsLibrary();\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">trackEvent</span><span class=\"hljs-params\">(String name, Map&lt;String, String&gt; data)</span> </span>{\n        JSONObject json = convertMapToJson(data);\n        newAnalytics.logActivity(name, json);\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">private</span> JSONObject <span class=\"hljs-title\">convertMapToJson</span><span class=\"hljs-params\">(Map&lt;String, String&gt; data)</span> </span>{\n        <span class=\"hljs-comment\">// Conversion logic</span>\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> JSONObject(data);\n    }\n}\n</code></pre>\n<p>Now your existing code works with the new library without modifications!</p>\n<h3 id=\"heading-3-behavioral-patterns\">3. Behavioral Patterns</h3>\n<p>These patterns are concerned with algorithms and the assignment of responsibilities between objects.</p>\n<p><strong>Example: The Observer Pattern</strong></p>\n<p>Think of how social media works: when someone posts an update, all their followers get notified. This is the Observer pattern in action!</p>\n<pre><code class=\"lang-java\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Post</span> </span>{\n    <span class=\"hljs-keyword\">private</span> List&lt;User&gt; followers = <span class=\"hljs-keyword\">new</span> ArrayList&lt;&gt;();\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">addFollower</span><span class=\"hljs-params\">(User user)</span> </span>{\n        followers.add(user);\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">createUpdate</span><span class=\"hljs-params\">(String content)</span> </span>{\n        <span class=\"hljs-comment\">// Create the update</span>\n        notifyFollowers();\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">notifyFollowers</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">for</span>(User follower : followers) {\n            follower.notify(<span class=\"hljs-string\">\"New post available!\"</span>);\n        }\n    }\n}\n</code></pre>\n<p>This pattern creates a one-to-many dependency where multiple observers (followers) are notified when the subject (post creator) changes state.</p>\n<h2 id=\"heading-why-should-beginners-care-about-design-patterns\">Why Should Beginners Care About Design Patterns?</h2>\n<p>If you're new to programming, you might wonder if design patterns are relevant to you yet. The answer is a resounding yes, for several important reasons:</p>\n<h3 id=\"heading-1-they-teach-you-how-to-think-about-code-structure\">1. They Teach You How to Think About Code Structure</h3>\n<p>Learning design patterns early helps develop an architectural mindset. Instead of focusing solely on making your code work, you start considering how it's organized and how different components interact.</p>\n<h3 id=\"heading-2-they-help-you-write-more-professional-code-faster\">2. They Help You Write More Professional Code Faster</h3>\n<p>When you recognize common problems, you can apply established solutions rather than struggling through trial and error. This accelerates your development process and results in more robust solutions.</p>\n<h3 id=\"heading-3-they-improve-collaboration\">3. They Improve Collaboration</h3>\n<p>Programming is rarely a solo activity. Using established patterns creates a shared vocabulary with other developers. When you mention using a \"Factory Method\" or \"Observer Pattern,\" other developers immediately understand your approach.</p>\n<h3 id=\"heading-4-they-prepare-you-for-framework-learning\">4. They Prepare You for Framework Learning</h3>\n<p>Modern frameworks like React, Angular, and Spring incorporate many design patterns. Understanding these patterns makes learning frameworks easier because you recognize the underlying concepts.</p>\n<h3 id=\"heading-5-they-prevent-common-mistakes\">5. They Prevent Common Mistakes</h3>\n<p>Many design patterns evolved specifically to address problems that repeatedly caused bugs or maintenance headaches. Learning these patterns helps you avoid these pitfalls from the start.</p>\n<h2 id=\"heading-design-patterns-in-real-world-applications\">Design Patterns in Real-World Applications</h2>\n<p>Let's look at some examples of how design patterns show up in technologies you might already be using:</p>\n<h3 id=\"heading-in-web-development\">In Web Development</h3>\n<p><strong>React's Component Model:</strong> React uses the Composite pattern, allowing you to build complex UIs from simple components that can contain other components.</p>\n<p><strong>Event Handling in JavaScript:</strong> The Observer pattern is used extensively in event-driven programming, where event listeners \"observe\" elements and respond to user interactions.</p>\n<h3 id=\"heading-in-mobile-apps\">In Mobile Apps</h3>\n<p><strong>iOS's Delegation Pattern:</strong> This is a variation of the Observer pattern where objects delegate certain responsibilities to other objects.</p>\n<p><strong>Android's Adapter Views:</strong> These use the Adapter pattern to convert data sources into views that can be displayed in lists.</p>\n<h3 id=\"heading-in-everyday-applications\">In Everyday Applications</h3>\n<p><strong>Word Processors:</strong> The Command pattern powers features like undo/redo, where each action is encapsulated as an object that can be executed, tracked, and reversed.</p>\n<p><strong>Video Games:</strong> The State pattern manages character behaviors, allowing characters to smoothly transition between actions like walking, running, or attacking.</p>\n<h2 id=\"heading-common-misunderstandings-about-design-patterns\">Common Misunderstandings About Design Patterns</h2>\n<p>As you learn about design patterns, be aware of these common misconceptions:</p>\n<h3 id=\"heading-misunderstanding-1-design-patterns-are-too-complex-for-beginners\">Misunderstanding #1: \"Design Patterns Are Too Complex for Beginners\"</h3>\n<p><strong>Reality:</strong> While some patterns have complex implementations, the concepts behind them are accessible to beginners. Start with simpler patterns like Factory, Observer, and Strategy.</p>\n<h3 id=\"heading-misunderstanding-2-i-should-use-design-patterns-everywhere\">Misunderstanding #2: \"I Should Use Design Patterns Everywhere\"</h3>\n<p><strong>Reality:</strong> Design patterns are tools, not rules. They should be applied when they solve a specific problem, not forced into every situation. Sometimes simple, straightforward code is better.</p>\n<h3 id=\"heading-misunderstanding-3-design-patterns-are-outdated\">Misunderstanding #3: \"Design Patterns Are Outdated\"</h3>\n<p><strong>Reality:</strong> While some specific implementations may become less relevant as languages evolve, the core principles behind design patterns remain valuable. Modern languages and frameworks may offer built-in solutions for some patterns, but understanding the patterns helps you use these features more effectively.</p>\n<h2 id=\"heading-how-to-start-learning-design-patterns\">How to Start Learning Design Patterns</h2>\n<p>Ready to dive into design patterns? Here's a beginner-friendly approach:</p>\n<h3 id=\"heading-1-start-with-real-problems\">1. Start with Real Problems</h3>\n<p>Rather than trying to memorize all 23 GoF patterns at once, focus on patterns that solve problems you've encountered. This makes the learning more relevant and memorable.</p>\n<h3 id=\"heading-2-learn-through-examples\">2. Learn Through Examples</h3>\n<p>Look for concrete examples of patterns in languages you're familiar with. Many online resources provide code samples in different programming languages.</p>\n<h3 id=\"heading-3-practice-implementation\">3. Practice Implementation</h3>\n<p>Try implementing a simple version of each pattern you learn. This hands-on approach helps solidify your understanding.</p>\n<h3 id=\"heading-4-refactor-existing-code\">4. Refactor Existing Code</h3>\n<p>Take some code you've already written and refactor it using a design pattern. This exercise helps you see the benefits and trade-offs directly.</p>\n<h3 id=\"heading-5-learn-patterns-in-groups\">5. Learn Patterns in Groups</h3>\n<p>Study related patterns together to understand their similarities and differences. For example, learn Factory Method, Abstract Factory, and Builder together to understand different approaches to object creation.</p>\n<h2 id=\"heading-a-deeper-look-at-five-essential-patterns-for-beginners\">A Deeper Look at Five Essential Patterns for Beginners</h2>\n<p>Let's explore five patterns that are particularly valuable for beginners to understand:</p>\n<h3 id=\"heading-1-singleton-pattern\">1. Singleton Pattern</h3>\n<p><strong>Problem it Solves:</strong> Sometimes you need exactly one instance of a class that is accessible globally, like a configuration manager or connection pool.</p>\n<p><strong>How it Works:</strong> The pattern ensures a class has only one instance and provides a global point to access it.</p>\n<p><strong>Example:</strong></p>\n<pre><code class=\"lang-java\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">DatabaseConnection</span> </span>{\n    <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">static</span> DatabaseConnection instance;\n\n    <span class=\"hljs-comment\">// Private constructor prevents direct instantiation</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">private</span> <span class=\"hljs-title\">DatabaseConnection</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-comment\">// Initialize connection</span>\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">synchronized</span> DatabaseConnection <span class=\"hljs-title\">getInstance</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">if</span> (instance == <span class=\"hljs-keyword\">null</span>) {\n            instance = <span class=\"hljs-keyword\">new</span> DatabaseConnection();\n        }\n        <span class=\"hljs-keyword\">return</span> instance;\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">query</span><span class=\"hljs-params\">(String sql)</span> </span>{\n        <span class=\"hljs-comment\">// Execute query using the single connection</span>\n    }\n}\n\n<span class=\"hljs-comment\">// Usage</span>\nDatabaseConnection connection = DatabaseConnection.getInstance();\nconnection.query(<span class=\"hljs-string\">\"SELECT * FROM users\"</span>);\n</code></pre>\n<p><strong>When to Use It:</strong> When having multiple instances would cause problems (like multiple file writers trying to access the same file) or waste resources.</p>\n<p><strong>When to Avoid It:</strong> When you need different instances with different configurations or when it introduces unnecessary global state.</p>\n<h3 id=\"heading-2-strategy-pattern\">2. Strategy Pattern</h3>\n<p><strong>Problem it Solves:</strong> You need different variants of an algorithm, but don't want to hardcode all the variants into a single class.</p>\n<p><strong>How it Works:</strong> Define a family of algorithms, encapsulate each one, and make them interchangeable.</p>\n<p><strong>Example:</strong></p>\n<pre><code class=\"lang-java\"><span class=\"hljs-comment\">// Strategy interface</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">interface</span> <span class=\"hljs-title\">PaymentStrategy</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pay</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> amount)</span></span>;\n}\n\n<span class=\"hljs-comment\">// Concrete strategies</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">CreditCardPayment</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">PaymentStrategy</span> </span>{\n    <span class=\"hljs-keyword\">private</span> String cardNumber;\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title\">CreditCardPayment</span><span class=\"hljs-params\">(String cardNumber)</span> </span>{\n        <span class=\"hljs-keyword\">this</span>.cardNumber = cardNumber;\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pay</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> amount)</span> </span>{\n        System.out.println(amount + <span class=\"hljs-string\">\" paid with credit card \"</span> + cardNumber);\n    }\n}\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">PayPalPayment</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">PaymentStrategy</span> </span>{\n    <span class=\"hljs-keyword\">private</span> String email;\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title\">PayPalPayment</span><span class=\"hljs-params\">(String email)</span> </span>{\n        <span class=\"hljs-keyword\">this</span>.email = email;\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pay</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> amount)</span> </span>{\n        System.out.println(amount + <span class=\"hljs-string\">\" paid using PayPal account \"</span> + email);\n    }\n}\n\n<span class=\"hljs-comment\">// Context</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ShoppingCart</span> </span>{\n    <span class=\"hljs-keyword\">private</span> PaymentStrategy paymentStrategy;\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">setPaymentStrategy</span><span class=\"hljs-params\">(PaymentStrategy paymentStrategy)</span> </span>{\n        <span class=\"hljs-keyword\">this</span>.paymentStrategy = paymentStrategy;\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">checkout</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> amount)</span> </span>{\n        paymentStrategy.pay(amount);\n    }\n}\n\n<span class=\"hljs-comment\">// Usage</span>\nShoppingCart cart = <span class=\"hljs-keyword\">new</span> ShoppingCart();\ncart.setPaymentStrategy(<span class=\"hljs-keyword\">new</span> CreditCardPayment(<span class=\"hljs-string\">\"1234-5678-9012-3456\"</span>));\ncart.checkout(<span class=\"hljs-number\">100</span>);\n\ncart.setPaymentStrategy(<span class=\"hljs-keyword\">new</span> PayPalPayment(<span class=\"hljs-string\">\"user@example.com\"</span>));\ncart.checkout(<span class=\"hljs-number\">200</span>);\n</code></pre>\n<p><strong>When to Use It:</strong> When you have multiple ways to perform an operation and need to switch between them dynamically.</p>\n<p><strong>When to Avoid It:</strong> When there's only one or two simple variants of an algorithm that aren't likely to change.</p>\n<h3 id=\"heading-3-observer-pattern\">3. Observer Pattern</h3>\n<p><strong>Problem it Solves:</strong> You need many objects to receive updates when another object changes.</p>\n<p><strong>How it Works:</strong> Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified.</p>\n<p><strong>Example:</strong></p>\n<pre><code class=\"lang-java\"><span class=\"hljs-comment\">// Subject interface</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">interface</span> <span class=\"hljs-title\">Subject</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">addObserver</span><span class=\"hljs-params\">(Observer observer)</span></span>;\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">removeObserver</span><span class=\"hljs-params\">(Observer observer)</span></span>;\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">notifyObservers</span><span class=\"hljs-params\">()</span></span>;\n}\n\n<span class=\"hljs-comment\">// Observer interface</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">interface</span> <span class=\"hljs-title\">Observer</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">update</span><span class=\"hljs-params\">(String message)</span></span>;\n}\n\n<span class=\"hljs-comment\">// Concrete subject</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">NewsAgency</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">Subject</span> </span>{\n    <span class=\"hljs-keyword\">private</span> List&lt;Observer&gt; observers = <span class=\"hljs-keyword\">new</span> ArrayList&lt;&gt;();\n    <span class=\"hljs-keyword\">private</span> String news;\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">addObserver</span><span class=\"hljs-params\">(Observer observer)</span> </span>{\n        observers.add(observer);\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">removeObserver</span><span class=\"hljs-params\">(Observer observer)</span> </span>{\n        observers.remove(observer);\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">notifyObservers</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">for</span> (Observer observer : observers) {\n            observer.update(news);\n        }\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">setNews</span><span class=\"hljs-params\">(String news)</span> </span>{\n        <span class=\"hljs-keyword\">this</span>.news = news;\n        notifyObservers();\n    }\n}\n\n<span class=\"hljs-comment\">// Concrete observer</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">NewsChannel</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">Observer</span> </span>{\n    <span class=\"hljs-keyword\">private</span> String name;\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title\">NewsChannel</span><span class=\"hljs-params\">(String name)</span> </span>{\n        <span class=\"hljs-keyword\">this</span>.name = name;\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">update</span><span class=\"hljs-params\">(String news)</span> </span>{\n        System.out.println(name + <span class=\"hljs-string\">\" received news: \"</span> + news);\n    }\n}\n\n<span class=\"hljs-comment\">// Usage</span>\nNewsAgency agency = <span class=\"hljs-keyword\">new</span> NewsAgency();\nNewsChannel channel1 = <span class=\"hljs-keyword\">new</span> NewsChannel(<span class=\"hljs-string\">\"Channel 1\"</span>);\nNewsChannel channel2 = <span class=\"hljs-keyword\">new</span> NewsChannel(<span class=\"hljs-string\">\"Channel 2\"</span>);\n\nagency.addObserver(channel1);\nagency.addObserver(channel2);\nagency.setNews(<span class=\"hljs-string\">\"Breaking news: Design patterns are awesome!\"</span>);\n</code></pre>\n<p><strong>When to Use It:</strong> When changes to one object may require changing other objects, and you don't know how many objects need to change.</p>\n<p><strong>When to Avoid It:</strong> When the notification logic becomes too complex or observers need to rely on notifications that might be missed (e.g., if they're temporarily disconnected).</p>\n<h3 id=\"heading-4-factory-method-pattern\">4. Factory Method Pattern</h3>\n<p><strong>Problem it Solves:</strong> You need to create objects, but don't know exactly what type of objects you'll need to create until runtime.</p>\n<p><strong>How it Works:</strong> Define an interface for creating an object, but let subclasses decide which class to instantiate.</p>\n<p><strong>Example:</strong></p>\n<pre><code class=\"lang-java\"><span class=\"hljs-comment\">// Product interface</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">interface</span> <span class=\"hljs-title\">Vehicle</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">drive</span><span class=\"hljs-params\">()</span></span>;\n}\n\n<span class=\"hljs-comment\">// Concrete products</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Car</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">Vehicle</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">drive</span><span class=\"hljs-params\">()</span> </span>{\n        System.out.println(<span class=\"hljs-string\">\"Driving a car...\"</span>);\n    }\n}\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Motorcycle</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">Vehicle</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">drive</span><span class=\"hljs-params\">()</span> </span>{\n        System.out.println(<span class=\"hljs-string\">\"Riding a motorcycle...\"</span>);\n    }\n}\n\n<span class=\"hljs-comment\">// Creator abstract class</span>\n<span class=\"hljs-keyword\">abstract</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">VehicleFactory</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">abstract</span> Vehicle <span class=\"hljs-title\">createVehicle</span><span class=\"hljs-params\">()</span></span>;\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">deliverVehicle</span><span class=\"hljs-params\">()</span> </span>{\n        Vehicle vehicle = createVehicle();\n        System.out.println(<span class=\"hljs-string\">\"Delivering the vehicle...\"</span>);\n        vehicle.drive();\n    }\n}\n\n<span class=\"hljs-comment\">// Concrete creators</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">CarFactory</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">VehicleFactory</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> Vehicle <span class=\"hljs-title\">createVehicle</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> Car();\n    }\n}\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">MotorcycleFactory</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">VehicleFactory</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> Vehicle <span class=\"hljs-title\">createVehicle</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">new</span> Motorcycle();\n    }\n}\n\n<span class=\"hljs-comment\">// Usage</span>\nVehicleFactory factory = <span class=\"hljs-keyword\">new</span> CarFactory();\nfactory.deliverVehicle();\n\nfactory = <span class=\"hljs-keyword\">new</span> MotorcycleFactory();\nfactory.deliverVehicle();\n</code></pre>\n<p><strong>When to Use It:</strong> When a class can't anticipate the type of objects it must create, or when a class wants its subclasses to specify the objects it creates.</p>\n<p><strong>When to Avoid It:</strong> When adding new products requires changing the factory interface, which violates the Open/Closed Principle.</p>\n<h3 id=\"heading-5-decorator-pattern\">5. Decorator Pattern</h3>\n<p><strong>Problem it Solves:</strong> You need to add responsibilities to objects dynamically without affecting other objects of the same class.</p>\n<p><strong>How it Works:</strong> Attach additional responsibilities to an object dynamically by placing it inside special wrapper objects.</p>\n<p><strong>Example:</strong></p>\n<pre><code class=\"lang-java\"><span class=\"hljs-comment\">// Component interface</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">interface</span> <span class=\"hljs-title\">Coffee</span> </span>{\n    <span class=\"hljs-function\">String <span class=\"hljs-title\">getDescription</span><span class=\"hljs-params\">()</span></span>;\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">double</span> <span class=\"hljs-title\">cost</span><span class=\"hljs-params\">()</span></span>;\n}\n\n<span class=\"hljs-comment\">// Concrete component</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">SimpleCoffee</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">Coffee</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> String <span class=\"hljs-title\">getDescription</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">\"Simple coffee\"</span>;\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">double</span> <span class=\"hljs-title\">cost</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1.0</span>;\n    }\n}\n\n<span class=\"hljs-comment\">// Decorator abstract class</span>\n<span class=\"hljs-keyword\">abstract</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">CoffeeDecorator</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">Coffee</span> </span>{\n    <span class=\"hljs-keyword\">protected</span> Coffee decoratedCoffee;\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title\">CoffeeDecorator</span><span class=\"hljs-params\">(Coffee coffee)</span> </span>{\n        <span class=\"hljs-keyword\">this</span>.decoratedCoffee = coffee;\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> String <span class=\"hljs-title\">getDescription</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">return</span> decoratedCoffee.getDescription();\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">double</span> <span class=\"hljs-title\">cost</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">return</span> decoratedCoffee.cost();\n    }\n}\n\n<span class=\"hljs-comment\">// Concrete decorators</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">MilkDecorator</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">CoffeeDecorator</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title\">MilkDecorator</span><span class=\"hljs-params\">(Coffee coffee)</span> </span>{\n        <span class=\"hljs-keyword\">super</span>(coffee);\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> String <span class=\"hljs-title\">getDescription</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">return</span> decoratedCoffee.getDescription() + <span class=\"hljs-string\">\", milk\"</span>;\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">double</span> <span class=\"hljs-title\">cost</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">return</span> decoratedCoffee.cost() + <span class=\"hljs-number\">0.5</span>;\n    }\n}\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">SugarDecorator</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">CoffeeDecorator</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title\">SugarDecorator</span><span class=\"hljs-params\">(Coffee coffee)</span> </span>{\n        <span class=\"hljs-keyword\">super</span>(coffee);\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> String <span class=\"hljs-title\">getDescription</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">return</span> decoratedCoffee.getDescription() + <span class=\"hljs-string\">\", sugar\"</span>;\n    }\n\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">double</span> <span class=\"hljs-title\">cost</span><span class=\"hljs-params\">()</span> </span>{\n        <span class=\"hljs-keyword\">return</span> decoratedCoffee.cost() + <span class=\"hljs-number\">0.2</span>;\n    }\n}\n\n<span class=\"hljs-comment\">// Usage</span>\nCoffee coffee = <span class=\"hljs-keyword\">new</span> SimpleCoffee();\nSystem.out.println(coffee.getDescription() + <span class=\"hljs-string\">\": $\"</span> + coffee.cost());\n\ncoffee = <span class=\"hljs-keyword\">new</span> MilkDecorator(coffee);\nSystem.out.println(coffee.getDescription() + <span class=\"hljs-string\">\": $\"</span> + coffee.cost());\n\ncoffee = <span class=\"hljs-keyword\">new</span> SugarDecorator(coffee);\nSystem.out.println(coffee.getDescription() + <span class=\"hljs-string\">\": $\"</span> + coffee.cost());\n</code></pre>\n<p><strong>When to Use It:</strong> When you need to add responsibilities to objects dynamically and transparently, without affecting other objects.</p>\n<p><strong>When to Avoid It:</strong> When the component hierarchy becomes too complex with many layers of decorators.</p>\n<h2 id=\"heading-design-patterns-and-code-quality\">Design Patterns and Code Quality</h2>\n<p>Beyond solving specific problems, design patterns contribute to overall code quality in several ways:</p>\n<h3 id=\"heading-they-promote-the-solid-principles\">They Promote the SOLID Principles</h3>\n<p>Many design patterns naturally align with the SOLID principles of object-oriented design:</p>\n<ul>\n<li><p><strong>Single Responsibility Principle:</strong> Patterns like Decorator and Strategy help separate different responsibilities.</p>\n</li>\n<li><p><strong>Open/Closed Principle:</strong> Patterns like Factory Method allow for extension without modification.</p>\n</li>\n<li><p><strong>Liskov Substitution Principle:</strong> Patterns ensure that subclasses can be used in place of their parent classes.</p>\n</li>\n<li><p><strong>Interface Segregation Principle:</strong> Patterns like Adapter help create focused interfaces.</p>\n</li>\n<li><p><strong>Dependency Inversion Principle:</strong> Patterns like Dependency Injection promote depending on abstractions.</p>\n</li>\n</ul>\n<h3 id=\"heading-they-reduce-code-duplication\">They Reduce Code Duplication</h3>\n<p>By providing standard solutions to common problems, patterns help avoid reinventing solutions, reducing duplicated code across projects.</p>\n<h3 id=\"heading-they-improve-code-maintainability\">They Improve Code Maintainability</h3>\n<p>Well-implemented patterns make code more modular and easier to understand, which simplifies maintenance and updates.</p>\n<h2 id=\"heading-the-journey-from-pattern-user-to-pattern-creator\">The Journey From Pattern User to Pattern Creator</h2>\n<p>As you grow as a developer, your relationship with design patterns will evolve:</p>\n<ol>\n<li><p><strong>Pattern Recognizer:</strong> First, you'll learn to identify when existing patterns apply to your problems.</p>\n</li>\n<li><p><strong>Pattern Implementer:</strong> Then, you'll become comfortable implementing standard patterns in your code.</p>\n</li>\n<li><p><strong>Pattern Adapter:</strong> Next, you'll adapt patterns to fit your specific needs, combining and modifying them as necessary.</p>\n</li>\n<li><p><strong>Pattern Creator:</strong> Eventually, you might even develop your own patterns to address unique challenges in your domain.</p>\n</li>\n</ol>\n<h2 id=\"heading-patterns-as-a-growth-investment\">Patterns as a Growth Investment</h2>\n<p>Learning design patterns is one of the best investments you can make in your development career. They provide immediate benefits in code quality and long-term benefits in thinking about software architecture.</p>\n<p>Start small, focus on understanding the problems each pattern solves, and gradually incorporate them into your projects. Over time, you'll find yourself naturally reaching for the right pattern when faced with a familiar challenge.</p>\n<p>Remember, the goal isn't to use patterns for their own sake, but to solve problems efficiently and create maintainable code. When used appropriately, design patterns become powerful tools that elevate your work from merely functional to truly professional.</p>\n<p>Happy pattern hunting!</p>\n<h2 id=\"heading-additional-resources-for-learning-design-patterns\">Additional Resources for Learning Design Patterns</h2>\n<ul>\n<li><p><strong>Books:</strong></p>\n<ul>\n<li><p>\"Head First Design Patterns\" by Eric Freeman and Elisabeth Robson (beginner-friendly)</p>\n</li>\n<li><p>\"Design Patterns Explained\" by Alan Shalloway and James Trott</p>\n</li>\n<li><p>The original \"Design Patterns\" by the Gang of Four (more advanced)</p>\n</li>\n</ul>\n</li>\n<li><p><strong>Online Resources:</strong></p>\n<ul>\n<li><p><a target=\"_blank\" href=\"http://Refactoring.Guru\">Refactoring.Guru</a> (visual explanations with examples in multiple languages)</p>\n</li>\n<li><p><a target=\"_blank\" href=\"http://SourceMaking.com\">SourceMaking.com</a> (pattern descriptions with real-world examples)</p>\n</li>\n<li><p>Design Patterns in the Java Tutorials (Oracle's official examples)</p>\n</li>\n</ul>\n</li>\n<li><p><strong>Practice Projects:</strong></p>\n<ul>\n<li><p>Try implementing a simple text editor with undo/redo using the Command pattern</p>\n</li>\n<li><p>Build a notification system using the Observer pattern</p>\n</li>\n<li><p>Create a document converter that can output different formats using the Strategy pattern</p>\n</li>\n</ul>\n</li>\n</ul>\n","contentMarkdown":"Imagine you're building furniture. You could design each piece from scratch, figuring out how legs connect to tabletops or how drawers slide in and out. Or, you could use tried-and-tested blueprints that woodworkers have refined over generations.\n\nIn software development, design patterns are these blueprints. They represent elegant solutions to common coding problems that developers have encountered repeatedly over decades. And whether you're just starting your coding journey or you're a seasoned developer, understanding these patterns can dramatically improve your programming skills.\n\n## What Are Design Patterns, Really?\n\nAt their core, design patterns are reusable solutions to problems that occur frequently in software design. Think of them as templates that can be applied to different situations, saving you from reinventing the wheel each time you face a familiar challenge.\n\nThe concept was popularized in 1994 when four authors (often called the \"Gang of Four\" or GoF) published the book \"Design Patterns: Elements of Reusable Object-Oriented Software.\" This landmark text identified 23 patterns that addressed common problems in object-oriented programming.\n\n## The Three Categories of Design Patterns\n\nDesign patterns generally fall into three categories, each addressing a different aspect of software design:\n\n### 1\\. Creational Patterns\n\nThese patterns deal with object creation mechanisms, trying to create objects in a manner suitable to the situation.\n\n**Example: The Factory Pattern**\n\nImagine you're developing a game with different character types (warrior, mage, archer). Instead of writing code like this everywhere:\n\n```java\nCharacter character;\nif (type.equals(\"warrior\")) {\n    character = new Warrior();\n} else if(type.equals(\"mage\")) {\n    character = new Mage();\n} else if(type.equals(\"archer\")) {\n    character = new Archer();\n}\n```\n\nYou could use a Factory pattern:\n\n```java\nCharacter character = CharacterFactory.createCharacter(type);\n```\n\nThe factory handles the complex creation logic, making your code cleaner and more maintainable. If you add a new character type later, you only need to modify the factory, not every place characters are created.\n\n### 2\\. Structural Patterns\n\nThese patterns focus on how classes and objects are composed to form larger structures.\n\n**Example: The Adapter Pattern**\n\nImagine you have a new library that tracks user analytics, but its interface doesn't match what your application expects:\n\n```java\n// Your application expects:\ninterface OldAnalytics {\n    void trackEvent(String name, Map<String, String> data);\n}\n\n// But the new library uses:\nclass NewAnalyticsLibrary {\n    void logActivity(String activityName, JSONObject attributes) {\n        // Implementation\n    }\n}\n```\n\nInstead of changing your entire codebase, you can create an adapter:\n\n```java\nclass AnalyticsAdapter implements OldAnalytics {\n    private NewAnalyticsLibrary newAnalytics = new NewAnalyticsLibrary();\n    \n    public void trackEvent(String name, Map<String, String> data) {\n        JSONObject json = convertMapToJson(data);\n        newAnalytics.logActivity(name, json);\n    }\n    \n    private JSONObject convertMapToJson(Map<String, String> data) {\n        // Conversion logic\n        return new JSONObject(data);\n    }\n}\n```\n\nNow your existing code works with the new library without modifications!\n\n### 3\\. Behavioral Patterns\n\nThese patterns are concerned with algorithms and the assignment of responsibilities between objects.\n\n**Example: The Observer Pattern**\n\nThink of how social media works: when someone posts an update, all their followers get notified. This is the Observer pattern in action!\n\n```java\nclass Post {\n    private List<User> followers = new ArrayList<>();\n    \n    public void addFollower(User user) {\n        followers.add(user);\n    }\n    \n    public void createUpdate(String content) {\n        // Create the update\n        notifyFollowers();\n    }\n    \n    private void notifyFollowers() {\n        for(User follower : followers) {\n            follower.notify(\"New post available!\");\n        }\n    }\n}\n```\n\nThis pattern creates a one-to-many dependency where multiple observers (followers) are notified when the subject (post creator) changes state.\n\n## Why Should Beginners Care About Design Patterns?\n\nIf you're new to programming, you might wonder if design patterns are relevant to you yet. The answer is a resounding yes, for several important reasons:\n\n### 1\\. They Teach You How to Think About Code Structure\n\nLearning design patterns early helps develop an architectural mindset. Instead of focusing solely on making your code work, you start considering how it's organized and how different components interact.\n\n### 2\\. They Help You Write More Professional Code Faster\n\nWhen you recognize common problems, you can apply established solutions rather than struggling through trial and error. This accelerates your development process and results in more robust solutions.\n\n### 3\\. They Improve Collaboration\n\nProgramming is rarely a solo activity. Using established patterns creates a shared vocabulary with other developers. When you mention using a \"Factory Method\" or \"Observer Pattern,\" other developers immediately understand your approach.\n\n### 4\\. They Prepare You for Framework Learning\n\nModern frameworks like React, Angular, and Spring incorporate many design patterns. Understanding these patterns makes learning frameworks easier because you recognize the underlying concepts.\n\n### 5\\. They Prevent Common Mistakes\n\nMany design patterns evolved specifically to address problems that repeatedly caused bugs or maintenance headaches. Learning these patterns helps you avoid these pitfalls from the start.\n\n## Design Patterns in Real-World Applications\n\nLet's look at some examples of how design patterns show up in technologies you might already be using:\n\n### In Web Development\n\n**React's Component Model:** React uses the Composite pattern, allowing you to build complex UIs from simple components that can contain other components.\n\n**Event Handling in JavaScript:** The Observer pattern is used extensively in event-driven programming, where event listeners \"observe\" elements and respond to user interactions.\n\n### In Mobile Apps\n\n**iOS's Delegation Pattern:** This is a variation of the Observer pattern where objects delegate certain responsibilities to other objects.\n\n**Android's Adapter Views:** These use the Adapter pattern to convert data sources into views that can be displayed in lists.\n\n### In Everyday Applications\n\n**Word Processors:** The Command pattern powers features like undo/redo, where each action is encapsulated as an object that can be executed, tracked, and reversed.\n\n**Video Games:** The State pattern manages character behaviors, allowing characters to smoothly transition between actions like walking, running, or attacking.\n\n## Common Misunderstandings About Design Patterns\n\nAs you learn about design patterns, be aware of these common misconceptions:\n\n### Misunderstanding #1: \"Design Patterns Are Too Complex for Beginners\"\n\n**Reality:** While some patterns have complex implementations, the concepts behind them are accessible to beginners. Start with simpler patterns like Factory, Observer, and Strategy.\n\n### Misunderstanding #2: \"I Should Use Design Patterns Everywhere\"\n\n**Reality:** Design patterns are tools, not rules. They should be applied when they solve a specific problem, not forced into every situation. Sometimes simple, straightforward code is better.\n\n### Misunderstanding #3: \"Design Patterns Are Outdated\"\n\n**Reality:** While some specific implementations may become less relevant as languages evolve, the core principles behind design patterns remain valuable. Modern languages and frameworks may offer built-in solutions for some patterns, but understanding the patterns helps you use these features more effectively.\n\n## How to Start Learning Design Patterns\n\nReady to dive into design patterns? Here's a beginner-friendly approach:\n\n### 1\\. Start with Real Problems\n\nRather than trying to memorize all 23 GoF patterns at once, focus on patterns that solve problems you've encountered. This makes the learning more relevant and memorable.\n\n### 2\\. Learn Through Examples\n\nLook for concrete examples of patterns in languages you're familiar with. Many online resources provide code samples in different programming languages.\n\n### 3\\. Practice Implementation\n\nTry implementing a simple version of each pattern you learn. This hands-on approach helps solidify your understanding.\n\n### 4\\. Refactor Existing Code\n\nTake some code you've already written and refactor it using a design pattern. This exercise helps you see the benefits and trade-offs directly.\n\n### 5\\. Learn Patterns in Groups\n\nStudy related patterns together to understand their similarities and differences. For example, learn Factory Method, Abstract Factory, and Builder together to understand different approaches to object creation.\n\n## A Deeper Look at Five Essential Patterns for Beginners\n\nLet's explore five patterns that are particularly valuable for beginners to understand:\n\n### 1\\. Singleton Pattern\n\n**Problem it Solves:** Sometimes you need exactly one instance of a class that is accessible globally, like a configuration manager or connection pool.\n\n**How it Works:** The pattern ensures a class has only one instance and provides a global point to access it.\n\n**Example:**\n\n```java\npublic class DatabaseConnection {\n    private static DatabaseConnection instance;\n    \n    // Private constructor prevents direct instantiation\n    private DatabaseConnection() {\n        // Initialize connection\n    }\n    \n    public static synchronized DatabaseConnection getInstance() {\n        if (instance == null) {\n            instance = new DatabaseConnection();\n        }\n        return instance;\n    }\n    \n    public void query(String sql) {\n        // Execute query using the single connection\n    }\n}\n\n// Usage\nDatabaseConnection connection = DatabaseConnection.getInstance();\nconnection.query(\"SELECT * FROM users\");\n```\n\n**When to Use It:** When having multiple instances would cause problems (like multiple file writers trying to access the same file) or waste resources.\n\n**When to Avoid It:** When you need different instances with different configurations or when it introduces unnecessary global state.\n\n### 2\\. Strategy Pattern\n\n**Problem it Solves:** You need different variants of an algorithm, but don't want to hardcode all the variants into a single class.\n\n**How it Works:** Define a family of algorithms, encapsulate each one, and make them interchangeable.\n\n**Example:**\n\n```java\n// Strategy interface\ninterface PaymentStrategy {\n    void pay(int amount);\n}\n\n// Concrete strategies\nclass CreditCardPayment implements PaymentStrategy {\n    private String cardNumber;\n    \n    public CreditCardPayment(String cardNumber) {\n        this.cardNumber = cardNumber;\n    }\n    \n    public void pay(int amount) {\n        System.out.println(amount + \" paid with credit card \" + cardNumber);\n    }\n}\n\nclass PayPalPayment implements PaymentStrategy {\n    private String email;\n    \n    public PayPalPayment(String email) {\n        this.email = email;\n    }\n    \n    public void pay(int amount) {\n        System.out.println(amount + \" paid using PayPal account \" + email);\n    }\n}\n\n// Context\nclass ShoppingCart {\n    private PaymentStrategy paymentStrategy;\n    \n    public void setPaymentStrategy(PaymentStrategy paymentStrategy) {\n        this.paymentStrategy = paymentStrategy;\n    }\n    \n    public void checkout(int amount) {\n        paymentStrategy.pay(amount);\n    }\n}\n\n// Usage\nShoppingCart cart = new ShoppingCart();\ncart.setPaymentStrategy(new CreditCardPayment(\"1234-5678-9012-3456\"));\ncart.checkout(100);\n\ncart.setPaymentStrategy(new PayPalPayment(\"user@example.com\"));\ncart.checkout(200);\n```\n\n**When to Use It:** When you have multiple ways to perform an operation and need to switch between them dynamically.\n\n**When to Avoid It:** When there's only one or two simple variants of an algorithm that aren't likely to change.\n\n### 3\\. Observer Pattern\n\n**Problem it Solves:** You need many objects to receive updates when another object changes.\n\n**How it Works:** Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified.\n\n**Example:**\n\n```java\n// Subject interface\ninterface Subject {\n    void addObserver(Observer observer);\n    void removeObserver(Observer observer);\n    void notifyObservers();\n}\n\n// Observer interface\ninterface Observer {\n    void update(String message);\n}\n\n// Concrete subject\nclass NewsAgency implements Subject {\n    private List<Observer> observers = new ArrayList<>();\n    private String news;\n    \n    public void addObserver(Observer observer) {\n        observers.add(observer);\n    }\n    \n    public void removeObserver(Observer observer) {\n        observers.remove(observer);\n    }\n    \n    public void notifyObservers() {\n        for (Observer observer : observers) {\n            observer.update(news);\n        }\n    }\n    \n    public void setNews(String news) {\n        this.news = news;\n        notifyObservers();\n    }\n}\n\n// Concrete observer\nclass NewsChannel implements Observer {\n    private String name;\n    \n    public NewsChannel(String name) {\n        this.name = name;\n    }\n    \n    public void update(String news) {\n        System.out.println(name + \" received news: \" + news);\n    }\n}\n\n// Usage\nNewsAgency agency = new NewsAgency();\nNewsChannel channel1 = new NewsChannel(\"Channel 1\");\nNewsChannel channel2 = new NewsChannel(\"Channel 2\");\n\nagency.addObserver(channel1);\nagency.addObserver(channel2);\nagency.setNews(\"Breaking news: Design patterns are awesome!\");\n```\n\n**When to Use It:** When changes to one object may require changing other objects, and you don't know how many objects need to change.\n\n**When to Avoid It:** When the notification logic becomes too complex or observers need to rely on notifications that might be missed (e.g., if they're temporarily disconnected).\n\n### 4\\. Factory Method Pattern\n\n**Problem it Solves:** You need to create objects, but don't know exactly what type of objects you'll need to create until runtime.\n\n**How it Works:** Define an interface for creating an object, but let subclasses decide which class to instantiate.\n\n**Example:**\n\n```java\n// Product interface\ninterface Vehicle {\n    void drive();\n}\n\n// Concrete products\nclass Car implements Vehicle {\n    public void drive() {\n        System.out.println(\"Driving a car...\");\n    }\n}\n\nclass Motorcycle implements Vehicle {\n    public void drive() {\n        System.out.println(\"Riding a motorcycle...\");\n    }\n}\n\n// Creator abstract class\nabstract class VehicleFactory {\n    public abstract Vehicle createVehicle();\n    \n    public void deliverVehicle() {\n        Vehicle vehicle = createVehicle();\n        System.out.println(\"Delivering the vehicle...\");\n        vehicle.drive();\n    }\n}\n\n// Concrete creators\nclass CarFactory extends VehicleFactory {\n    public Vehicle createVehicle() {\n        return new Car();\n    }\n}\n\nclass MotorcycleFactory extends VehicleFactory {\n    public Vehicle createVehicle() {\n        return new Motorcycle();\n    }\n}\n\n// Usage\nVehicleFactory factory = new CarFactory();\nfactory.deliverVehicle();\n\nfactory = new MotorcycleFactory();\nfactory.deliverVehicle();\n```\n\n**When to Use It:** When a class can't anticipate the type of objects it must create, or when a class wants its subclasses to specify the objects it creates.\n\n**When to Avoid It:** When adding new products requires changing the factory interface, which violates the Open/Closed Principle.\n\n### 5\\. Decorator Pattern\n\n**Problem it Solves:** You need to add responsibilities to objects dynamically without affecting other objects of the same class.\n\n**How it Works:** Attach additional responsibilities to an object dynamically by placing it inside special wrapper objects.\n\n**Example:**\n\n```java\n// Component interface\ninterface Coffee {\n    String getDescription();\n    double cost();\n}\n\n// Concrete component\nclass SimpleCoffee implements Coffee {\n    public String getDescription() {\n        return \"Simple coffee\";\n    }\n    \n    public double cost() {\n        return 1.0;\n    }\n}\n\n// Decorator abstract class\nabstract class CoffeeDecorator implements Coffee {\n    protected Coffee decoratedCoffee;\n    \n    public CoffeeDecorator(Coffee coffee) {\n        this.decoratedCoffee = coffee;\n    }\n    \n    public String getDescription() {\n        return decoratedCoffee.getDescription();\n    }\n    \n    public double cost() {\n        return decoratedCoffee.cost();\n    }\n}\n\n// Concrete decorators\nclass MilkDecorator extends CoffeeDecorator {\n    public MilkDecorator(Coffee coffee) {\n        super(coffee);\n    }\n    \n    public String getDescription() {\n        return decoratedCoffee.getDescription() + \", milk\";\n    }\n    \n    public double cost() {\n        return decoratedCoffee.cost() + 0.5;\n    }\n}\n\nclass SugarDecorator extends CoffeeDecorator {\n    public SugarDecorator(Coffee coffee) {\n        super(coffee);\n    }\n    \n    public String getDescription() {\n        return decoratedCoffee.getDescription() + \", sugar\";\n    }\n    \n    public double cost() {\n        return decoratedCoffee.cost() + 0.2;\n    }\n}\n\n// Usage\nCoffee coffee = new SimpleCoffee();\nSystem.out.println(coffee.getDescription() + \": $\" + coffee.cost());\n\ncoffee = new MilkDecorator(coffee);\nSystem.out.println(coffee.getDescription() + \": $\" + coffee.cost());\n\ncoffee = new SugarDecorator(coffee);\nSystem.out.println(coffee.getDescription() + \": $\" + coffee.cost());\n```\n\n**When to Use It:** When you need to add responsibilities to objects dynamically and transparently, without affecting other objects.\n\n**When to Avoid It:** When the component hierarchy becomes too complex with many layers of decorators.\n\n## Design Patterns and Code Quality\n\nBeyond solving specific problems, design patterns contribute to overall code quality in several ways:\n\n### They Promote the SOLID Principles\n\nMany design patterns naturally align with the SOLID principles of object-oriented design:\n\n* **Single Responsibility Principle:** Patterns like Decorator and Strategy help separate different responsibilities.\n    \n* **Open/Closed Principle:** Patterns like Factory Method allow for extension without modification.\n    \n* **Liskov Substitution Principle:** Patterns ensure that subclasses can be used in place of their parent classes.\n    \n* **Interface Segregation Principle:** Patterns like Adapter help create focused interfaces.\n    \n* **Dependency Inversion Principle:** Patterns like Dependency Injection promote depending on abstractions.\n    \n\n### They Reduce Code Duplication\n\nBy providing standard solutions to common problems, patterns help avoid reinventing solutions, reducing duplicated code across projects.\n\n### They Improve Code Maintainability\n\nWell-implemented patterns make code more modular and easier to understand, which simplifies maintenance and updates.\n\n## The Journey From Pattern User to Pattern Creator\n\nAs you grow as a developer, your relationship with design patterns will evolve:\n\n1. **Pattern Recognizer:** First, you'll learn to identify when existing patterns apply to your problems.\n    \n2. **Pattern Implementer:** Then, you'll become comfortable implementing standard patterns in your code.\n    \n3. **Pattern Adapter:** Next, you'll adapt patterns to fit your specific needs, combining and modifying them as necessary.\n    \n4. **Pattern Creator:** Eventually, you might even develop your own patterns to address unique challenges in your domain.\n    \n\n## Patterns as a Growth Investment\n\nLearning design patterns is one of the best investments you can make in your development career. They provide immediate benefits in code quality and long-term benefits in thinking about software architecture.\n\nStart small, focus on understanding the problems each pattern solves, and gradually incorporate them into your projects. Over time, you'll find yourself naturally reaching for the right pattern when faced with a familiar challenge.\n\nRemember, the goal isn't to use patterns for their own sake, but to solve problems efficiently and create maintainable code. When used appropriately, design patterns become powerful tools that elevate your work from merely functional to truly professional.\n\nHappy pattern hunting!\n\n## Additional Resources for Learning Design Patterns\n\n* **Books:**\n    \n    * \"Head First Design Patterns\" by Eric Freeman and Elisabeth Robson (beginner-friendly)\n        \n    * \"Design Patterns Explained\" by Alan Shalloway and James Trott\n        \n    * The original \"Design Patterns\" by the Gang of Four (more advanced)\n        \n* **Online Resources:**\n    \n    * [Refactoring.Guru](http://Refactoring.Guru) (visual explanations with examples in multiple languages)\n        \n    * [SourceMaking.com](http://SourceMaking.com) (pattern descriptions with real-world examples)\n        \n    * Design Patterns in the Java Tutorials (Oracle's official examples)\n        \n* **Practice Projects:**\n    \n    * Try implementing a simple text editor with undo/redo using the Command pattern\n        \n    * Build a notification system using the Observer pattern\n        \n    * Create a document converter that can output different formats using the Strategy pattern","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1741414255515/ae42c76a-bc09-4da0-9a83-90567f06aa5b.webp","brief":"Imagine you're building furniture. You could design each piece from scratch, figuring out how legs connect to tabletops or how drawers slide in and out. Or, you could use tried-and-tested blueprints that woodworkers have refined over generations.\nIn ...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":false,"readTime":13,"draft":"67cbc50e8942deccc35d5bcd","tags":[],"publication":"5cdd04921a7cb8b20267646b","isNewsletterActivated":true,"coAuthors":[],"dateUpdated":"2025-03-08T20:40:39.585Z","pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"67cbf99efca581965cde6fca"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"_id":"66b29d4c63629cc69724f054","createdAt":"2024-08-06T22:01:48.091Z","updatedAt":"2025-03-08T20:40:39.611Z","views":116,"isActive":true,"hasLatex":false,"popularity":6977.1224,"discussionScore":0,"enableToc":true,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"disableComments":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"slugOverridden":false,"tweetOptions":{"enabled":false},"title":"Refactor a tightly coupled codebase by following SOLID Principles","subtitle":"Transforming an Old Codebase for Better Modularity and Security with SOLID Principles and Design patterns","cuid":"clziytmii000409l6e00j4vlr","dateAdded":"2024-08-06T22:01:48.090Z","isCoverAttributionHidden":false,"coverImageAttribution":"","coverImagePhotographer":"","stickCoverToBottom":true,"slug":"refactor-a-tightly-coupled-codebase-by-following-solid-principles","toc":[[{"id":"b0b931ec-9095-46e7-b863-3dd440f5da93","level":2,"previousLevel":null,"parentId":null,"slug":"background","title":"Background"}],[{"id":"f86671c5-4641-4fc0-99ce-f48c7f41d577","level":2,"previousLevel":2,"parentId":null,"slug":"inspiration","title":"Inspiration"}],[{"id":"71fd24e4-c0f7-4909-917c-df5a1da5ee6b","level":2,"previousLevel":2,"parentId":null,"slug":"breakdown","title":"Breakdown"}],[{"id":"e92ff691-3d30-495f-b420-e99deb193bd7","level":2,"previousLevel":2,"parentId":null,"slug":"request-package","title":"Request Package"}],[{"id":"818cfa36-925d-4aa6-a702-59e49639fa6e","level":3,"previousLevel":2,"parentId":"e92ff691-3d30-495f-b420-e99deb193bd7","slug":"method","title":"Method"}],[{"id":"c5891468-038b-43be-a382-2a31a8a04c35","level":3,"previousLevel":3,"parentId":"e92ff691-3d30-495f-b420-e99deb193bd7","slug":"body","title":"Body"}],[{"id":"bc763bac-13b9-4bc6-886f-22b11b9c8c5b","level":3,"previousLevel":3,"parentId":"e92ff691-3d30-495f-b420-e99deb193bd7","slug":"authentication","title":"Authentication"}],[{"id":"b6c17e45-db29-4a97-b8a9-180e36fa957b","level":3,"previousLevel":3,"parentId":"e92ff691-3d30-495f-b420-e99deb193bd7","slug":"api-request","title":"API Request"}],[{"id":"784e9a2b-8cf4-48a5-b122-1e9af7e04b7c","level":3,"previousLevel":3,"parentId":"e92ff691-3d30-495f-b420-e99deb193bd7","slug":"api-request-builder","title":"API Request Builder"}],[{"id":"eec9bd89-1605-4d89-b879-f5f13b907259","level":3,"previousLevel":3,"parentId":"e92ff691-3d30-495f-b420-e99deb193bd7","slug":"api-response","title":"API Response"}],[{"id":"fdec6d7d-df27-4f74-80c2-b99bc7da1e77","level":2,"previousLevel":3,"parentId":null,"slug":"client","title":"Client"}],[{"id":"6efcae98-b5d4-4461-9ea9-a67c3ab04507","level":3,"previousLevel":2,"parentId":"fdec6d7d-df27-4f74-80c2-b99bc7da1e77","slug":"client-library","title":"Client Library"}],[{"id":"ad7c5f92-6661-4846-bd88-dfbdc8de8003","level":3,"previousLevel":3,"parentId":"fdec6d7d-df27-4f74-80c2-b99bc7da1e77","slug":"authentication-wrapper","title":"Authentication Wrapper"}],[{"id":"b1d04944-c579-4fe3-8276-559ccb3cd62b","level":3,"previousLevel":3,"parentId":"fdec6d7d-df27-4f74-80c2-b99bc7da1e77","slug":"body-parser","title":"Body Parser"}],[{"id":"23fa9bca-2592-4922-8fd1-61e00ad14b87","level":3,"previousLevel":3,"parentId":"fdec6d7d-df27-4f74-80c2-b99bc7da1e77","slug":"client-implementation","title":"Client Implementation"}],[{"id":"ab265c12-3a8d-4f3c-99c5-960bb94207fc","level":2,"previousLevel":3,"parentId":null,"slug":"ensure-stability-of-api-package","title":"Ensure stability of API package"}],[{"id":"5cfb7da8-80ad-4559-848c-6c1e7d398e3c","level":2,"previousLevel":2,"parentId":null,"slug":"using-the-client","title":"Using the client"}],[{"id":"713cb89a-2d67-4ed3-8ddc-f04d17125a93","level":2,"previousLevel":2,"parentId":null,"slug":"adherence-to-solid-principles","title":"Adherence to SOLID Principles"}],[{"id":"7cfdf042-b8fe-46e8-8c9b-ebfbe5aae51d","level":3,"previousLevel":2,"parentId":"713cb89a-2d67-4ed3-8ddc-f04d17125a93","slug":"single-responsibility-principle-srp","title":"Single Responsibility Principle (SRP)"}],[{"id":"b14120ae-3179-465b-a114-e62965c4f3c9","level":3,"previousLevel":3,"parentId":"713cb89a-2d67-4ed3-8ddc-f04d17125a93","slug":"openclosed-principle-ocp","title":"Open/Closed Principle (OCP)"}],[{"id":"a487cf00-c948-4785-a07f-4c911be5adfc","level":3,"previousLevel":3,"parentId":"713cb89a-2d67-4ed3-8ddc-f04d17125a93","slug":"liskov-substitution-principle-lsp","title":"Liskov Substitution Principle (LSP)"}],[{"id":"65eb7a68-1d97-48e3-8ddd-41af6af78ce8","level":3,"previousLevel":3,"parentId":"713cb89a-2d67-4ed3-8ddc-f04d17125a93","slug":"interface-segregation-principle-isp","title":"Interface Segregation Principle (ISP)"}],[{"id":"3333be84-cd7e-4b18-bd9a-98eb24dc5f89","level":3,"previousLevel":3,"parentId":"713cb89a-2d67-4ed3-8ddc-f04d17125a93","slug":"dependency-inversion-principle-dip","title":"Dependency Inversion Principle (DIP)"}],[{"id":"2d7f3131-15f7-4cd8-b21e-01c4fb24f27e","level":2,"previousLevel":3,"parentId":null,"slug":"conclusion","title":"Conclusion"}]],"content":"<p>We've been developing an AI-enabled data engineering product at our company, using Scala as the core programming language. We also utilize Scala-related frameworks like Spark and Play to power various components. Recently, we conducted a vulnerability scan on our applications and discovered numerous security issues. The root cause was that we hadn't updated our libraries in over three years.</p>\n<p>During this period, Scala underwent a major release and introduced its first Long-Term Support (LTS) version. Alongside these updates, our codebase had accumulated significant technical debt, providing us with an opportunity to address longstanding inefficiencies.</p>\n<h2 id=\"heading-background\">Background</h2>\n<p>We had been using the <a target=\"_blank\" href=\"https://github.com/scalaj/scalaj-http\"><code>scalaj-http</code></a> library for making HTTP calls in Scala. However, this library had reached its end-of-life (EOL) status over two years ago and was no longer receiving updates.</p>\n<p>This is a small snippet of our class which defines the methods making HTTP calls:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">makePostCall</span></span>(url: <span class=\"hljs-type\">String</span>, body: <span class=\"hljs-type\">String</span>, authToken: <span class=\"hljs-type\">String</span>): (<span class=\"hljs-type\">Int</span>, <span class=\"hljs-type\">JsValue</span>) = {\n    println(<span class=\"hljs-string\">\"url: \"</span>+url)\n    println(<span class=\"hljs-string\">\"body: \"</span>+body)\n    <span class=\"hljs-keyword\">val</span> res = <span class=\"hljs-type\">Http</span>(url)\n      .header(<span class=\"hljs-string\">\"Content-Type\"</span>, <span class=\"hljs-string\">\"application/json\"</span>)\n      .header(<span class=\"hljs-string\">\"Authorization\"</span>, <span class=\"hljs-string\">s\"Bearer <span class=\"hljs-subst\">$authToken</span>\"</span>)\n      .header(<span class=\"hljs-string\">\"Charset\"</span>, <span class=\"hljs-string\">\"UTF-8\"</span>)\n      .option(<span class=\"hljs-type\">HttpOptions</span>.readTimeout(<span class=\"hljs-number\">100000000</span>))\n      .option(<span class=\"hljs-type\">HttpOptions</span>.connTimeout(<span class=\"hljs-number\">100000000</span>))\n      .postData(body)\n      .asString\n\n\n    <span class=\"hljs-keyword\">val</span> code = res.code\n    <span class=\"hljs-keyword\">val</span> response = <span class=\"hljs-type\">Json</span>.parse(res.body)\n\n    (code, response)\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">makeGetCall</span></span>(url: <span class=\"hljs-type\">String</span>, authToken: <span class=\"hljs-type\">String</span>): (<span class=\"hljs-type\">Int</span>, <span class=\"hljs-type\">JsValue</span>) = {\n    println(<span class=\"hljs-string\">\"url: \"</span>+url)\n    <span class=\"hljs-keyword\">val</span> res = <span class=\"hljs-type\">Http</span>(url)\n      .header(<span class=\"hljs-string\">\"Content-Type\"</span>, <span class=\"hljs-string\">\"application/json\"</span>)\n      .header(<span class=\"hljs-string\">\"Authorization\"</span>, <span class=\"hljs-string\">s\"Bearer <span class=\"hljs-subst\">$authToken</span>\"</span>)\n      .header(<span class=\"hljs-string\">\"Charset\"</span>, <span class=\"hljs-string\">\"UTF-8\"</span>)\n      .option(<span class=\"hljs-type\">HttpOptions</span>.readTimeout(<span class=\"hljs-number\">100000000</span>))\n      .option(<span class=\"hljs-type\">HttpOptions</span>.connTimeout(<span class=\"hljs-number\">100000000</span>))\n      .asString\n\n    <span class=\"hljs-keyword\">val</span> code = res.code\n    <span class=\"hljs-keyword\">val</span> response = <span class=\"hljs-type\">Json</span>.parse(res.body)\n\n    (code, response)\n}\n\n<span class=\"hljs-comment\">// More methods for more HTTP types.</span>\n</code></pre>\n<p>With our existing code base, there was no scope of any modification. It had a lot of limitations:</p>\n<ol>\n<li><p>HTTP call functions were hardcoded.</p>\n</li>\n<li><p>Headers were not modifiable</p>\n</li>\n<li><p>Authentication was limited to Bearer tokens</p>\n</li>\n<li><p>The request body format was restricted to JSON</p>\n</li>\n<li><p>HTTP methods could not be easily altered.</p>\n</li>\n</ol>\n<p>These limitations affected not only our HTTP class but also other classes that relied on it. With the EOL of <code>scalaj-http</code>, we needed to refactor our codebase significantly.</p>\n<h2 id=\"heading-inspiration\">Inspiration</h2>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1722886780835/f2e3b482-7e1b-45d3-a23e-4986ed15fcc6.jpeg\" alt=\"A sample REST API Client\" class=\"image--center mx-auto\" /></p>\n<p>Many software developers and testers use REST API clients to test API endpoints. Various REST API clients exist, and the one you see above is Bruno - One of the only REST clients that meet my org's stringent IT Security Standards.</p>\n<p>The flexibility of API clients - allowing for different HTTP methods, body types, and authentication mechanisms - is crucial. This adaptability is possible because these clients are not hardcoded, unlike our previous implementation. Therefore, in our refactoring, we aimed to make our code modular and adhere to known design patterns and SOLID principles.</p>\n<h2 id=\"heading-breakdown\">Breakdown</h2>\n<p>In our previous implementation, constructing the HTTP request and making the call were done within a single file. This approach meant that any modification required changes across multiple classes, leading to tight coupling.</p>\n<p>To resolve this, we decided to separate our API package into three subpackages:</p>\n<ol>\n<li><p><code>request</code></p>\n</li>\n<li><p><code>client</code></p>\n</li>\n<li><p><code>apps</code></p>\n</li>\n</ol>\n<p>The <code>request</code> and <code>client</code> components are designed to be loosely coupled. This separation ensures that changes in one part, such as switching to a different client library, require minimal modifications elsewhere in the code. Ideally, only a single line should need updating to change the client library used throughout the program. Classes inside <code>apps</code> would use the client to execute business processes by making the HTTP calls.</p>\n<h2 id=\"heading-request-package\">Request Package</h2>\n<p>To construct an HTTP request, there are five fundamental components:</p>\n<ol>\n<li><p>URL</p>\n</li>\n<li><p>Headers</p>\n</li>\n<li><p>HTTP Method</p>\n</li>\n<li><p>Body</p>\n</li>\n<li><p>Authentication</p>\n</li>\n</ol>\n<p>It's a widely accepted convention that the URL is a <code>String</code>, while headers are represented as a <code>HashMap</code> with <code>String</code> keys and values.</p>\n<p>The elements that can vary between HTTP requests are the Method, Body, and Authentication.</p>\n<h3 id=\"heading-method\">Method</h3>\n<p>In this initial implementation of the Request package, I've chosen to support the most commonly used HTTP methods:</p>\n<ol>\n<li><p>GET</p>\n</li>\n<li><p>POST</p>\n</li>\n<li><p>PUT</p>\n</li>\n<li><p>DELETE</p>\n</li>\n</ol>\n<pre><code class=\"lang-scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">trait</span> <span class=\"hljs-title\">ApiMethod</span>        <span class=\"hljs-title\">//</span> <span class=\"hljs-title\">trait</span> <span class=\"hljs-title\">is</span> <span class=\"hljs-title\">the</span> <span class=\"hljs-title\">equivalent</span> <span class=\"hljs-title\">for</span> <span class=\"hljs-title\">interface</span> <span class=\"hljs-title\">in</span> <span class=\"hljs-title\">OOP</span> <span class=\"hljs-title\">langugaes</span></span>\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">object</span> <span class=\"hljs-title\">DELETE</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiMethod</span></span>\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">object</span> <span class=\"hljs-title\">GET</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiMethod</span></span>\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">object</span> <span class=\"hljs-title\">POST</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiMethod</span></span>\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">object</span> <span class=\"hljs-title\">PUT</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiMethod</span></span>\n</code></pre>\n<p>To implement these, I use a Scala-specific paradigm called <a target=\"_blank\" href=\"https://docs.scala-lang.org/overviews/scala-book/case-objects.html\"><code>Case Object</code></a>, which aligns with the <a target=\"_blank\" href=\"https://sourcemaking.com/design_patterns/singleton\">Singleton design pattern</a>. This approach is similar to enums in other programming languages.</p>\n<h3 id=\"heading-body\">Body</h3>\n<p>For the body of HTTP requests, I will support four types:</p>\n<ol>\n<li><p>JSON</p>\n</li>\n<li><p>XML</p>\n</li>\n<li><p>Binary</p>\n</li>\n<li><p>FormURLEncoded</p>\n</li>\n</ol>\n<p>To manage these, I created an interface (<code>ApiBody</code>) that specifies two methods: <code>contentType</code> and <code>content</code>. Each respective class will have a default constructor that includes a variable representing the content we intend to send.</p>\n<p>The <code>contentType</code> method will return the MIME type, such as <code>application/json</code> or <code>application/xml</code>. The <code>content</code> method will convert the body content into a byte array. The choice of a byte array is deliberate; while JSON and XML content can often be represented as a string, binary data cannot. By converting all types into a byte array, we provide a consistent interface for later client implementations.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">trait</span> <span class=\"hljs-title\">ApiBody</span> </span>{\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">contentType</span></span>: <span class=\"hljs-type\">String</span>\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">content</span></span>: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>]\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">JsonBody</span>(<span class=\"hljs-params\">json: <span class=\"hljs-type\">String</span></span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiBody</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">contentType</span></span>: <span class=\"hljs-type\">String</span> = <span class=\"hljs-string\">\"application/json\"</span>\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">content</span></span>: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>] = json.getBytes(<span class=\"hljs-string\">\"UTF-8\"</span>)\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">XmlBody</span>(<span class=\"hljs-params\">xml: <span class=\"hljs-type\">String</span></span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiBody</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">contentType</span></span>: <span class=\"hljs-type\">String</span> = <span class=\"hljs-string\">\"application/xml\"</span>\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">content</span></span>: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>] = xml.getBytes(<span class=\"hljs-string\">\"UTF-8\"</span>)\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">FormUrlEncodedBody</span>(<span class=\"hljs-params\">formData: <span class=\"hljs-type\">Map</span>[<span class=\"hljs-type\">String</span>, <span class=\"hljs-type\">String</span>]</span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiBody</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">contentType</span></span>: <span class=\"hljs-type\">String</span> = <span class=\"hljs-string\">\"application/x-www-form-urlencoded\"</span>\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">content</span></span>: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>] = formData\n    .map(e =&gt; java.net.<span class=\"hljs-type\">URLEncoder</span>.encode(e._1, <span class=\"hljs-string\">\"UTF-8\"</span>) + <span class=\"hljs-string\">\"=\"</span> + java.net.<span class=\"hljs-type\">URLEncoder</span>.encode(e._2, <span class=\"hljs-string\">\"UTF-8\"</span>))\n    .mkString(<span class=\"hljs-string\">\"&amp;\"</span>)\n    .getBytes(<span class=\"hljs-string\">\"UTF-8\"</span>)\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">BinaryBody</span>(<span class=\"hljs-params\">data: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>]</span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiBody</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">contentType</span></span>: <span class=\"hljs-type\">String</span> = <span class=\"hljs-string\">\"application/octet-stream\"</span>\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">content</span></span>: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>] = data\n}\n</code></pre>\n<h3 id=\"heading-authentication\">Authentication</h3>\n<p>We will implement two common types of authentication:</p>\n<ol>\n<li><p>Token based authentication</p>\n</li>\n<li><p>Basic authentication (user/password)</p>\n</li>\n</ol>\n<p>The plan was to use the same approach as with Body and Method, by defining an interface and corresponding classes. However, there’s a challenge: different client libraries may handle authentication in unique ways. Since the Request package must remain unaware of the Client package's specifics, a direct implementation isn’t feasible.</p>\n<p>One potential solution is to use headers since they can be represented as a key-value map. This method works for basic and token-based authentication but fails for more complex mechanisms, such as GitHub API or AWS S3 SDK with v4 signature. These mechanisms often require access to the request body to generate appropriate headers.</p>\n<p>In my implementation, I have kept Body and Authentication separate, and I intend to maintain that separation. The solution involves creating an interface and corresponding classes for authentication types, along with a wrapper that encapsulates all authentication mechanisms. This wrapper will then be implemented by the Client to execute the HTTP call.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">trait</span> <span class=\"hljs-title\">AuthRequestProvider</span> </span>{\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">addBearerToken</span></span>(token: <span class=\"hljs-type\">String</span>): <span class=\"hljs-type\">Unit</span>\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">addBasicAuth</span></span>(username: <span class=\"hljs-type\">String</span>, password: <span class=\"hljs-type\">String</span>): <span class=\"hljs-type\">Unit</span>\n}\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">trait</span> <span class=\"hljs-title\">ApiAuth</span> </span>{\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">applyTo</span></span>(request: <span class=\"hljs-type\">AuthRequestProvider</span>): <span class=\"hljs-type\">Unit</span>\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">BasicAuth</span>(<span class=\"hljs-params\">username: <span class=\"hljs-type\">String</span>, password: <span class=\"hljs-type\">String</span></span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiAuth</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">applyTo</span></span>(request: <span class=\"hljs-type\">AuthRequestProvider</span>): <span class=\"hljs-type\">Unit</span> = {\n    request.addBasicAuth(username, password)\n  }\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">TokenAuth</span>(<span class=\"hljs-params\">token: <span class=\"hljs-type\">String</span></span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiAuth</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">applyTo</span></span>(request: <span class=\"hljs-type\">AuthRequestProvider</span>): <span class=\"hljs-type\">Unit</span> = {\n    request.addBearerToken(token)\n  }\n}\n</code></pre>\n<p>The implementation of the <code>AuthRequestProvider</code> in the Client package will be discussed in a subsequent section.</p>\n<h3 id=\"heading-api-request\">API Request</h3>\n<p>With the basics of building an HTTP Request covered, the next step is to create a class representing our <code>ApiRequest</code>. This class will be used by the client to execute the actual HTTP call.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">protected</span>[api] <span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ApiRequest</span>(<span class=\"hljs-params\">\n                        method: <span class=\"hljs-type\">ApiMethod</span>,\n                        url: <span class=\"hljs-type\">String</span>,\n                        body: <span class=\"hljs-type\">Option</span>[<span class=\"hljs-type\">ApiBody</span>] = <span class=\"hljs-type\">None</span>,\n                        headers: <span class=\"hljs-type\">Map</span>[<span class=\"hljs-type\">String</span>, <span class=\"hljs-type\">String</span>] = <span class=\"hljs-type\">Map</span>.empty,\n                        authentication: <span class=\"hljs-type\">Option</span>[<span class=\"hljs-type\">ApiAuth</span>] = <span class=\"hljs-type\">None</span>\n                      </span>)</span>\n</code></pre>\n<p>In this class, the <code>Method</code> and <code>URL</code> are mandatory components for making an HTTP call. While headers are optional, they are represented using a <code>Map</code> data type, so no dedicated class is necessary. The <code>Body</code> and <code>Authentication</code> components are also optional and are encapsulated using the <a target=\"_blank\" href=\"https://docs.scala-lang.org/overviews/collections-2.13/conversion-between-option-and-the-collections.html#inner-main\"><code>Option</code> wrapper</a>. If a component is absent, it will be represented as <code>None</code>; if present, it will be enclosed within a <code>Some</code> object.</p>\n<p>The <code>protected[api]</code> modifier on the case class restricts its instantiation to within the <code>api</code> package, which includes both the request and client sub-packages. This ensures that downstream classes cannot create substandard <code>ApiRequest</code> instances, maintaining the integrity of our API implementation.</p>\n<h3 id=\"heading-api-request-builder\">API Request Builder</h3>\n<p>Downstream classes should use the <code>ApiRequestBuilder</code> to create an <code>ApiRequest</code> object, which they can then pass to the client for making the HTTP call. This implementation follows the <a target=\"_blank\" href=\"https://sourcemaking.com/design_patterns/builder\">Builder design pattern</a>.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ApiRequestBuilder</span>(<span class=\"hljs-params\">\n                               private val method: <span class=\"hljs-type\">Option</span>[<span class=\"hljs-type\">ApiMethod</span>] = <span class=\"hljs-type\">Some</span>(<span class=\"hljs-type\">GET</span></span>),</span>\n                               <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">val</span> url: <span class=\"hljs-type\">String</span> = <span class=\"hljs-string\">\"\"</span>,\n                               <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">val</span> body: <span class=\"hljs-type\">Option</span>[<span class=\"hljs-type\">ApiBody</span>] = <span class=\"hljs-type\">None</span>,\n                               <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">val</span> headers: <span class=\"hljs-type\">Map</span>[<span class=\"hljs-type\">String</span>, <span class=\"hljs-type\">String</span>] = <span class=\"hljs-type\">Map</span>(),\n                               <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">val</span> authentication: <span class=\"hljs-type\">Option</span>[<span class=\"hljs-type\">ApiAuth</span>] = <span class=\"hljs-type\">None</span>\n                             ) {\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">withMethod</span></span>(method: <span class=\"hljs-type\">ApiMethod</span>): <span class=\"hljs-type\">ApiRequestBuilder</span> = <span class=\"hljs-keyword\">this</span>.copy(method = <span class=\"hljs-type\">Some</span>(method))\n\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">withUrl</span></span>(url: <span class=\"hljs-type\">String</span>): <span class=\"hljs-type\">ApiRequestBuilder</span> = <span class=\"hljs-keyword\">this</span>.copy(url = url)\n\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">withBody</span></span>(body: <span class=\"hljs-type\">ApiBody</span>): <span class=\"hljs-type\">ApiRequestBuilder</span> = <span class=\"hljs-keyword\">this</span>.copy(body = <span class=\"hljs-type\">Some</span>(body))\n\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">withHeaders</span></span>(headers: <span class=\"hljs-type\">Map</span>[<span class=\"hljs-type\">String</span>, <span class=\"hljs-type\">String</span>]): <span class=\"hljs-type\">ApiRequestBuilder</span> = <span class=\"hljs-keyword\">this</span>.copy(headers = headers)\n\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">addHeader</span></span>(key: <span class=\"hljs-type\">String</span>, value: <span class=\"hljs-type\">String</span>): <span class=\"hljs-type\">ApiRequestBuilder</span> = <span class=\"hljs-keyword\">this</span>.copy(headers = headers + (key -&gt; value))\n\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">withAuthentication</span></span>(auth: <span class=\"hljs-type\">ApiAuth</span>): <span class=\"hljs-type\">ApiRequestBuilder</span> = <span class=\"hljs-keyword\">this</span>.copy(authentication = <span class=\"hljs-type\">Some</span>(auth))\n\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">build</span></span>(): <span class=\"hljs-type\">ApiRequest</span> = {\n    <span class=\"hljs-keyword\">if</span> (method.isEmpty || url.isEmpty) <span class=\"hljs-keyword\">throw</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">IllegalStateException</span>(<span class=\"hljs-string\">\"Method and URL cannot be empty\"</span>)\n    <span class=\"hljs-type\">ApiRequest</span>(method.get, url, body, headers, authentication)\n  }\n}\n</code></pre>\n<p>The usage is straightforward: methods like <code>withUrl</code>, <code>withHeaders</code> and others allow you to configure your request. The <code>build()</code> method then produces the <code>ApiRequest</code> object, which can be passed to the client from downstream classes.</p>\n<h3 id=\"heading-api-response\">API Response</h3>\n<p>When an HTTP request is made, a response is received, which can influence decisions within the application. The <code>APIResponse</code> case class encapsulates this response, including the HTTP response code, response body, and response headers.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ApiResponse</span>(<span class=\"hljs-params\">code: <span class=\"hljs-type\">Int</span>, body: <span class=\"hljs-type\">ApiBody</span>, headers: <span class=\"hljs-type\">Map</span>[<span class=\"hljs-type\">String</span>, <span class=\"hljs-type\">String</span>] = <span class=\"hljs-type\">Map</span>(</span>))</span>\n</code></pre>\n<p>For the response body, we utilize the same <code>ApiBody</code> interface as for the request body, <mark>maintaining consistency</mark> across request and response handling.</p>\n<h2 id=\"heading-client\">Client</h2>\n<p>With our Request package established, we now focus on the client responsible for making the actual HTTP call. The client will be defined as an interface with a single method, <code>send</code>, which accepts an instance of <code>ApiRequest</code>.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">trait</span> <span class=\"hljs-title\">ApiClient</span> </span>{\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">send</span></span>(request: <span class=\"hljs-type\">ApiRequest</span>): <span class=\"hljs-type\">Either</span>[<span class=\"hljs-type\">ApiResponse</span>, <span class=\"hljs-type\">ApiResponse</span>]\n}\n</code></pre>\n<h3 id=\"heading-client-library\">Client Library</h3>\n<p>For our client implementation, we use the Scala <a target=\"_blank\" href=\"https://github.com/softwaremill/sttp\">STTP</a> library, which will consume <code>ApiRequest</code> and generate an <code>ApiResponse</code>. Before implementing the client, we need to address two key components:</p>\n<ol>\n<li><p><strong>Authentication Wrapper</strong>: An implementation to handle various authentication mechanisms.</p>\n</li>\n<li><p><strong>Body Parser</strong>: To convert the response body into an appropriate <code>ApiBody</code> implementation.</p>\n</li>\n</ol>\n<h3 id=\"heading-authentication-wrapper\">Authentication Wrapper</h3>\n<p>The authentication wrapper for the STTP library will accept an STTP <code>Request</code> as a constructor argument and provide the necessary authentication logic.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">SttpRequestProviderWrapper</span>(<span class=\"hljs-params\">var request: sttp.client4.<span class=\"hljs-type\">Request</span>[<span class=\"hljs-type\">Either</span>[<span class=\"hljs-type\">String</span>, <span class=\"hljs-type\">String</span>]]</span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">AuthRequestProvider</span> </span>{\n    <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">addBearerToken</span></span>(token: <span class=\"hljs-type\">String</span>): <span class=\"hljs-type\">Unit</span> = {\n      request = request.auth.bearer(token)\n    }\n\n    <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">addBasicAuth</span></span>(username: <span class=\"hljs-type\">String</span>, password: <span class=\"hljs-type\">String</span>): <span class=\"hljs-type\">Unit</span> = {\n      request = request.auth.basic(username, password)\n    }\n}\n</code></pre>\n<p>This wrapper can be extended to support additional authentication mechanisms as needed. The request (<code>sttp.client4.Request[Either[String, String]]</code>) will include the request body, allowing the wrapper to generate custom HTTP headers based on the body content.</p>\n<h3 id=\"heading-body-parser\">Body Parser</h3>\n<p>To transform the response body into one of our <code>ApiBody</code> implementations, we create a <code>BodyParser</code> interface. This interface will take the response content and headers, returning the appropriate body type.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">trait</span> <span class=\"hljs-title\">BodyParser</span> </span>{\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">parseBody</span></span>(): <span class=\"hljs-type\">ApiBody</span>\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">BinaryParser</span>(<span class=\"hljs-params\">content: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>], contentType: <span class=\"hljs-type\">String</span></span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">BodyParser</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">parseBody</span></span>(): <span class=\"hljs-type\">ApiBody</span> = <span class=\"hljs-type\">BinaryBody</span>(content, contentType)\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">JsonParser</span>(<span class=\"hljs-params\">content: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>]</span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">BodyParser</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">parseBody</span></span>(): <span class=\"hljs-type\">ApiBody</span> = <span class=\"hljs-type\">JsonBody</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">String</span>(content, <span class=\"hljs-string\">\"UTF-8\"</span>))\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">XmlParser</span>(<span class=\"hljs-params\">content: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>]</span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">BodyParser</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">parseBody</span></span>(): <span class=\"hljs-type\">ApiBody</span> = <span class=\"hljs-type\">XmlBody</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">String</span>(content, <span class=\"hljs-string\">\"UTF-8\"</span>))\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">StringParser</span>(<span class=\"hljs-params\">content: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>]</span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">BodyParser</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">parseBody</span></span>(): <span class=\"hljs-type\">ApiBody</span> = <span class=\"hljs-type\">StringBody</span>(<span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">String</span>(content, <span class=\"hljs-string\">\"UTF-8\"</span>))\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">FormUrlEncodedParser</span>(<span class=\"hljs-params\">content: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>]</span>) <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">BodyParser</span> </span>{\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">parseBody</span></span>(): <span class=\"hljs-type\">ApiBody</span> = {\n    <span class=\"hljs-keyword\">val</span> decodedContent = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">String</span>(content, <span class=\"hljs-string\">\"UTF-8\"</span>)\n    <span class=\"hljs-keyword\">val</span> formData = decodedContent.split(<span class=\"hljs-string\">\"&amp;\"</span>).map { pair =&gt;\n      <span class=\"hljs-keyword\">val</span> <span class=\"hljs-type\">Array</span>(key, value) = pair.split(<span class=\"hljs-string\">\"=\"</span>)\n      java.net.<span class=\"hljs-type\">URLDecoder</span>.decode(key, <span class=\"hljs-string\">\"UTF-8\"</span>) -&gt; java.net.<span class=\"hljs-type\">URLDecoder</span>.decode(value, <span class=\"hljs-string\">\"UTF-8\"</span>)\n    }.toMap\n    <span class=\"hljs-type\">FormUrlEncodedBody</span>(formData)\n  }\n}\n</code></pre>\n<p>A <a target=\"_blank\" href=\"https://sourcemaking.com/design_patterns/factory_method\">Factory design pattern</a> will be used to instantiate the appropriate <code>BodyParser</code>:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">object</span> <span class=\"hljs-title\">BodyParser</span> </span>{\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">getParser</span></span>(content: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Byte</span>], headers: <span class=\"hljs-type\">Map</span>[<span class=\"hljs-type\">String</span>, <span class=\"hljs-type\">String</span>]): <span class=\"hljs-type\">Option</span>[<span class=\"hljs-type\">BodyParser</span>] = headers.get(<span class=\"hljs-string\">\"content-type\"</span>) <span class=\"hljs-keyword\">match</span> {\n    <span class=\"hljs-keyword\">case</span> <span class=\"hljs-type\">Some</span>(value) =&gt; value <span class=\"hljs-keyword\">match</span> {\n      <span class=\"hljs-keyword\">case</span> <span class=\"hljs-string\">\"application/json\"</span> =&gt; <span class=\"hljs-type\">Some</span>(<span class=\"hljs-type\">JsonParser</span>(content))\n      <span class=\"hljs-keyword\">case</span> <span class=\"hljs-string\">\"application/xml\"</span> =&gt; <span class=\"hljs-type\">Some</span>(<span class=\"hljs-type\">XmlParser</span>(content))\n      <span class=\"hljs-keyword\">case</span> <span class=\"hljs-string\">\"application/x-www-form-urlencoded\"</span> =&gt; <span class=\"hljs-type\">Some</span>(<span class=\"hljs-type\">FormUrlEncodedParser</span>(content))\n      <span class=\"hljs-keyword\">case</span> _ =&gt; <span class=\"hljs-type\">Some</span>(<span class=\"hljs-type\">BinaryParser</span>(content))\n    }\n    <span class=\"hljs-keyword\">case</span> <span class=\"hljs-type\">None</span> =&gt; <span class=\"hljs-type\">None</span>\n  }\n}\n</code></pre>\n<h3 id=\"heading-client-implementation\">Client Implementation</h3>\n<p>With the building blocks in place, we implement the client. The client will use the <code>ApiRequest</code> properties (method, URL, headers) to construct the initial request, apply the body if present, and then handle authentication if required.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">protected</span>[api] <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">SttpClient</span> <span class=\"hljs-keyword\">extends</span> <span class=\"hljs-title\">ApiClient</span> </span>{\n  <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">val</span> backend = <span class=\"hljs-type\">HttpURLConnectionBackend</span>()\n\n  <span class=\"hljs-keyword\">override</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">send</span></span>(request: <span class=\"hljs-type\">ApiRequest</span>): <span class=\"hljs-type\">Either</span>[<span class=\"hljs-type\">ApiResponse</span>, <span class=\"hljs-type\">ApiResponse</span>] = {\n    <span class=\"hljs-keyword\">try</span> {\n      <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">URI</span>(request.url).toURL\n    }\n    <span class=\"hljs-keyword\">catch</span> {\n      <span class=\"hljs-keyword\">case</span> e: <span class=\"hljs-type\">URISyntaxException</span> =&gt; <span class=\"hljs-keyword\">return</span> <span class=\"hljs-type\">Left</span>(<span class=\"hljs-type\">ApiResponse</span>(<span class=\"hljs-number\">500</span>, <span class=\"hljs-type\">Some</span>(<span class=\"hljs-type\">JsonBody</span>(ujson.<span class=\"hljs-type\">Obj</span>(<span class=\"hljs-string\">\"message\"</span> -&gt; e.getMessage).toString())), <span class=\"hljs-type\">Map</span>()))\n      <span class=\"hljs-keyword\">case</span> e: <span class=\"hljs-type\">IllegalArgumentException</span> =&gt; <span class=\"hljs-keyword\">return</span> <span class=\"hljs-type\">Left</span>(<span class=\"hljs-type\">ApiResponse</span>(<span class=\"hljs-number\">500</span>, <span class=\"hljs-type\">Some</span>(<span class=\"hljs-type\">JsonBody</span>(ujson.<span class=\"hljs-type\">Obj</span>(<span class=\"hljs-string\">\"message\"</span> -&gt; e.getMessage).toString())), <span class=\"hljs-type\">Map</span>()))\n    }\n\n    <span class=\"hljs-keyword\">var</span> sttpRequest = sttp.client4.basicRequest.method(sttp.model.<span class=\"hljs-type\">Method</span>(request.method.toString), <span class=\"hljs-string\">uri\"<span class=\"hljs-subst\">${request.url}</span>\"</span>)\n\n    request.headers.foreach { <span class=\"hljs-keyword\">case</span> (key, value) =&gt;\n      sttpRequest = sttpRequest.header(key, value)\n    }\n\n    request.body.foreach { body =&gt;\n      sttpRequest = sttpRequest.body(body.content).contentType(body.contentType)\n    }\n\n    <span class=\"hljs-keyword\">val</span> authRequest = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">SttpRequestProviderWrapper</span>(sttpRequest)\n    request.authentication.foreach(_.applyTo(authRequest))\n    sttpRequest = authRequest.request\n\n    <span class=\"hljs-keyword\">val</span> response = sttpRequest.response(asByteArray).send(backend)\n    <span class=\"hljs-keyword\">val</span> headers = response.headers.map(h =&gt; h.name -&gt; h.value).toMap\n    <span class=\"hljs-keyword\">val</span> responseEntity = <span class=\"hljs-type\">ApiResponse</span>(\n      response.code.code,\n      response.body <span class=\"hljs-keyword\">match</span> {\n        <span class=\"hljs-keyword\">case</span> <span class=\"hljs-type\">Left</span>(error) =&gt; <span class=\"hljs-type\">BodyParser</span>.getParser(error.getBytes(<span class=\"hljs-string\">\"UTF-8\"</span>), headers) <span class=\"hljs-keyword\">match</span> {\n          <span class=\"hljs-keyword\">case</span> <span class=\"hljs-type\">Some</span>(value) =&gt; <span class=\"hljs-type\">Some</span>(value.parseBody())\n          <span class=\"hljs-keyword\">case</span> <span class=\"hljs-type\">None</span> =&gt; <span class=\"hljs-type\">None</span>\n        }\n        <span class=\"hljs-keyword\">case</span> <span class=\"hljs-type\">Right</span>(value) =&gt; <span class=\"hljs-type\">Some</span>(<span class=\"hljs-type\">BodyParser</span>.getParser(value, headers).get.parseBody())\n      },\n      headers\n    )\n\n    <span class=\"hljs-keyword\">if</span> (response.code.isClientError || response.code.isServerError) <span class=\"hljs-type\">Left</span>(responseEntity)\n    <span class=\"hljs-keyword\">else</span> <span class=\"hljs-type\">Right</span>(responseEntity)\n  }\n}\n</code></pre>\n<h2 id=\"heading-ensure-stability-of-api-package\">Ensure stability of API package</h2>\n<p>A primary motivation for this rewrite is to minimize the impact of a library going end-of-life (EOL) in the future. If the STTP library becomes unsupported, we should only need to make a single line change in our code, ensuring the rest of the classes remain unaffected.</p>\n<p>In the <code>SttpClient</code> implementation, the access modifier is set to <code>protected[api]</code>. This restricts access to within the <code>api</code> package, preventing direct usage outside. To facilitate client access, we define an <code>ApiClient</code> object in the same file as the <code>ApiClient</code> trait. This object includes an <code>apply()</code> method that creates a new instance of <code>SttpClient</code>, leveraging its position within the <code>api</code> subpackage.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">object</span> <span class=\"hljs-title\">ApiClient</span> </span>{\n  <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">apply</span></span>() = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">SttpClient</span>()\n}\n</code></pre>\n<p>In the event that the STTP library goes EOL, we would need to:</p>\n<ol>\n<li><p>Implement a new authentication wrapper for the replacement library.</p>\n</li>\n<li><p>Implement the new library's client (similar to <code>SttpClient</code>).</p>\n</li>\n<li><p>Update the <code>apply()</code> method in <code>ApiClient</code> to return an instance of the new client. This single-line change ensures that <mark>no other classes are impacted by the transition</mark>.</p>\n</li>\n</ol>\n<h2 id=\"heading-using-the-client\">Using the client</h2>\n<p>With the foundational components in place, we can now use the <code>ApiClient</code> to make an HTTP call. Here's an example of how to perform an API call using the implemented code:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> request = <span class=\"hljs-type\">ApiRequestBuilder</span>()\n  .withUrl(url)\n  .withMethod(<span class=\"hljs-type\">POST</span>)        <span class=\"hljs-comment\">// Refers to the case object POST created above</span>\n  .withAuthentication(<span class=\"hljs-type\">TokenAuth</span>(token))\n  .withBody(<span class=\"hljs-type\">JsonBody</span>(<span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"{\"</span><span class=\"hljs-string\">key\":\"</span><span class=\"hljs-string\">value\"}\"</span><span class=\"hljs-string\">\"\"</span>))\n  .build()\n\n<span class=\"hljs-type\">ApiClient</span>().send(request) <span class=\"hljs-keyword\">match</span> {\n  <span class=\"hljs-keyword\">case</span> <span class=\"hljs-type\">Left</span>(value) =&gt;\n    <span class=\"hljs-keyword\">throw</span> <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">Exception</span>(value.body.get)\n  <span class=\"hljs-keyword\">case</span> <span class=\"hljs-type\">Right</span>(<span class=\"hljs-type\">ApiResponse</span>(_, body, _)) =&gt;\n    println(body.get)\n    println(<span class=\"hljs-string\">\"API Call successful\"</span>)\n}\n</code></pre>\n<p>Note the use of <code>ApiClient()</code> to initiate the HTTP call. In Scala, <code>ApiClient()</code> is syntactic sugar that the compiler interprets as a call to the <code>ApiClient.apply()</code> method.</p>\n<h2 id=\"heading-adherence-to-solid-principles\">Adherence to SOLID Principles</h2>\n<p><a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/SOLID\">SOLID</a> is a set of five principles of Object-Oriented class design. They are a set of rules and best practices to follow while designing a class structure. These five principles help us understand the need for certain design patterns and software architecture in general. I always strive to adhere to these principles whenever I'm developing software, and we will now have a look at how the code above adheres to the SOLID Principles.</p>\n<h3 id=\"heading-single-responsibility-principle-srp\"><strong>S</strong>ingle Responsibility Principle (SRP)</h3>\n<p>A class should have one, and only one, reason to change. This principle promotes the separation of concerns within a system:</p>\n<ul>\n<li><p>Our <code>HttpRequestBuilder</code> is solely responsible for building <code>HttpRequest</code> objects. It encapsulates the construction logic and provides an interface for setting request properties.</p>\n</li>\n<li><p>The <code>BodyParser</code> isolates the logic for parsing different types of response bodies based on the content type, keeping this concern separate from other parts of the system</p>\n</li>\n<li><p>Our <code>SttpClient</code> implementation handles the responsibility of sending HTTP requests and processing responses. It doesn't concern itself with the construction of requests or parsing of response bodies, which are handled by other classes.</p>\n</li>\n<li><p><code>ApiResponse</code> encapsulates the response data, separating it from the request logic and the client implementation.</p>\n</li>\n<li><p><code>ApiAuth</code> and its various subclasses have a single responsibility to apply a specific authentication mechanism.</p>\n</li>\n</ul>\n<h3 id=\"heading-openclosed-principle-ocp\"><strong>O</strong>pen/Closed Principle (OCP)</h3>\n<p>Software entities should be open for extension but closed for modification. This means you can extend the behavior of a class without modifying its source code:</p>\n<ul>\n<li><p>The <code>Body</code> trait and its subclasses allow for easy addition of new body types without altering existing code. For example, adding a new <code>CsvBody</code> would involve creating a new case class that extends <code>Body</code>.</p>\n</li>\n<li><p>New implementations of <code>ApiClient</code> can be created (e.g., <code>JavaApiClient</code>, <code>Http4sApiClient</code>) without modifying the existing <code>SttpClient</code>. Each new client implementation can provide its own logic for sending requests.</p>\n</li>\n<li><p>New authentication methods can be added by creating new classes that implement the <code>Authentication</code> trait.</p>\n</li>\n</ul>\n<h3 id=\"heading-liskov-substitution-principle-lsp\"><strong>L</strong>iskov Substitution Principle (LSP)</h3>\n<p>Objects of a superclass should be replaceable with objects of a subclass without affecting the correctness of the program:</p>\n<ul>\n<li><p>Anywhere a <code>Body</code> is expected, any of its subclasses (<code>JsonBody</code>, <code>XmlBody</code>, etc.) can be used interchangeably.</p>\n</li>\n<li><p>The system can use <code>TokenAuthentication</code> or <code>BasicAuthentication</code> interchangeably wherever <code>Authentication</code> is expected, ensuring the <code>applyTo</code> method works correctly for any subclass.</p>\n</li>\n</ul>\n<h3 id=\"heading-interface-segregation-principle-isp\"><strong>I</strong>nterface Segregation Principle (ISP)</h3>\n<p>No client should be forced to depend on methods it does not use. This principle advocates for smaller, more specific interfaces:</p>\n<ul>\n<li><p><code>ApiAuth</code> <strong>Interface</strong>: This interface is specifically for adding authentication to a request and does not include other unrelated methods. It ensures that only relevant methods are exposed to classes that implement this interface.</p>\n</li>\n<li><p><code>ApiClient</code> <strong>Interface</strong>: Defines a minimal interface for sending HTTP requests. It does not force implementing classes to expose unnecessary methods.</p>\n</li>\n</ul>\n<h3 id=\"heading-dependency-inversion-principle-dip\"><strong>D</strong>ependency Inversion Principle (DIP)</h3>\n<p>High-level modules should not depend on low-level modules. Both should depend on abstractions. Abstractions should not depend on details. Details should depend on abstractions:</p>\n<ul>\n<li><p><code>ApiClient</code> <strong>Interface</strong>: The high-level code (such as a service using the HTTP client) depends on the <code>ApiClient</code> abstraction, not on specific implementations like <code>SttpClient</code>.</p>\n</li>\n<li><p><strong>Dependency on Abstractions</strong>: The system uses the <code>ApiAuth</code>, <code>ApiBody</code>, and <code>ApiClient</code> abstractions rather than concrete implementations, making it easy to swap out implementations as needed.</p>\n</li>\n</ul>\n<h2 id=\"heading-conclusion\">Conclusion</h2>\n<p>The goal was to modernize our HTTP client classes, moving from a rigid, outdated pieces to a flexible, modular architecture. By focusing on a clean separation of concerns and employing design patterns like Builder, Factory and Singleton, we created a robust framework that enhances maintainability and scalability.</p>\n<p>Key features include a modular request builder, an extensible authentication wrapper, and a consistent handling of API responses. The new design ensures easy adaptability to future changes, such as switching out libraries or updating security protocols, with minimal impact on the overall system.</p>\n<p>This streamlined, adaptable architecture not only addresses previous limitations but also positions our product for future growth and technological advancements.</p>\n<p>Code used inside this post is also available inside my <a target=\"_blank\" href=\"https://github.com/Sparker0i/API-Scala-with-SOLID-Principles\">GitHub repo</a>.</p>\n","contentMarkdown":"We've been developing an AI-enabled data engineering product at our company, using Scala as the core programming language. We also utilize Scala-related frameworks like Spark and Play to power various components. Recently, we conducted a vulnerability scan on our applications and discovered numerous security issues. The root cause was that we hadn't updated our libraries in over three years.\n\nDuring this period, Scala underwent a major release and introduced its first Long-Term Support (LTS) version. Alongside these updates, our codebase had accumulated significant technical debt, providing us with an opportunity to address longstanding inefficiencies.\n\n## Background\n\nWe had been using the [`scalaj-http`](https://github.com/scalaj/scalaj-http) library for making HTTP calls in Scala. However, this library had reached its end-of-life (EOL) status over two years ago and was no longer receiving updates.\n\nThis is a small snippet of our class which defines the methods making HTTP calls:\n\n```scala\ndef makePostCall(url: String, body: String, authToken: String): (Int, JsValue) = {\n    println(\"url: \"+url)\n    println(\"body: \"+body)\n    val res = Http(url)\n      .header(\"Content-Type\", \"application/json\")\n      .header(\"Authorization\", s\"Bearer $authToken\")\n      .header(\"Charset\", \"UTF-8\")\n      .option(HttpOptions.readTimeout(100000000))\n      .option(HttpOptions.connTimeout(100000000))\n      .postData(body)\n      .asString\n\n\n    val code = res.code\n    val response = Json.parse(res.body)\n\n    (code, response)\n}\n\ndef makeGetCall(url: String, authToken: String): (Int, JsValue) = {\n    println(\"url: \"+url)\n    val res = Http(url)\n      .header(\"Content-Type\", \"application/json\")\n      .header(\"Authorization\", s\"Bearer $authToken\")\n      .header(\"Charset\", \"UTF-8\")\n      .option(HttpOptions.readTimeout(100000000))\n      .option(HttpOptions.connTimeout(100000000))\n      .asString\n\n    val code = res.code\n    val response = Json.parse(res.body)\n\n    (code, response)\n}\n\n// More methods for more HTTP types.\n```\n\nWith our existing code base, there was no scope of any modification. It had a lot of limitations:\n\n1. HTTP call functions were hardcoded.\n    \n2. Headers were not modifiable\n    \n3. Authentication was limited to Bearer tokens\n    \n4. The request body format was restricted to JSON\n    \n5. HTTP methods could not be easily altered.\n    \n\nThese limitations affected not only our HTTP class but also other classes that relied on it. With the EOL of `scalaj-http`, we needed to refactor our codebase significantly.\n\n## Inspiration\n\n![A sample REST API Client](https://cdn.hashnode.com/res/hashnode/image/upload/v1722886780835/f2e3b482-7e1b-45d3-a23e-4986ed15fcc6.jpeg align=\"center\")\n\nMany software developers and testers use REST API clients to test API endpoints. Various REST API clients exist, and the one you see above is Bruno - One of the only REST clients that meet my org's stringent IT Security Standards.\n\nThe flexibility of API clients - allowing for different HTTP methods, body types, and authentication mechanisms - is crucial. This adaptability is possible because these clients are not hardcoded, unlike our previous implementation. Therefore, in our refactoring, we aimed to make our code modular and adhere to known design patterns and SOLID principles.\n\n## Breakdown\n\nIn our previous implementation, constructing the HTTP request and making the call were done within a single file. This approach meant that any modification required changes across multiple classes, leading to tight coupling.\n\nTo resolve this, we decided to separate our API package into three subpackages:\n\n1. `request`\n    \n2. `client`\n    \n3. `apps`\n    \n\nThe `request` and `client` components are designed to be loosely coupled. This separation ensures that changes in one part, such as switching to a different client library, require minimal modifications elsewhere in the code. Ideally, only a single line should need updating to change the client library used throughout the program. Classes inside `apps` would use the client to execute business processes by making the HTTP calls.\n\n## Request Package\n\nTo construct an HTTP request, there are five fundamental components:\n\n1. URL\n    \n2. Headers\n    \n3. HTTP Method\n    \n4. Body\n    \n5. Authentication\n    \n\nIt's a widely accepted convention that the URL is a `String`, while headers are represented as a `HashMap` with `String` keys and values.\n\nThe elements that can vary between HTTP requests are the Method, Body, and Authentication.\n\n### Method\n\nIn this initial implementation of the Request package, I've chosen to support the most commonly used HTTP methods:\n\n1. GET\n    \n2. POST\n    \n3. PUT\n    \n4. DELETE\n    \n\n```scala\ntrait ApiMethod        // trait is the equivalent for interface in OOP langugaes\n\ncase object DELETE extends ApiMethod\ncase object GET extends ApiMethod\ncase object POST extends ApiMethod\ncase object PUT extends ApiMethod\n```\n\nTo implement these, I use a Scala-specific paradigm called [`Case Object`](https://docs.scala-lang.org/overviews/scala-book/case-objects.html), which aligns with the [Singleton design pattern](https://sourcemaking.com/design_patterns/singleton). This approach is similar to enums in other programming languages.\n\n### Body\n\nFor the body of HTTP requests, I will support four types:\n\n1. JSON\n    \n2. XML\n    \n3. Binary\n    \n4. FormURLEncoded\n    \n\nTo manage these, I created an interface (`ApiBody`) that specifies two methods: `contentType` and `content`. Each respective class will have a default constructor that includes a variable representing the content we intend to send.\n\nThe `contentType` method will return the MIME type, such as `application/json` or `application/xml`. The `content` method will convert the body content into a byte array. The choice of a byte array is deliberate; while JSON and XML content can often be represented as a string, binary data cannot. By converting all types into a byte array, we provide a consistent interface for later client implementations.\n\n```scala\ntrait ApiBody {\n  def contentType: String\n  def content: Array[Byte]\n}\n\ncase class JsonBody(json: String) extends ApiBody {\n  override def contentType: String = \"application/json\"\n  override def content: Array[Byte] = json.getBytes(\"UTF-8\")\n}\n\ncase class XmlBody(xml: String) extends ApiBody {\n  override def contentType: String = \"application/xml\"\n  override def content: Array[Byte] = xml.getBytes(\"UTF-8\")\n}\n\ncase class FormUrlEncodedBody(formData: Map[String, String]) extends ApiBody {\n  override def contentType: String = \"application/x-www-form-urlencoded\"\n  override def content: Array[Byte] = formData\n    .map(e => java.net.URLEncoder.encode(e._1, \"UTF-8\") + \"=\" + java.net.URLEncoder.encode(e._2, \"UTF-8\"))\n    .mkString(\"&\")\n    .getBytes(\"UTF-8\")\n}\n\ncase class BinaryBody(data: Array[Byte]) extends ApiBody {\n  override def contentType: String = \"application/octet-stream\"\n  override def content: Array[Byte] = data\n}\n```\n\n### Authentication\n\nWe will implement two common types of authentication:\n\n1. Token based authentication\n    \n2. Basic authentication (user/password)\n    \n\nThe plan was to use the same approach as with Body and Method, by defining an interface and corresponding classes. However, there’s a challenge: different client libraries may handle authentication in unique ways. Since the Request package must remain unaware of the Client package's specifics, a direct implementation isn’t feasible.\n\nOne potential solution is to use headers since they can be represented as a key-value map. This method works for basic and token-based authentication but fails for more complex mechanisms, such as GitHub API or AWS S3 SDK with v4 signature. These mechanisms often require access to the request body to generate appropriate headers.\n\nIn my implementation, I have kept Body and Authentication separate, and I intend to maintain that separation. The solution involves creating an interface and corresponding classes for authentication types, along with a wrapper that encapsulates all authentication mechanisms. This wrapper will then be implemented by the Client to execute the HTTP call.\n\n```scala\ntrait AuthRequestProvider {\n  def addBearerToken(token: String): Unit\n  def addBasicAuth(username: String, password: String): Unit\n}\n\ntrait ApiAuth {\n  def applyTo(request: AuthRequestProvider): Unit\n}\n\ncase class BasicAuth(username: String, password: String) extends ApiAuth {\n  override def applyTo(request: AuthRequestProvider): Unit = {\n    request.addBasicAuth(username, password)\n  }\n}\n\ncase class TokenAuth(token: String) extends ApiAuth {\n  override def applyTo(request: AuthRequestProvider): Unit = {\n    request.addBearerToken(token)\n  }\n}\n```\n\nThe implementation of the `AuthRequestProvider` in the Client package will be discussed in a subsequent section.\n\n### API Request\n\nWith the basics of building an HTTP Request covered, the next step is to create a class representing our `ApiRequest`. This class will be used by the client to execute the actual HTTP call.\n\n```scala\nprotected[api] case class ApiRequest(\n                        method: ApiMethod,\n                        url: String,\n                        body: Option[ApiBody] = None,\n                        headers: Map[String, String] = Map.empty,\n                        authentication: Option[ApiAuth] = None\n                      )\n```\n\nIn this class, the `Method` and `URL` are mandatory components for making an HTTP call. While headers are optional, they are represented using a `Map` data type, so no dedicated class is necessary. The `Body` and `Authentication` components are also optional and are encapsulated using the [`Option` wrapper](https://docs.scala-lang.org/overviews/collections-2.13/conversion-between-option-and-the-collections.html#inner-main). If a component is absent, it will be represented as `None`; if present, it will be enclosed within a `Some` object.\n\nThe `protected[api]` modifier on the case class restricts its instantiation to within the `api` package, which includes both the request and client sub-packages. This ensures that downstream classes cannot create substandard `ApiRequest` instances, maintaining the integrity of our API implementation.\n\n### API Request Builder\n\nDownstream classes should use the `ApiRequestBuilder` to create an `ApiRequest` object, which they can then pass to the client for making the HTTP call. This implementation follows the [Builder design pattern](https://sourcemaking.com/design_patterns/builder).\n\n```scala\ncase class ApiRequestBuilder(\n                               private val method: Option[ApiMethod] = Some(GET),\n                               private val url: String = \"\",\n                               private val body: Option[ApiBody] = None,\n                               private val headers: Map[String, String] = Map(),\n                               private val authentication: Option[ApiAuth] = None\n                             ) {\n  def withMethod(method: ApiMethod): ApiRequestBuilder = this.copy(method = Some(method))\n\n  def withUrl(url: String): ApiRequestBuilder = this.copy(url = url)\n\n  def withBody(body: ApiBody): ApiRequestBuilder = this.copy(body = Some(body))\n\n  def withHeaders(headers: Map[String, String]): ApiRequestBuilder = this.copy(headers = headers)\n\n  def addHeader(key: String, value: String): ApiRequestBuilder = this.copy(headers = headers + (key -> value))\n\n  def withAuthentication(auth: ApiAuth): ApiRequestBuilder = this.copy(authentication = Some(auth))\n\n  def build(): ApiRequest = {\n    if (method.isEmpty || url.isEmpty) throw new IllegalStateException(\"Method and URL cannot be empty\")\n    ApiRequest(method.get, url, body, headers, authentication)\n  }\n}\n```\n\nThe usage is straightforward: methods like `withUrl`, `withHeaders` and others allow you to configure your request. The `build()` method then produces the `ApiRequest` object, which can be passed to the client from downstream classes.\n\n### API Response\n\nWhen an HTTP request is made, a response is received, which can influence decisions within the application. The `APIResponse` case class encapsulates this response, including the HTTP response code, response body, and response headers.\n\n```scala\ncase class ApiResponse(code: Int, body: ApiBody, headers: Map[String, String] = Map())\n```\n\nFor the response body, we utilize the same `ApiBody` interface as for the request body, <mark>maintaining consistency</mark> across request and response handling.\n\n## Client\n\nWith our Request package established, we now focus on the client responsible for making the actual HTTP call. The client will be defined as an interface with a single method, `send`, which accepts an instance of `ApiRequest`.\n\n```scala\ntrait ApiClient {\n  def send(request: ApiRequest): Either[ApiResponse, ApiResponse]\n}\n```\n\n### Client Library\n\nFor our client implementation, we use the Scala [STTP](https://github.com/softwaremill/sttp) library, which will consume `ApiRequest` and generate an `ApiResponse`. Before implementing the client, we need to address two key components:\n\n1. **Authentication Wrapper**: An implementation to handle various authentication mechanisms.\n    \n2. **Body Parser**: To convert the response body into an appropriate `ApiBody` implementation.\n    \n\n### Authentication Wrapper\n\nThe authentication wrapper for the STTP library will accept an STTP `Request` as a constructor argument and provide the necessary authentication logic.\n\n```scala\nclass SttpRequestProviderWrapper(var request: sttp.client4.Request[Either[String, String]]) extends AuthRequestProvider {\n    override def addBearerToken(token: String): Unit = {\n      request = request.auth.bearer(token)\n    }\n\n    override def addBasicAuth(username: String, password: String): Unit = {\n      request = request.auth.basic(username, password)\n    }\n}\n```\n\nThis wrapper can be extended to support additional authentication mechanisms as needed. The request (`sttp.client4.Request[Either[String, String]]`) will include the request body, allowing the wrapper to generate custom HTTP headers based on the body content.\n\n### Body Parser\n\nTo transform the response body into one of our `ApiBody` implementations, we create a `BodyParser` interface. This interface will take the response content and headers, returning the appropriate body type.\n\n```scala\ntrait BodyParser {\n  def parseBody(): ApiBody\n}\n\ncase class BinaryParser(content: Array[Byte], contentType: String) extends BodyParser {\n  override def parseBody(): ApiBody = BinaryBody(content, contentType)\n}\n\ncase class JsonParser(content: Array[Byte]) extends BodyParser {\n  override def parseBody(): ApiBody = JsonBody(new String(content, \"UTF-8\"))\n}\n\ncase class XmlParser(content: Array[Byte]) extends BodyParser {\n  override def parseBody(): ApiBody = XmlBody(new String(content, \"UTF-8\"))\n}\n\ncase class StringParser(content: Array[Byte]) extends BodyParser {\n  override def parseBody(): ApiBody = StringBody(new String(content, \"UTF-8\"))\n}\n\ncase class FormUrlEncodedParser(content: Array[Byte]) extends BodyParser {\n  override def parseBody(): ApiBody = {\n    val decodedContent = new String(content, \"UTF-8\")\n    val formData = decodedContent.split(\"&\").map { pair =>\n      val Array(key, value) = pair.split(\"=\")\n      java.net.URLDecoder.decode(key, \"UTF-8\") -> java.net.URLDecoder.decode(value, \"UTF-8\")\n    }.toMap\n    FormUrlEncodedBody(formData)\n  }\n}\n```\n\nA [Factory design pattern](https://sourcemaking.com/design_patterns/factory_method) will be used to instantiate the appropriate `BodyParser`:\n\n```scala\nobject BodyParser {\n  def getParser(content: Array[Byte], headers: Map[String, String]): Option[BodyParser] = headers.get(\"content-type\") match {\n    case Some(value) => value match {\n      case \"application/json\" => Some(JsonParser(content))\n      case \"application/xml\" => Some(XmlParser(content))\n      case \"application/x-www-form-urlencoded\" => Some(FormUrlEncodedParser(content))\n      case _ => Some(BinaryParser(content))\n    }\n    case None => None\n  }\n}\n```\n\n### Client Implementation\n\nWith the building blocks in place, we implement the client. The client will use the `ApiRequest` properties (method, URL, headers) to construct the initial request, apply the body if present, and then handle authentication if required.\n\n```scala\nprotected[api] class SttpClient extends ApiClient {\n  private val backend = HttpURLConnectionBackend()\n\n  override def send(request: ApiRequest): Either[ApiResponse, ApiResponse] = {\n    try {\n      new URI(request.url).toURL\n    }\n    catch {\n      case e: URISyntaxException => return Left(ApiResponse(500, Some(JsonBody(ujson.Obj(\"message\" -> e.getMessage).toString())), Map()))\n      case e: IllegalArgumentException => return Left(ApiResponse(500, Some(JsonBody(ujson.Obj(\"message\" -> e.getMessage).toString())), Map()))\n    }\n\n    var sttpRequest = sttp.client4.basicRequest.method(sttp.model.Method(request.method.toString), uri\"${request.url}\")\n\n    request.headers.foreach { case (key, value) =>\n      sttpRequest = sttpRequest.header(key, value)\n    }\n    \n    request.body.foreach { body =>\n      sttpRequest = sttpRequest.body(body.content).contentType(body.contentType)\n    }\n\n    val authRequest = new SttpRequestProviderWrapper(sttpRequest)\n    request.authentication.foreach(_.applyTo(authRequest))\n    sttpRequest = authRequest.request\n\n    val response = sttpRequest.response(asByteArray).send(backend)\n    val headers = response.headers.map(h => h.name -> h.value).toMap\n    val responseEntity = ApiResponse(\n      response.code.code,\n      response.body match {\n        case Left(error) => BodyParser.getParser(error.getBytes(\"UTF-8\"), headers) match {\n          case Some(value) => Some(value.parseBody())\n          case None => None\n        }\n        case Right(value) => Some(BodyParser.getParser(value, headers).get.parseBody())\n      },\n      headers\n    )\n\n    if (response.code.isClientError || response.code.isServerError) Left(responseEntity)\n    else Right(responseEntity)\n  }\n}\n```\n\n## Ensure stability of API package\n\nA primary motivation for this rewrite is to minimize the impact of a library going end-of-life (EOL) in the future. If the STTP library becomes unsupported, we should only need to make a single line change in our code, ensuring the rest of the classes remain unaffected.\n\nIn the `SttpClient` implementation, the access modifier is set to `protected[api]`. This restricts access to within the `api` package, preventing direct usage outside. To facilitate client access, we define an `ApiClient` object in the same file as the `ApiClient` trait. This object includes an `apply()` method that creates a new instance of `SttpClient`, leveraging its position within the `api` subpackage.\n\n```scala\nobject ApiClient {\n  def apply() = new SttpClient()\n}\n```\n\nIn the event that the STTP library goes EOL, we would need to:\n\n1. Implement a new authentication wrapper for the replacement library.\n    \n2. Implement the new library's client (similar to `SttpClient`).\n    \n3. Update the `apply()` method in `ApiClient` to return an instance of the new client. This single-line change ensures that <mark>no other classes are impacted by the transition</mark>.\n    \n\n## Using the client\n\nWith the foundational components in place, we can now use the `ApiClient` to make an HTTP call. Here's an example of how to perform an API call using the implemented code:\n\n```scala\nval request = ApiRequestBuilder()\n  .withUrl(url)\n  .withMethod(POST)        // Refers to the case object POST created above\n  .withAuthentication(TokenAuth(token))\n  .withBody(JsonBody(\"\"\"{\"key\":\"value\"}\"\"\"))\n  .build()\n\nApiClient().send(request) match {\n  case Left(value) =>\n    throw new Exception(value.body.get)\n  case Right(ApiResponse(_, body, _)) =>\n    println(body.get)\n    println(\"API Call successful\")\n}\n```\n\nNote the use of `ApiClient()` to initiate the HTTP call. In Scala, `ApiClient()` is syntactic sugar that the compiler interprets as a call to the `ApiClient.apply()` method.\n\n## Adherence to SOLID Principles\n\n[SOLID](https://en.wikipedia.org/wiki/SOLID) is a set of five principles of Object-Oriented class design. They are a set of rules and best practices to follow while designing a class structure. These five principles help us understand the need for certain design patterns and software architecture in general. I always strive to adhere to these principles whenever I'm developing software, and we will now have a look at how the code above adheres to the SOLID Principles.\n\n### **S**ingle Responsibility Principle (SRP)\n\nA class should have one, and only one, reason to change. This principle promotes the separation of concerns within a system:\n\n* Our `HttpRequestBuilder` is solely responsible for building `HttpRequest` objects. It encapsulates the construction logic and provides an interface for setting request properties.\n    \n* The `BodyParser` isolates the logic for parsing different types of response bodies based on the content type, keeping this concern separate from other parts of the system\n    \n* Our `SttpClient` implementation handles the responsibility of sending HTTP requests and processing responses. It doesn't concern itself with the construction of requests or parsing of response bodies, which are handled by other classes.\n    \n* `ApiResponse` encapsulates the response data, separating it from the request logic and the client implementation.\n    \n* `ApiAuth` and its various subclasses have a single responsibility to apply a specific authentication mechanism.\n    \n\n### **O**pen/Closed Principle (OCP)\n\nSoftware entities should be open for extension but closed for modification. This means you can extend the behavior of a class without modifying its source code:\n\n* The `Body` trait and its subclasses allow for easy addition of new body types without altering existing code. For example, adding a new `CsvBody` would involve creating a new case class that extends `Body`.\n    \n* New implementations of `ApiClient` can be created (e.g., `JavaApiClient`, `Http4sApiClient`) without modifying the existing `SttpClient`. Each new client implementation can provide its own logic for sending requests.\n    \n* New authentication methods can be added by creating new classes that implement the `Authentication` trait.\n    \n\n### **L**iskov Substitution Principle (LSP)\n\nObjects of a superclass should be replaceable with objects of a subclass without affecting the correctness of the program:\n\n* Anywhere a `Body` is expected, any of its subclasses (`JsonBody`, `XmlBody`, etc.) can be used interchangeably.\n    \n* The system can use `TokenAuthentication` or `BasicAuthentication` interchangeably wherever `Authentication` is expected, ensuring the `applyTo` method works correctly for any subclass.\n    \n\n### **I**nterface Segregation Principle (ISP)\n\nNo client should be forced to depend on methods it does not use. This principle advocates for smaller, more specific interfaces:\n\n* `ApiAuth` **Interface**: This interface is specifically for adding authentication to a request and does not include other unrelated methods. It ensures that only relevant methods are exposed to classes that implement this interface.\n    \n* `ApiClient` **Interface**: Defines a minimal interface for sending HTTP requests. It does not force implementing classes to expose unnecessary methods.\n    \n\n### **D**ependency Inversion Principle (DIP)\n\nHigh-level modules should not depend on low-level modules. Both should depend on abstractions. Abstractions should not depend on details. Details should depend on abstractions:\n\n* `ApiClient` **Interface**: The high-level code (such as a service using the HTTP client) depends on the `ApiClient` abstraction, not on specific implementations like `SttpClient`.\n    \n* **Dependency on Abstractions**: The system uses the `ApiAuth`, `ApiBody`, and `ApiClient` abstractions rather than concrete implementations, making it easy to swap out implementations as needed.\n    \n\n## Conclusion\n\nThe goal was to modernize our HTTP client classes, moving from a rigid, outdated pieces to a flexible, modular architecture. By focusing on a clean separation of concerns and employing design patterns like Builder, Factory and Singleton, we created a robust framework that enhances maintainability and scalability.\n\nKey features include a modular request builder, an extensible authentication wrapper, and a consistent handling of API responses. The new design ensures easy adaptability to future changes, such as switching out libraries or updating security protocols, with minimal impact on the overall system.\n\nThis streamlined, adaptable architecture not only addresses previous limitations but also positions our product for future growth and technological advancements.\n\nCode used inside this post is also available inside my [GitHub repo](https://github.com/Sparker0i/API-Scala-with-SOLID-Principles).","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1722975091604/d8fadfca-3058-46c3-9fd9-7ac6950354e5.webp","brief":"We've been developing an AI-enabled data engineering product at our company, using Scala as the core programming language. We also utilize Scala-related frameworks like Spark and Play to power various components. Recently, we conducted a vulnerabilit...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":false,"readTime":14,"draft":"66b112a8fe7530ff05685d84","tags":[],"publication":"5cdd04921a7cb8b20267646b","metaTitle":"Refactor tightly coupled Codebase Using SOLID Principles","metaDescription":"Refactor your tightly coupled codebase using SOLID principles to improve maintainability, modularity, and security.","isNewsletterActivated":true,"coAuthors":[],"dateUpdated":"2024-08-06T22:02:48.656Z","pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"66b29d4c63629cc69724f054"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"_id":"661c07fb9bb70e9dac2bfedf","createdAt":"2024-04-14T16:44:43.896Z","updatedAt":"2024-08-06T22:02:48.663Z","views":197,"isActive":true,"hasLatex":false,"popularity":6748.1493,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"How to use Devcontainers to create apps with x86 architecture on an Apple Silicon Mac","cuid":"cluzrarcn000308jwavxf3j6q","dateAdded":"2024-04-09T15:51:58.000Z","hasCustomDate":true,"slug":"running-vs-code-devcontainers-with-x86-runtime-apple-silicon","content":"<p><em>UPDATE 25th June 2024: Modified the article to include podman alongside colima.</em></p>\n<p>Apps are a significant part of our lives today. There are various apps you might be using today. On a smartphone, you would be using WhatsApp, Snapchat, Instagram, YouTube and various other apps. On a PC/laptop, you would be using a browser, game launchers to start your favorite games and IDEs to develop applications.</p>\n<p>Many websites you know and love are apps themselves. As an example, the Facebook website is written using the React framework and packaged as a Web application to run in a browser. YouTube and various other websites by Google are written in the Angular framework and packaged as web apps too.</p>\n<p>To develop any kind of major applications, you would need a PC or a laptop and an IDE installed. There are various kinds of IDEs available based on the programming language and the kind of application you are developing. You would also need various libraries to create your application - lest write the code yourself. Which leads to the problem I'll be tackling in today's post.</p>\n<h2 id=\"heading-background\">Background</h2>\n<p>PCs and laptops sold today run on x86 architecture CPUs made by Intel and AMD. However in recent times, we have started to see a lot of laptops being sold with the CPUs using ARM architecture, which until recently was found only in mobile phones. Not only are these CPUs way more battery efficient, they also allow to wake a laptop from sleep a lot quicker than x86 based laptops. Most notable ARM based laptops are manufactured by Apple, which use the Apple Silicon chips - M1, M2, M3 etc.</p>\n<p>Like I've explained before when you are looking to build an application, you'd need various libraries to write code. Most libraries in the various programming languages are universal, ie. they are compatible to run on the architecture of your machine's CPU. However, there are some libraries which do not run (yet) on an ARM machine.</p>\n<p>The most notable culprit for this is the <a target=\"_blank\" href=\"https://www.npmjs.com/package/ibm_db?ref=localhost\">ibm_db</a> library on Node. If you try to install that package on your Apple Silicon mac, you will see this error:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113078489/9da41139-2d53-4bff-aa5e-8708e6bf7632.jpeg\" alt /></p>\n<p>Error installing ibm_db directly on the Apple Silicon MacBook</p>\n<p>Yup, it suggests to install the x64 version of NodeJS and then use the package. I had so many other NodeJS applications on my machine without ibm_db which were working pretty well, so I did not want to install an inefficient version of NodeJS for my machine. But I also had to work on this important project on the M1 mac for my org. I was in a dilemma. Enter <strong>devcontainers</strong>:</p>\n<h2 id=\"heading-devcontainers\">Devcontainers</h2>\n<p>From its website, A devcontainer allows you to use a container as a full-featured development environment. It can be used to run an application, to separate tools, libraries, or runtimes needed for working with a codebase, and to aid in continuous integration and testing.</p>\n<p>This is very similar to how Python's venv (Virtual Environments) work. Usually, all Python developers need that to do any basic development. But one key difference with devcontainers is that it opens your project folder inside a Docker container, and then any packages you install in the devcontainer remains inside that and does not cross over to your host machine.</p>\n<p>While the devcontainer spec is Open source and available independently, Visual Studio Code provides an easy way (UI) of doing stuff with it. Using devcontainers, I'll be trying to run my NodeJS app with the ibm_db dependency on my MacBook with Apple Silicon.</p>\n<h2 id=\"heading-create-the-virtual-machine\">Create the Virtual Machine</h2>\n<p>Docker - or for that matter any of the open source containerization software - cannot run as is on a machine without a Linux Kernel. You'll need a Linux virtual machine that acts as the place where all your containers will be run. The simplest solution to do this is to create a VM using <a target=\"_blank\" href=\"https://github.com/abiosoft/colima?ref=localhost\">Colima</a> or <a target=\"_blank\" href=\"https://podman.io\">Podman</a>.</p>\n<p>Here is the command to create a machine using Colima:</p>\n<pre><code class=\"lang-plaintext\">colima start --cpu 2 --memory 4 --disk 50 --arch aarch64 --vm-type=vz --mount-type=virtiofs --vz-rosetta --very-verbose\n</code></pre>\n<ul>\n<li><p>The CPU, Memory and Disk parameters should be very obvious here.</p>\n</li>\n<li><p><code>--very-verbose</code> is to see more detailed logging while the VM starts. It is useful to debug if anything is going wrong or not.</p>\n</li>\n<li><p><code>--arch aarch64</code> tells the Lima CLI to create the VM with the ARM64 architecture. You cannot directly create an x86 machine on an ARM MacBook just like that. The next two options will help enable what I want to do.</p>\n</li>\n<li><p><code>--vm-type=vz</code> will use the new MacOS <a target=\"_blank\" href=\"https://developer.apple.com/documentation/virtualization?language=objc&amp;ref=localhost\">Virtualization API</a> to create the VMs.</p>\n</li>\n<li><p><code>--vz-rosetta</code> will use Rosetta translation layer when interacting with the VM.</p>\n</li>\n<li><p><code>--mount-type=virtiofs</code> creates a VM with the virtiofs volume driver. This allows you to share files from your host machine inside the Container.</p>\n</li>\n</ul>\n<p>Using the VZ APIs along with the virtiofs mount enables better performance running the VM.</p>\n<p>As of Podman 5.1, Rosetta translation layer is supported by default. If you have been using Podman for your other projects but holding back to the emulation issues, you may start using it instead of colima. Here is the command to create and start a similar VM for Podman:</p>\n<pre><code class=\"lang-plaintext\">podman machine init --cpus=2 --memory=2048 --disk-size=50\npodman machine start\n</code></pre>\n<p>It doesn't matter what option you choose, any further steps from hereon are independent of your choice of Containerization Framework.</p>\n<h2 id=\"heading-create-base-image-for-the-container\">Create base image for the Container</h2>\n<p>Devcontainer runs your code inside a Docker container. The basic principle of running a Docker Container requires you to have a base image on top of which any operations can be performed.</p>\n<p>In this case I want to develop a NodeJS app which utilizes the ibm_db library. So I will need a base image with NodeJS installed. Thankfully, Microsoft provides base Docker images that work well with devcontainers inside VS Code. I'll be using a base image which comes with NodeJS 20 installed.</p>\n<p>To create the base image I will use in my application, I will need to SSH into the Virtual Machine using the command and then create the base image from there. If you try to create the base image from your host terminal, the image gets created with the ARM architecture, which is not helpful for us as we want the image with an x86 architecture.</p>\n<p>This is the <code>Dockerfile</code> I will be using:</p>\n<pre><code class=\"lang-dockerfile\"><span class=\"hljs-keyword\">FROM</span> --platform=linux/amd64 mcr.microsoft.com/devcontainers/typescript-node:<span class=\"hljs-number\">20</span>-bookworm \n<span class=\"hljs-keyword\">RUN</span><span class=\"bash\"> uname -a</span>\n</code></pre>\n<p>Dockerfile contents</p>\n<p>To create the image, run the following commands:</p>\n<ol>\n<li><p><code>colima ssh</code></p>\n</li>\n<li><p><code>export DOCKER_DEFAULT_PLATFORM=linux/amd64</code></p>\n</li>\n<li><p>Command to build image:</p>\n<ol>\n<li><p><code>docker build --no-cache --platform linux/amd64 --progress plain -t node20-amd64-localhost:latest .</code> (For Colima)</p>\n</li>\n<li><p><code>podman build --no-cache --platform linux/amd64 --progress plain -t node20-amd64-localhost:latest .</code> (For Podman)</p>\n</li>\n</ol>\n</li>\n<li><p><code>exit</code></p>\n</li>\n</ol>\n<p>Once you build this image, you should see the output like below for the <code>uname</code> command. If you don't see the <code>x86_64</code> like I've highlighted, then you might have not followed the guide properly:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113079651/dbc607e1-1bb5-4bc5-bf36-3f71b5774630.jpeg\" alt=\"Output from Colima VM\" /></p>\n<p><em>PS: If you are using Podman and had a Podman VM created before installing v5.1, you may have to delete that VM and create another one in its place</em> <strong><em>if you don't see x86_64</em></strong> <em>as highlighted above. That will ensure that any new VMs created will have Rosetta translation layer by default.</em></p>\n<h2 id=\"heading-run-your-project-inside-a-devcontainer\">Run your project inside a Devcontainer</h2>\n<p>I won't be using any sample project for this article, as you may use any of your x86 based projects you wish to emulate inside a Devcontainer. To do that, you will need to create a folder called <code>.devcontainer</code>, inside which you need to have two files: <code>devcontainer.json</code> and <code>Dockerfile</code>.</p>\n<p>The contents of the <code>Dockerfile</code> is a single line which uses the base image that we had built in one of the previous sections:</p>\n<pre><code class=\"lang-dockerfile\"><span class=\"hljs-keyword\">FROM</span> --platform=linux/amd64 node20-amd64-localhost:latest\n</code></pre>\n<p>The <code>devcontainer.json</code> would contain the following contents (Please do not copy the comments as is, it is only meant to explain what each line does:</p>\n<pre><code class=\"lang-json\">{\n  <span class=\"hljs-attr\">\"name\"</span>: <span class=\"hljs-string\">\"NodeJS with Typescript installed to build angular apps using x86-only libraries\"</span>,\n  <span class=\"hljs-attr\">\"dockerfile\"</span>: <span class=\"hljs-string\">\"Dockerfile\"</span>,\n  <span class=\"hljs-attr\">\"runArgs\"</span>: [<span class=\"hljs-string\">\"-v\"</span>, <span class=\"hljs-string\">\"${localWorkspaceFolder}:/workspace:cached\"</span>],\n  <span class=\"hljs-attr\">\"customizations\"</span>: {\n    <span class=\"hljs-attr\">\"vscode\"</span>: {\n      <span class=\"hljs-attr\">\"extensions\"</span>: [\n        <span class=\"hljs-string\">\"ms-azuretools.vscode-docker\"</span>\n      ]\n    }\n  },\n  <span class=\"hljs-attr\">\"remoteUser\"</span>: <span class=\"hljs-string\">\"root\"</span>,\n  <span class=\"hljs-attr\">\"forwardPorts\"</span>: [<span class=\"hljs-number\">3000</span>]\n}\n</code></pre>\n<p>In line 4, <code>${localWorkspaceFolder}</code> refers to your project's location on the host machine, <code>/workspace</code> is where your project files be mounted inside the devcontainer and the <code>:cached</code> option is used to improve performance in Docker when mounting volumes.</p>\n<p>I want to use the user <code>root</code> inside my devcontainer so that I don't need to do a <code>sudo</code> everytime to install an npm package inside the container. I'm forwarding the port 3000 from my container to my host machine as my NodeJS express app uses that port to listen onto requests.</p>\n<p>Once you are done with these two files, open your project inside VSCode, then install the <a target=\"_blank\" href=\"https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers&amp;ref=localhost\">Devcontainers</a> extension, Reload the window, press Cmd+Shift+P and then type <code>Reopen in Container</code> and click on that option. This will build your Container image, mount your project and make it available inside <code>/workspace</code> in the container and then you should be able to emulate projects using x86 libraries inside the devcontainer on your machine.</p>\n<p>To test that it works, I will try to install the <code>ibm_db</code> package from within the container, and here's how that went:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113080972/7c5e0791-1363-4fd2-acb1-caafad5f6468.jpeg\" alt /></p>\n<p>That went nicely. Now I need to run my app and see whether it is able to connect to my Database using this library or not:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113082099/3cb9bb56-1433-45e0-ad11-b0a25fe83e9c.jpeg\" alt /></p>\n<p>Yup it did connect well.</p>\n<h3 id=\"heading-why-am-i-using-colima\">Why am I using Colima</h3>\n<p>Colima has support for emulating x86 based VMs using the Rosetta 2 translation layer on Apple Silicon Macs. This is important as we needed ibm_db to work. I also think that building x86 images on ARM platforms will become common, as soon as ARM based laptops from Apple and others start becoming mainstream.</p>\n<p>Moreover, I've not yet found another easier way to create and run a Docker machine using CLI commands. Of course there's Docker Desktop which gives a nice GUI, but its <a target=\"_blank\" href=\"https://www.docker.com/blog/updating-product-subscriptions/?ref=localhost\">license change</a> in 2022 wrecked havoc on many companies. Our org had to ban the installs of Docker Desktop completely. I have had to migrate to Podman <a target=\"_blank\" href=\"https://blog.sparker0i.me/podman-best-docker-alternative/?ref=localhost\">in the past</a> due to this. <s>While it was fun, it didn't help me solve my problem. Which brings us to:</s> Podman v5.1 now supports the Rosetta translation layer.</p>\n<h3 id=\"heading-why-not-qemu\">Why not QEMU?</h3>\n<p>I did try using QEMU based emulation by typing <code>colima start --arch x86_64 -p qemu</code> but, While that worked okay, as in it started the container and I was able to run my app, I discovered that for my NodeJS based application it wasn't really as efficient. Also, my M1 MacBook was heating up like it hadn't done ever before. What is the point of having an M1 Mac if it's going to behave the same as the Intel ones. Thus I felt using Rosetta based emulation was better for me.</p>\n<h3 id=\"heading-colima-vs-podman\">Colima vs Podman</h3>\n<p>I've updated the blog post in June 2024 with the instructions for Podman as well. Thus a performance comparison between both options was also needed. In real world performance on your Apple Silicon based machine, you will not notice any difference between using your projects with a Docker VM (through Colima) or a Podman VM.</p>\n<p>If you have a keen eye though, you'd notice that operations with Podman did finish 1-2s faster than on Colima. Even building the first <code>node20-amd64</code> image on Podman took 2s lesser than that on Colima, despite using the same internet for both. If I were to make a guess, it could be due to one peculiar output I noticed when creating the first image on the Podman VM.</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1719268113345/586a406d-2e96-4a6e-a747-f8d0701d3ea0.jpeg\" alt=\"Output from Podman VM\" class=\"image--center mx-auto\" /></p>\n<p>Here I can see two things: <code>SMP</code> and <code>PREEMPT_DYNAMIC</code>, which were not available when I created the VM inside Colima. With a simple Google Search, I found <a target=\"_blank\" href=\"https://learn.farizizwan.com/infrastructure/system-administration-linux/redhat-derivatives/smp-preempt_dynamic-definitions\">this website</a> which helped explain both these things. In a nutshell, a combination of both those strings allows you to utilize resources better while providing better responsiveness.</p>\n<h3 id=\"heading-how-about-windows\">How about Windows?</h3>\n<p>While ARM based Windows laptops are set to make a debut later in 2024, I don't believe there will be too much to be done to get it to work. There's WSL which exists already, and one has to watch out how the x86 emulation plays out on these ARM machines using the Snapdragon X chips. If that ends up like how Rosetta has played out so far, all we'll need is for WSL and its distros to support doing the same as well. Things are not yet clear on that front, and I will try to update my article as soon as the picture is clear.</p>\n<h2 id=\"heading-conclusion\">Conclusion</h2>\n<p>Right now I've just shown one example where I had to run an NodeJS app with x86 libraries on an M1 based Mac without spinning up a full fledged VM like inside VirtualBox or VMWare. You can also extend this concept to various other languages having x86-only libraries like Python etc.</p>\n","contentMarkdown":"*UPDATE 25th June 2024: Modified the article to include podman alongside colima.*\n\nApps are a significant part of our lives today. There are various apps you might be using today. On a smartphone, you would be using WhatsApp, Snapchat, Instagram, YouTube and various other apps. On a PC/laptop, you would be using a browser, game launchers to start your favorite games and IDEs to develop applications.\n\nMany websites you know and love are apps themselves. As an example, the Facebook website is written using the React framework and packaged as a Web application to run in a browser. YouTube and various other websites by Google are written in the Angular framework and packaged as web apps too.\n\nTo develop any kind of major applications, you would need a PC or a laptop and an IDE installed. There are various kinds of IDEs available based on the programming language and the kind of application you are developing. You would also need various libraries to create your application - lest write the code yourself. Which leads to the problem I'll be tackling in today's post.\n\n## Background\n\nPCs and laptops sold today run on x86 architecture CPUs made by Intel and AMD. However in recent times, we have started to see a lot of laptops being sold with the CPUs using ARM architecture, which until recently was found only in mobile phones. Not only are these CPUs way more battery efficient, they also allow to wake a laptop from sleep a lot quicker than x86 based laptops. Most notable ARM based laptops are manufactured by Apple, which use the Apple Silicon chips - M1, M2, M3 etc.\n\nLike I've explained before when you are looking to build an application, you'd need various libraries to write code. Most libraries in the various programming languages are universal, ie. they are compatible to run on the architecture of your machine's CPU. However, there are some libraries which do not run (yet) on an ARM machine.\n\nThe most notable culprit for this is the [ibm\\_db](https://www.npmjs.com/package/ibm_db?ref=localhost) library on Node. If you try to install that package on your Apple Silicon mac, you will see this error:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113078489/9da41139-2d53-4bff-aa5e-8708e6bf7632.jpeg align=\"left\")\n\nError installing ibm\\_db directly on the Apple Silicon MacBook\n\nYup, it suggests to install the x64 version of NodeJS and then use the package. I had so many other NodeJS applications on my machine without ibm\\_db which were working pretty well, so I did not want to install an inefficient version of NodeJS for my machine. But I also had to work on this important project on the M1 mac for my org. I was in a dilemma. Enter **devcontainers**:\n\n## Devcontainers\n\nFrom its website, A devcontainer allows you to use a container as a full-featured development environment. It can be used to run an application, to separate tools, libraries, or runtimes needed for working with a codebase, and to aid in continuous integration and testing.\n\nThis is very similar to how Python's venv (Virtual Environments) work. Usually, all Python developers need that to do any basic development. But one key difference with devcontainers is that it opens your project folder inside a Docker container, and then any packages you install in the devcontainer remains inside that and does not cross over to your host machine.\n\nWhile the devcontainer spec is Open source and available independently, Visual Studio Code provides an easy way (UI) of doing stuff with it. Using devcontainers, I'll be trying to run my NodeJS app with the ibm\\_db dependency on my MacBook with Apple Silicon.\n\n## Create the Virtual Machine\n\nDocker - or for that matter any of the open source containerization software - cannot run as is on a machine without a Linux Kernel. You'll need a Linux virtual machine that acts as the place where all your containers will be run. The simplest solution to do this is to create a VM using [Colima](https://github.com/abiosoft/colima?ref=localhost) or [Podman](https://podman.io).\n\nHere is the command to create a machine using Colima:\n\n```plaintext\ncolima start --cpu 2 --memory 4 --disk 50 --arch aarch64 --vm-type=vz --mount-type=virtiofs --vz-rosetta --very-verbose\n```\n\n* The CPU, Memory and Disk parameters should be very obvious here.\n    \n* `--very-verbose` is to see more detailed logging while the VM starts. It is useful to debug if anything is going wrong or not.\n    \n* `--arch aarch64` tells the Lima CLI to create the VM with the ARM64 architecture. You cannot directly create an x86 machine on an ARM MacBook just like that. The next two options will help enable what I want to do.\n    \n* `--vm-type=vz` will use the new MacOS [Virtualization API](https://developer.apple.com/documentation/virtualization?language=objc&ref=localhost) to create the VMs.\n    \n* `--vz-rosetta` will use Rosetta translation layer when interacting with the VM.\n    \n* `--mount-type=virtiofs` creates a VM with the virtiofs volume driver. This allows you to share files from your host machine inside the Container.\n    \n\nUsing the VZ APIs along with the virtiofs mount enables better performance running the VM.\n\nAs of Podman 5.1, Rosetta translation layer is supported by default. If you have been using Podman for your other projects but holding back to the emulation issues, you may start using it instead of colima. Here is the command to create and start a similar VM for Podman:\n\n```plaintext\npodman machine init --cpus=2 --memory=2048 --disk-size=50\npodman machine start\n```\n\nIt doesn't matter what option you choose, any further steps from hereon are independent of your choice of Containerization Framework.\n\n## Create base image for the Container\n\nDevcontainer runs your code inside a Docker container. The basic principle of running a Docker Container requires you to have a base image on top of which any operations can be performed.\n\nIn this case I want to develop a NodeJS app which utilizes the ibm\\_db library. So I will need a base image with NodeJS installed. Thankfully, Microsoft provides base Docker images that work well with devcontainers inside VS Code. I'll be using a base image which comes with NodeJS 20 installed.\n\nTo create the base image I will use in my application, I will need to SSH into the Virtual Machine using the command and then create the base image from there. If you try to create the base image from your host terminal, the image gets created with the ARM architecture, which is not helpful for us as we want the image with an x86 architecture.\n\nThis is the `Dockerfile` I will be using:\n\n```dockerfile\nFROM --platform=linux/amd64 mcr.microsoft.com/devcontainers/typescript-node:20-bookworm \nRUN uname -a\n```\n\nDockerfile contents\n\nTo create the image, run the following commands:\n\n1. `colima ssh`\n    \n2. `export DOCKER_DEFAULT_PLATFORM=linux/amd64`\n    \n3. Command to build image:\n    \n    1. `docker build --no-cache --platform linux/amd64 --progress plain -t node20-amd64-localhost:latest .` (For Colima)\n        \n    2. `podman build --no-cache --platform linux/amd64 --progress plain -t node20-amd64-localhost:latest .` (For Podman)\n        \n4. `exit`\n    \n\nOnce you build this image, you should see the output like below for the `uname` command. If you don't see the `x86_64` like I've highlighted, then you might have not followed the guide properly:\n\n![Output from Colima VM](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113079651/dbc607e1-1bb5-4bc5-bf36-3f71b5774630.jpeg align=\"left\")\n\n*PS: If you are using Podman and had a Podman VM created before installing v5.1, you may have to delete that VM and create another one in its place* ***if you don't see x86\\_64*** *as highlighted above. That will ensure that any new VMs created will have Rosetta translation layer by default.*\n\n## Run your project inside a Devcontainer\n\nI won't be using any sample project for this article, as you may use any of your x86 based projects you wish to emulate inside a Devcontainer. To do that, you will need to create a folder called `.devcontainer`, inside which you need to have two files: `devcontainer.json` and `Dockerfile`.\n\nThe contents of the `Dockerfile` is a single line which uses the base image that we had built in one of the previous sections:\n\n```dockerfile\nFROM --platform=linux/amd64 node20-amd64-localhost:latest\n```\n\nThe `devcontainer.json` would contain the following contents (Please do not copy the comments as is, it is only meant to explain what each line does:\n\n```json\n{\n  \"name\": \"NodeJS with Typescript installed to build angular apps using x86-only libraries\",\n  \"dockerfile\": \"Dockerfile\",\n  \"runArgs\": [\"-v\", \"${localWorkspaceFolder}:/workspace:cached\"],\n  \"customizations\": {\n    \"vscode\": {\n      \"extensions\": [\n        \"ms-azuretools.vscode-docker\"\n      ]\n    }\n  },\n  \"remoteUser\": \"root\",\n  \"forwardPorts\": [3000]\n}\n```\n\nIn line 4, `${localWorkspaceFolder}` refers to your project's location on the host machine, `/workspace` is where your project files be mounted inside the devcontainer and the `:cached` option is used to improve performance in Docker when mounting volumes.\n\nI want to use the user `root` inside my devcontainer so that I don't need to do a `sudo` everytime to install an npm package inside the container. I'm forwarding the port 3000 from my container to my host machine as my NodeJS express app uses that port to listen onto requests.\n\nOnce you are done with these two files, open your project inside VSCode, then install the [Devcontainers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers&ref=localhost) extension, Reload the window, press Cmd+Shift+P and then type `Reopen in Container` and click on that option. This will build your Container image, mount your project and make it available inside `/workspace` in the container and then you should be able to emulate projects using x86 libraries inside the devcontainer on your machine.\n\nTo test that it works, I will try to install the `ibm_db` package from within the container, and here's how that went:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113080972/7c5e0791-1363-4fd2-acb1-caafad5f6468.jpeg align=\"left\")\n\nThat went nicely. Now I need to run my app and see whether it is able to connect to my Database using this library or not:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113082099/3cb9bb56-1433-45e0-ad11-b0a25fe83e9c.jpeg align=\"left\")\n\nYup it did connect well.\n\n### Why am I using Colima\n\nColima has support for emulating x86 based VMs using the Rosetta 2 translation layer on Apple Silicon Macs. This is important as we needed ibm\\_db to work. I also think that building x86 images on ARM platforms will become common, as soon as ARM based laptops from Apple and others start becoming mainstream.\n\nMoreover, I've not yet found another easier way to create and run a Docker machine using CLI commands. Of course there's Docker Desktop which gives a nice GUI, but its [license change](https://www.docker.com/blog/updating-product-subscriptions/?ref=localhost) in 2022 wrecked havoc on many companies. Our org had to ban the installs of Docker Desktop completely. I have had to migrate to Podman [in the past](https://blog.sparker0i.me/podman-best-docker-alternative/?ref=localhost) due to this. <s>While it was fun, it didn't help me solve my problem. Which brings us to:</s> Podman v5.1 now supports the Rosetta translation layer.\n\n### Why not QEMU?\n\nI did try using QEMU based emulation by typing `colima start --arch x86_64 -p qemu` but, While that worked okay, as in it started the container and I was able to run my app, I discovered that for my NodeJS based application it wasn't really as efficient. Also, my M1 MacBook was heating up like it hadn't done ever before. What is the point of having an M1 Mac if it's going to behave the same as the Intel ones. Thus I felt using Rosetta based emulation was better for me.\n\n### Colima vs Podman\n\nI've updated the blog post in June 2024 with the instructions for Podman as well. Thus a performance comparison between both options was also needed. In real world performance on your Apple Silicon based machine, you will not notice any difference between using your projects with a Docker VM (through Colima) or a Podman VM.\n\nIf you have a keen eye though, you'd notice that operations with Podman did finish 1-2s faster than on Colima. Even building the first `node20-amd64` image on Podman took 2s lesser than that on Colima, despite using the same internet for both. If I were to make a guess, it could be due to one peculiar output I noticed when creating the first image on the Podman VM.\n\n![Output from Podman VM](https://cdn.hashnode.com/res/hashnode/image/upload/v1719268113345/586a406d-2e96-4a6e-a747-f8d0701d3ea0.jpeg align=\"center\")\n\nHere I can see two things: `SMP` and `PREEMPT_DYNAMIC`, which were not available when I created the VM inside Colima. With a simple Google Search, I found [this website](https://learn.farizizwan.com/infrastructure/system-administration-linux/redhat-derivatives/smp-preempt_dynamic-definitions) which helped explain both these things. In a nutshell, a combination of both those strings allows you to utilize resources better while providing better responsiveness.\n\n### How about Windows?\n\nWhile ARM based Windows laptops are set to make a debut later in 2024, I don't believe there will be too much to be done to get it to work. There's WSL which exists already, and one has to watch out how the x86 emulation plays out on these ARM machines using the Snapdragon X chips. If that ends up like how Rosetta has played out so far, all we'll need is for WSL and its distros to support doing the same as well. Things are not yet clear on that front, and I will try to update my article as soon as the picture is clear.\n\n## Conclusion\n\nRight now I've just shown one example where I had to run an NodeJS app with x86 libraries on an M1 based Mac without spinning up a full fledged VM like inside VirtualBox or VMWare. You can also extend this concept to various other languages having x86-only libraries like Python etc.","brief":"UPDATE 25th June 2024: Modified the article to include podman alongside colima.\nApps are a significant part of our lives today. There are various apps you might be using today. On a smartphone, you would be using WhatsApp, Snapchat, Instagram, YouTub...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/running-vs-code-devcontainers-with-x86-runtime-apple-silicon/","readTime":10,"tags":[],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-08-06T22:02:45.431Z","disableComments":false,"enableToc":true,"isCoverAttributionHidden":false,"metaTitle":"[Updated] Emulate x86 apps on an Apple Silicon Mac using Devcontainers","ogImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113542484/5938ad11-d22b-4915-91ad-1eb34cdb9130.jpeg","slugOverridden":false,"stickCoverToBottom":true,"subtitle":"Certain apps and libraries never want to update with time, thus you end up with emulation","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113803173/5e23bd54-6b41-4c71-bdc6-dff896c61bb7.jpeg","viewsUpdatedOn":1713349840789,"toc":[[{"id":"ad4a17da-f02d-4553-8aa8-52ed9b8bafe0","level":2,"previousLevel":null,"parentId":null,"slug":"background","title":"Background"}],[{"id":"afd18c75-6c49-4285-9dbe-faccd6788da4","level":2,"previousLevel":2,"parentId":null,"slug":"devcontainers","title":"Devcontainers"}],[{"id":"677f7e59-e6c8-469b-94a1-a2db03413dc3","level":2,"previousLevel":2,"parentId":null,"slug":"create-the-virtual-machine","title":"Create the Virtual Machine"}],[{"id":"2b94074d-222c-44f5-bf3e-46f22ee30b9d","level":2,"previousLevel":2,"parentId":null,"slug":"create-base-image-for-the-container","title":"Create base image for the Container"}],[{"id":"d4e3560b-2460-4487-8c79-db3ab8468e2c","level":2,"previousLevel":2,"parentId":null,"slug":"run-your-project-inside-a-devcontainer","title":"Run your project inside a Devcontainer"}],[{"id":"9daa0af7-f3e6-4260-8d8c-6e7e3883854e","level":3,"previousLevel":2,"parentId":"d4e3560b-2460-4487-8c79-db3ab8468e2c","slug":"why-am-i-using-colima","title":"Why am I using Colima"}],[{"id":"3e7968ed-2250-4ff5-b6fb-5ddc27529427","level":3,"previousLevel":3,"parentId":"d4e3560b-2460-4487-8c79-db3ab8468e2c","slug":"why-not-qemu","title":"Why not QEMU?"}],[{"id":"b7da3d9d-0aea-4940-a11a-3591285e9a66","level":3,"previousLevel":3,"parentId":"d4e3560b-2460-4487-8c79-db3ab8468e2c","slug":"colima-vs-podman","title":"Colima vs Podman"}],[{"id":"26a44525-7ea7-4ccb-9e5a-9bbd8094047f","level":3,"previousLevel":3,"parentId":"d4e3560b-2460-4487-8c79-db3ab8468e2c","slug":"how-about-windows","title":"How about Windows?"}],[{"id":"f70617e0-040b-4b61-9834-2e680a4738d4","level":2,"previousLevel":3,"parentId":null,"slug":"conclusion","title":"Conclusion"}]],"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c07fb9bb70e9dac2bfedf"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c08015ae500253ce7927c","createdAt":"2024-04-14T16:44:49.681Z","updatedAt":"2024-08-07T19:01:46.108Z","views":5,"isActive":false,"hasLatex":false,"popularity":5332.7623,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Podman with Desktop Companion: The best alternative to Docker Desktop","cuid":"cluzravtc000408l764rccchl","dateAdded":"2022-04-03T11:31:44.000Z","hasCustomDate":true,"slug":"podman-best-docker-alternative--deleted","content":"<p>Containers and Docker have always been synonymous to the ears since eternity. For most of us, Docker has been the go-to tool for containerization - a way to pack a software application and all dependencies into an image that can be run anywhere. This allows application to remain separate from the infrastructure so that the app works regardless of where it runs.</p>\n<p>While working on multiple applications in my company, I had been using Docker Desktop as my containerization platform of choice, on my company provided MacBooks to build and debug application images. But we were dealt with a blow a few months ago when it was announced that effective January 31st 2022, Docker Desktop will <a target=\"_blank\" href=\"https://www.docker.com/blog/updating-product-subscriptions/?ref=localhost\">require a license for enterprises</a> with more than 250 employees. Unfortunately, my company IBM fell into Docker's categorization of an enterprise.</p>\n<p>Naturally, I started looking at all available alternatives, given that Docker desktop annual subscription per user costs $250. Unfortunately there was no clear winner which could replicate everything that Docker Desktop could do - GUI support, Built in Kubernetes, Environments, Integration with IDEs etc. But all I needed was something with which I could build images locally in a secure manner and run containers locally, with an optional support of a GUI.</p>\n<p>Enter:</p>\n<h2 id=\"heading-podman\">Podman</h2>\n<p>Podman is a CLI tool that provides a Docker-compatible API. It is open source and published by Red Hat. The biggest advantage over Docker is that it is a Daemonless container engine which runs the containers in a rootless state by default. This brings in additional security layer, because even if the container engine, runtime or the orchestrator is compromized, the attacker won't gain any root privileges on the host - which is a flaw in Docker's architecture. You can read <a target=\"_blank\" href=\"https://www.imaginarycloud.com/blog/podman-vs-docker?ref=localhost\">this article</a> to understand the finer points of difference between Docker and Podman.</p>\n<p>Installation of Podman 4 is fairly simple on MacOS (using brew). Unfortunately for Linux based Operating Systems, only Fedora has an unofficial COPR that allows you to install Podman 4, while for other Operating Systems you have to build from source code in order to install podman 4.</p>\n<p>Once you install the podman binary, all you need to do is execute the below two commands for MacOS:</p>\n<pre><code class=\"lang-plaintext\">podman machine init\npodman machine start\n</code></pre>\n<p>This will start a Fedora CoreOS based VM in the background having podman installed. Once you have started this Podman VM, Almost all Docker CLI commands are compatible with Podman as well - <code>run</code>, <code>exec</code>, <code>push</code> etc. It brings zero impact to the developers that operate on CLI - how you build images and whatever you do with that image using the Docker CLI remains the same. You can also add <a target=\"_blank\" href=\"https://podman.io/whatis.html?ref=localhost\"><code>alias docker=podman</code></a> to <code>~/.zshrc</code> (MacOS) or <code>~/.bash_profile</code> (Linux) so that you don't need to keep reminding yourself to use podman instead of Docker.</p>\n<p>The CLI route is easy for users who have been working with Docker CLI. However what about those users who have been primarily using the Docker Desktop GUI for their workflows? Enter:</p>\n<h2 id=\"heading-podman-desktop-companion\">Podman Desktop Companion</h2>\n<p><a target=\"_blank\" href=\"https://iongion.github.io/podman-desktop-companion/?ref=localhost\">Podman Desktop Companion</a> is a third-party app, which is an almost adequate drop-in replacement for the Docker Desktop GUI. Since this is not an official app, there are a few features this app lacks, most notably the absence of Kubernetes - though this won't be a big deal for those who only want the containerization features of Podman. Here's a screenshot of the app running on my MacBook:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113087599/bc163f7c-0948-4378-ab5b-f995df78a27b.png\" alt /></p>\n<p>Podman Desktop Companion makes you feel right at home with the look and feel of Docker Desktop</p>\n<p>Feels familiar, doesn't it? Unfortunately, the process to install this app is not as straightforward. For a MacBook, you will need to install <code>lima-vm</code>, an app that launches Linux virtual machines with automatic file sharing and port forwarding - very similar to what WSL2 does, just that it is mostly for MacOS but can also be used on various Linux distros as well. Unfortunately if you want to proceed to the next step, you will have to stop the <code>podman machine</code> you had created earlier.</p>\n<p>Lima offers the ability to create VMs using their sample YAML templates or by supplying user written YAML. When you create a VM with the Podman Template YAML, the VM will be running Podman v3. This lacks some key features from Podman 4 including Volume and Device mounts, as well as a vastly improved Network stack. Thus you will have to use a custom YAML if you want to install Podman 4.</p>\n<p>You need to ensure that the name of this VM is <code>podman</code>. This is necessary for the Desktop Companion (This dependency on a specific VM name is a bad programming practice on the part of the Desktop Companion creator, but since this is a Beta version we can forgive them for now until they release a stable version). You can do this by running <code>limactl start --name=podman /location/of/the/yaml/from/below</code>. To make things easier for you, I've written a YAML that worked well for me. You need to save this to a location and use the location of this YAML in the command above.</p>\n<pre><code class=\"lang-yaml\"><span class=\"hljs-attr\">images:</span>\n<span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">location:</span> <span class=\"hljs-string\">\"https://download.fedoraproject.org/pub/fedora/linux/releases/35/Cloud/x86_64/images/Fedora-Cloud-Base-35-1.2.x86_64.qcow2\"</span>\n  <span class=\"hljs-attr\">arch:</span> <span class=\"hljs-string\">\"x86_64\"</span>\n  <span class=\"hljs-attr\">digest:</span> <span class=\"hljs-string\">\"sha256:fe84502779b3477284a8d4c86731f642ca10dd3984d2b5eccdf82630a9ca2de6\"</span>\n<span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">location:</span> <span class=\"hljs-string\">\"https://download.fedoraproject.org/pub/fedora/linux/releases/35/Cloud/aarch64/images/Fedora-Cloud-Base-35-1.2.aarch64.qcow2\"</span>\n  <span class=\"hljs-attr\">arch:</span> <span class=\"hljs-string\">\"aarch64\"</span>\n  <span class=\"hljs-attr\">digest:</span> <span class=\"hljs-string\">\"sha256:c71f2e6ce75b516d565e2c297ea9994c69b946cb3eaa0a4bbea400dbd6f59ae6\"</span>\n<span class=\"hljs-attr\">cpus:</span> <span class=\"hljs-number\">4</span>\n<span class=\"hljs-attr\">memory:</span> <span class=\"hljs-number\">8</span> <span class=\"hljs-string\">GiB</span>\n<span class=\"hljs-attr\">disk:</span> <span class=\"hljs-number\">50</span> <span class=\"hljs-string\">GiB</span>\n<span class=\"hljs-attr\">mounts:</span>\n<span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">location:</span> <span class=\"hljs-string\">\"~\"</span>\n<span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">location:</span> <span class=\"hljs-string\">\"/tmp/lima\"</span>\n  <span class=\"hljs-attr\">writable:</span> <span class=\"hljs-literal\">true</span>\n<span class=\"hljs-attr\">containerd:</span>\n  <span class=\"hljs-attr\">system:</span> <span class=\"hljs-literal\">false</span>\n  <span class=\"hljs-attr\">user:</span> <span class=\"hljs-literal\">false</span>\n<span class=\"hljs-attr\">provision:</span>\n<span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">mode:</span> <span class=\"hljs-string\">system</span>\n  <span class=\"hljs-attr\">script:</span> <span class=\"hljs-string\">|\n    #!/bin/bash\n    dnf copr enable rhcontainerbot/podman4 -y\n    dnf update\n    dnf install -y podman crun\n</span><span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">mode:</span> <span class=\"hljs-string\">user</span>\n  <span class=\"hljs-attr\">script:</span> <span class=\"hljs-string\">|\n    #!/bin/bash\n    set -eux -o pipefail\n    systemctl --user enable --now podman.socket\n</span><span class=\"hljs-attr\">probes:</span>\n<span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">script:</span> <span class=\"hljs-string\">|\n    #!/bin/bash\n    set -eux -o pipefail\n    if ! timeout 30s bash -c \"until command -v podman &gt;/dev/null 2&gt;&amp;1; do sleep 3; done\"; then\n      echo &gt;&amp;2 \"podman is not installed yet\"\n      exit 1\n    fi\n</span>  <span class=\"hljs-attr\">hint:</span> <span class=\"hljs-string\">See</span> <span class=\"hljs-string\">\"/var/log/cloud-init-output.log\"</span><span class=\"hljs-string\">.</span> <span class=\"hljs-string\">in</span> <span class=\"hljs-string\">the</span> <span class=\"hljs-string\">guest</span>\n<span class=\"hljs-attr\">portForwards:</span>\n<span class=\"hljs-bullet\">-</span> <span class=\"hljs-attr\">guestSocket:</span> <span class=\"hljs-string\">\"/run/user/<span class=\"hljs-template-variable\">{{.UID}}</span>/podman/podman.sock\"</span>\n  <span class=\"hljs-attr\">hostSocket:</span> <span class=\"hljs-string\">\"<span class=\"hljs-template-variable\">{{.Dir}}</span>/sock/podman.sock\"</span>\n<span class=\"hljs-attr\">message:</span> <span class=\"hljs-string\">|\n  To run `podman` on the host (assumes podman-remote is installed), run the following commands:\n  ------\n  export CONTAINER_HOST=$(limactl list podman --format 'unix://{{.Dir}}/sock/podman.sock')\n  podman system connection add lima \"unix://{{.Dir}}/sock/podman.sock\"\n  podman system connection default lima\n  podman{{if eq .HostOS \"linux\"}} --remote{{end}} run quay.io/podman/hello\n  ------</span>\n</code></pre>\n<p>I'm using a Fedora Base VM Image because there is a custom COPR available which can install Podman v4 in the VM image. Then once I'm done installing Podman and crun on the VM, I'm forwarding the VM's socket to a socket on the host machine. This is needed so for the Desktop companion to establish connection and verify services running on the guest VM.</p>\n<p>Once the VM is installed and started, you also need 4 other commands on the host to notify the podman remote CLI to connect to the guest VM rather than listening on the host. Thus once you are done installing Lima, Podman Remote CLI on Host, Podman on Lima VM and the Desktop Companion, you will feel right at home, without missing Docker Desktop.</p>\n","contentMarkdown":"Containers and Docker have always been synonymous to the ears since eternity. For most of us, Docker has been the go-to tool for containerization - a way to pack a software application and all dependencies into an image that can be run anywhere. This allows application to remain separate from the infrastructure so that the app works regardless of where it runs.\n\nWhile working on multiple applications in my company, I had been using Docker Desktop as my containerization platform of choice, on my company provided MacBooks to build and debug application images. But we were dealt with a blow a few months ago when it was announced that effective January 31st 2022, Docker Desktop will [require a license for enterprises](https://www.docker.com/blog/updating-product-subscriptions/?ref=localhost) with more than 250 employees. Unfortunately, my company IBM fell into Docker's categorization of an enterprise.\n\nNaturally, I started looking at all available alternatives, given that Docker desktop annual subscription per user costs $250. Unfortunately there was no clear winner which could replicate everything that Docker Desktop could do - GUI support, Built in Kubernetes, Environments, Integration with IDEs etc. But all I needed was something with which I could build images locally in a secure manner and run containers locally, with an optional support of a GUI.\n\nEnter:\n\n## Podman\n\nPodman is a CLI tool that provides a Docker-compatible API. It is open source and published by Red Hat. The biggest advantage over Docker is that it is a Daemonless container engine which runs the containers in a rootless state by default. This brings in additional security layer, because even if the container engine, runtime or the orchestrator is compromized, the attacker won't gain any root privileges on the host - which is a flaw in Docker's architecture. You can read [this article](https://www.imaginarycloud.com/blog/podman-vs-docker?ref=localhost) to understand the finer points of difference between Docker and Podman.\n\nInstallation of Podman 4 is fairly simple on MacOS (using brew). Unfortunately for Linux based Operating Systems, only Fedora has an unofficial COPR that allows you to install Podman 4, while for other Operating Systems you have to build from source code in order to install podman 4.\n\nOnce you install the podman binary, all you need to do is execute the below two commands for MacOS:\n\n```plaintext\npodman machine init\npodman machine start\n```\n\nThis will start a Fedora CoreOS based VM in the background having podman installed. Once you have started this Podman VM, Almost all Docker CLI commands are compatible with Podman as well - `run`, `exec`, `push` etc. It brings zero impact to the developers that operate on CLI - how you build images and whatever you do with that image using the Docker CLI remains the same. You can also add [`alias docker=podman`](https://podman.io/whatis.html?ref=localhost) to `~/.zshrc` (MacOS) or `~/.bash_profile` (Linux) so that you don't need to keep reminding yourself to use podman instead of Docker.\n\nThe CLI route is easy for users who have been working with Docker CLI. However what about those users who have been primarily using the Docker Desktop GUI for their workflows? Enter:\n\n## Podman Desktop Companion\n\n[Podman Desktop Companion](https://iongion.github.io/podman-desktop-companion/?ref=localhost) is a third-party app, which is an almost adequate drop-in replacement for the Docker Desktop GUI. Since this is not an official app, there are a few features this app lacks, most notably the absence of Kubernetes - though this won't be a big deal for those who only want the containerization features of Podman. Here's a screenshot of the app running on my MacBook:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113087599/bc163f7c-0948-4378-ab5b-f995df78a27b.png align=\"left\")\n\nPodman Desktop Companion makes you feel right at home with the look and feel of Docker Desktop\n\nFeels familiar, doesn't it? Unfortunately, the process to install this app is not as straightforward. For a MacBook, you will need to install `lima-vm`, an app that launches Linux virtual machines with automatic file sharing and port forwarding - very similar to what WSL2 does, just that it is mostly for MacOS but can also be used on various Linux distros as well. Unfortunately if you want to proceed to the next step, you will have to stop the `podman machine` you had created earlier.\n\nLima offers the ability to create VMs using their sample YAML templates or by supplying user written YAML. When you create a VM with the Podman Template YAML, the VM will be running Podman v3. This lacks some key features from Podman 4 including Volume and Device mounts, as well as a vastly improved Network stack. Thus you will have to use a custom YAML if you want to install Podman 4.\n\nYou need to ensure that the name of this VM is `podman`. This is necessary for the Desktop Companion (This dependency on a specific VM name is a bad programming practice on the part of the Desktop Companion creator, but since this is a Beta version we can forgive them for now until they release a stable version). You can do this by running `limactl start --name=podman /location/of/the/yaml/from/below`. To make things easier for you, I've written a YAML that worked well for me. You need to save this to a location and use the location of this YAML in the command above.\n\n```yaml\nimages:\n- location: \"https://download.fedoraproject.org/pub/fedora/linux/releases/35/Cloud/x86_64/images/Fedora-Cloud-Base-35-1.2.x86_64.qcow2\"\n  arch: \"x86_64\"\n  digest: \"sha256:fe84502779b3477284a8d4c86731f642ca10dd3984d2b5eccdf82630a9ca2de6\"\n- location: \"https://download.fedoraproject.org/pub/fedora/linux/releases/35/Cloud/aarch64/images/Fedora-Cloud-Base-35-1.2.aarch64.qcow2\"\n  arch: \"aarch64\"\n  digest: \"sha256:c71f2e6ce75b516d565e2c297ea9994c69b946cb3eaa0a4bbea400dbd6f59ae6\"\ncpus: 4\nmemory: 8 GiB\ndisk: 50 GiB\nmounts:\n- location: \"~\"\n- location: \"/tmp/lima\"\n  writable: true\ncontainerd:\n  system: false\n  user: false\nprovision:\n- mode: system\n  script: |\n    #!/bin/bash\n    dnf copr enable rhcontainerbot/podman4 -y\n    dnf update\n    dnf install -y podman crun\n- mode: user\n  script: |\n    #!/bin/bash\n    set -eux -o pipefail\n    systemctl --user enable --now podman.socket\nprobes:\n- script: |\n    #!/bin/bash\n    set -eux -o pipefail\n    if ! timeout 30s bash -c \"until command -v podman >/dev/null 2>&1; do sleep 3; done\"; then\n      echo >&2 \"podman is not installed yet\"\n      exit 1\n    fi\n  hint: See \"/var/log/cloud-init-output.log\". in the guest\nportForwards:\n- guestSocket: \"/run/user/{{.UID}}/podman/podman.sock\"\n  hostSocket: \"{{.Dir}}/sock/podman.sock\"\nmessage: |\n  To run `podman` on the host (assumes podman-remote is installed), run the following commands:\n  ------\n  export CONTAINER_HOST=$(limactl list podman --format 'unix://{{.Dir}}/sock/podman.sock')\n  podman system connection add lima \"unix://{{.Dir}}/sock/podman.sock\"\n  podman system connection default lima\n  podman{{if eq .HostOS \"linux\"}} --remote{{end}} run quay.io/podman/hello\n  ------\n```\n\nI'm using a Fedora Base VM Image because there is a custom COPR available which can install Podman v4 in the VM image. Then once I'm done installing Podman and crun on the VM, I'm forwarding the VM's socket to a socket on the host machine. This is needed so for the Desktop companion to establish connection and verify services running on the guest VM.\n\nOnce the VM is installed and started, you also need 4 other commands on the host to notify the podman remote CLI to connect to the guest VM rather than listening on the host. Thus once you are done installing Lima, Podman Remote CLI on Host, Podman on Lima VM and the Desktop Companion, you will feel right at home, without missing Docker Desktop.","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113916620/decd93bc-f7e5-43a6-9f7c-627237903b30.jpeg","brief":"Containers and Docker have always been synonymous to the ears since eternity. For most of us, Docker has been the go-to tool for containerization - a way to pack a software application and all dependencies into an image that can be run anywhere. This...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/podman-best-docker-alternative/","readTime":6,"tags":["56744721958ef13879b94b77","63259ae17ae3b59ef0062b69","5c4082769719c1a710fefd34"],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T17:08:41.775Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":true,"stickCoverToBottom":true,"subtitle":"Docker Desktop is no longer free for the enterprise. Podman helps you fill the void left by Docker. Know more about it and the installation process.","dateDeleted":"2024-08-07T19:01:45.591Z","pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c08015ae500253ce7927c"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c08055610fb416dbc1885","createdAt":"2024-04-14T16:44:53.434Z","updatedAt":"2024-04-14T18:19:21.342Z","views":17,"isActive":true,"hasLatex":false,"popularity":4871.388,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Factors to look at while dealing with Cryptocurrencies","cuid":"cluzraypm000e08jshvc32qx3","dateAdded":"2021-08-06T04:20:59.000Z","hasCustomDate":true,"slug":"factors-to-look-dealing-crypto","content":"<p>Crypto-currencies are a hot subject today. From seeing multiple bull-runs, to governments trying to destroy the movement of sovereign independence,  to countries adopting Bitcoin as a legal tender, cryptocurrencies have come a long way. I have been holding crypto-currencies since 2019, but it was only at the start of this year that I actually started trading and buying them.</p>\n<p>Now, if you ask anyone online about which crypto to buy, you will be frequently met with the term #DYOR - Do Your Own Research. Same was with me as well, whenever I've asked people on tips, I was told to #DYOR, but there were not many tips online about what to do in DYOR. Like many in the beginning, I've had my shares of success and failures in crypto hodling and trading. Here are a few tips I follow when looking to buy tokens.</p>\n<h2 id=\"heading-initial-research-and-filtering-bad-assets\">Initial Research and Filtering Bad Assets</h2>\n<p>Before I hodl or trade any tokens, I make sure to do some initial research with a few pointers. I'd feel great about those tokens that meet this initial criteria, while others become a big no-go for the rest of my life (unless something drastically changes in that particular crypto's tech, but would be unlikely).</p>\n<p>The first thing I do is visit CoinMarketCap website, search for the particular crypto I'm looking to hodl or invest. Every major crypto asset listed on CoinMarketCap will have its own website, and that is the first thing I always look at. Within the website, the first thing you should read is the <strong>Whitepaper</strong> of the token. When you read through the various pages on a particular crypto's website, I am able to mostly detect any non-sense or BS. If it uses any terms or protocols that you find it hard to comprehend - like it \"<strong>promises</strong>\" a huge payout or claims to have some tech that seems to good to be true (like self-mining) - immediately avoid it.</p>\n<p>You should also look for some more things like Roadmap of features for the particular project and the track record on how it has delivered so far on all those features. If a project has consistently failed or lagged behind to deliver new features, you should treat it as another yellow flag. I'd also look at how the crypto's tech functions and the value a token is trying to create. If there are no unique use-cases or if the crypto does not require/benefit from the use of blockchain fundamentals, I'd give it a red flag and move on.</p>\n<p>Another thing that you should really look at is the Blockchain Explorer for a given crypto. First thing I'd check here is the max supply for the given crypto. Needless to say, stablecoins are a no-go here. If there's no max supply for a token, it is usually a Red Flag from my side, although there are a very few exceptions for this - like Ethereum. If you still want to go ahead and deal with cryptos without a max supply, you should do it at your own risk and must usually look to own it only for the short-term and not hodl them.</p>\n<p>Next thing you should look at is the distribution of tokens across all wallet holders of the given token. If you see that one wallet holds more than 15-20% of the total current supply, I'd raise a red flag here. The moment a big whale dumps (sells) all those coins, the entire crypto will start reeling. Best example would be Vitalik Buterin <a target=\"_blank\" href=\"https://www.nzherald.co.nz/business/ethereum-co-founder-vitalik-buterin-destroys-410-trillion-shiba-inu-coins/VCNH2FDFQYRVDD6U3Q6VFYZ2XQ/?ref=localhost\">dumping 45% of the entire Shiba Inu coins in supply</a>, causing a massive drop in the price of the Shiba Inu coin. (More surprising in the case of Shiba Inu is that the Whitepaper of the coin still refers Buterin as a visionary - \"like its anonymous founder\" - even after he dumped the project's worth)</p>\n<p>Some other pointers that you can consider to research would be browsing the source code of a given asset on GitHub and the amount of activity in its repos in the recent past. As an alternate means, try going through the blogs and subreddit of the given token and look for any threads that look skeptical to you.</p>\n<h2 id=\"heading-avoid-scams\">Avoid Scams</h2>\n<p>When you start off dealing with cryptos, you would be looking at ways to maximize money instantly. While I'd say it is not impossible, but I would advise you to not do that. Lured by the opportunity of making quick money, people might fall into the trap of crypto scams.</p>\n<p>Most of these scams happen on Telegram within groups which usually advertise quick money making schemes in the form of Token Airdrops. They will mostly look to lure you with \"verified\" token deposit screenshots from customers. These \"customers\" are either running the scam along with the admins of the group, or are accounts managed by the admins themselves. If you look to participate in such airdrops, you will end up losing all your life savings.</p>\n<p>However, I'm not saying all airdrops are bad. Some of them that have happened - like the Stellar Airdrops in 2017 and 2019. But that was done by a verified entity - the Stellar Foundation. Here we are talking about Telegram groups that are run by Anonymous Users. Such groups are always Bait and Scam, and I would recommend you to avoid them.</p>\n<h2 id=\"heading-fill-out-an-investment-checklist\">Fill out an Investment Checklist</h2>\n<p>Once I'm done filtering out the coins I invest in, I look to create an investment checklist where I have noted certain questions that I ask before I invest in a coin. Here are the details of the questions:</p>\n<ul>\n<li><p><strong>What is the problem that a crypto is trying to solve?</strong> Like I mentioned in the previous section, if a token does not serve a purpose or does not solve a problem - not just with blockchains or the financial sector, but any sector, say Education or Supply Chain - I believe there is no reason for that coin to exist. Such coins are only hype driven and only good for short-term trading. I will call such hype-driven coins as <strong>Shitcoins</strong> from now. Hodling them for a long term will leave you reeling.</p>\n</li>\n<li><p><strong>What is the Dev Team like? What is their track record? How are they funded, organized?</strong> I will look for is the history of some of the Lead members on a project and see what they have worked on previously - via information they post online (say on LinkedIn). If they are anonymous members (exception: Satoshi Nakamoto, the creator of Bitcoin), I'll automatically raise a Red flag on that crypto and move on. Then, I will also look at how they are funded. Whether they have partnerships with Enterprises or they have solved a critical problem for any pillar of the society - say government or law - or any other major piece of news regarding any advancement that was made possible because of a crypto.</p>\n</li>\n<li><p><strong>Who is their competition and how big is the market they're targeting?</strong> What is the roadmap they created? Like I've mentioned in the previous section, you should always have a look at the roadmap for a given token. No roadmap -&gt; No progress -&gt; Red Flag. Also you need to look at the other coins being offered in the market and how do they compete with the token you're looking to buy. Because healthy competition always leads to success, unless you're looking for a shitcoin, or the competitors of a given token are all shitcoins.</p>\n</li>\n<li><p><strong>Is there a staking mechanism or is it transactional?</strong> There are cryptos which rely on various types of consensus mechanisms - Proof of Work (PoW), Proof of Stake (PoS), Proof of Time and Space etc.</p>\n</li>\n<li><p><strong>How does the token/coin actually derive value for the holder?</strong></p>\n</li>\n<li><p><strong>What are the weaknesses or problems with this crypto?</strong> Of course there can never be some shortcoming associated with a given crypto. If there are none, it sounds too good to be true. (Even for Bitcoin, there's only one disadvantage that I can think about - Electricity consumption. But that too is definitely lesser than electricity used for mining actual Gold, or by the entire banking system around the world)</p>\n</li>\n</ul>\n<h2 id=\"heading-create-a-valuation-framework-for-a-token\">Create a Valuation Framework for a token</h2>\n<p>With the boom that crypto trading has seen since November 2020, you must always be sure of what coins you want to invest in. I've been a part of various crypto groups on multiple sites like Facebook and Reddit. In it, I've seen a lot of people complain about the losses they've had to made while dealing with crypto, because they either bought high and then the market went bearish, or they invested in the pump-and-dump shitcoins.</p>\n<p>To avoid becoming one among such people, you need to have a certain valuation model for a given crypto. Even if you create a basic one, you'll go miles ahead of your peers/other people. Here are some simple things you can consider doing:</p>\n<ul>\n<li><p>Look at the total market cap of the coin and compare it with the size of the market it is trying to address. Market cap here includes not only the circulating supply, but also the max supply possible for the crypto.</p>\n</li>\n<li><p>Check for the total number of users of a given token. I believe that the value of a given crypto would be proportional to the number of users using the crypto. The best known crypto out there is Bitcoin and there are almost 100 Million people already using it. Compounded with its scarcity, its scale and community is why Bitcoin carries a huge value.</p>\n</li>\n</ul>\n<p>These were 2 very basic checks that I do for any crypto. I might add some other checks in the evaluation framework as well. Once you have a model setup, you can then evaluate one crypto against another, and also see why you would want to own this coin rather than do short-term trading. Doing this will lead you to think long term about dealing with a given crypto and think more about the \"value\" it provides.</p>\n<p>Once you do this, you will have more mental peace and have good confidence for your decision making. You would also not panic when there are any short-term price dips.</p>\n<h2 id=\"heading-portfolio-allocation\">Portfolio Allocation</h2>\n<p>This is one of the crucial aspects of your journey with crypto. You should think on how much fiat you can use to buy crypto, as well as how do you want to allocate your crypto portfolio between \"safe\" and \"rigged\" cryptos. (planned pump-and-dump, shitcoins etc.). If you're just starting out, I would recommend you to not go with shitcoins to begin with. I have seen a few of my friends who started their crypto journeys because of celebrities who rig coins like Elon Musk and co. The peak of this came during Elon's SNL appearance. Despite my advice against it, most of my friends bought Dogecoin only because of Elon's appearance and thinking it's price will keep going up if they bought then. Little did they know that it was the starting point for dumping Dogecoin, whose effects can still be felt today. Many of my friends felt cheated, and some of them have left the crypto space despite my assurances that not all cryptos are bad.</p>\n<p>So if you're just starting out, I'd recommend having 80-90% of your portfolio filled with safe coins. Once you become more informed and confident, you can start dealing with Shitcoins and vary your portfolio allocation. You should also think in terms of crypto categories as well as the percentage of your portfolio in each of these segments. For starters, I categorise crypto into following categories: (You may disagree with how I'm grouping the cryptos, but we can agree to disagree)</p>\n<ul>\n<li><p>Core Holdings: Bitcoin (BTC), Litecoin (LTC)</p>\n</li>\n<li><p>Smart Contracts: Ethereum (ETH), Cardano (ADA), Polkadot (DOT), ALGO, Solana etc.</p>\n</li>\n<li><p>Crypto with Privacy?: Monero (XMR), ZCash</p>\n</li>\n<li><p>Intermediary with fiat dealings/Bank Settlement: Stellar (XLM), Ripple (XRP)</p>\n</li>\n<li><p>Enterprise Solutions: VeChain etc.</p>\n</li>\n<li><p>Promising: NANO, IOTA, RVN, Algo etc.</p>\n</li>\n<li><p>Coins without intrinsic value (Shitcoin): DOGE + the army of dog coins (Shiba, Kishu) etc.</p>\n</li>\n</ul>\n<p>You should also have a fair idea about the market conditions as there is a lot of uncertainty today, mostly due to policies+governments and others due to rigging shitcoins. Due to this uncertainty, you should best stick to the core holdings and then pick up coins in segments you are knowledgeable enough about. Example, if you don't know about Smart Contracts, how can you be sure that ALGO is a game changer?</p>\n<p>This is where portfolio diversification and allocation comes into place. You should look to diversify, but in the ever-changing world of crypto you shouldn't look to diversify way too much. It would be difficult for you to keep up with all the changes that have occurred across cryptos. I wouldn't recommend you to have more than 10-12 cryptos. If you have more, I would recommend you to consolidate to the few segments you are well knowledgeable about.</p>\n<h2 id=\"heading-learn-everyday\">Learn Everyday</h2>\n<p>If you aren't doing this already, read a bit daily on cryptocurrencies. There are decent YouTubers that talk about the market movements in the crypto space. You should also learn more about the underlying principles in the crypto space. More specifically, if you are not aware of basics like Proof-of-Work (PoW), Proof-of-Space (PoS), learn about it first.</p>\n<p>If you invest in stocks, one factor you would look for is what are the core offerings of a given company and how it performs against other peers. If you don't know about how the underlying technology of a crypto works, learn about it as well. That will increase your belief if you want to buy that crypto. If you don't care about the underlying technology or find reading about it very tedious, I believe you shouldn't be in this crypto space at all and shouldn't look to invest here, otherwise you will feel betrayed after your coins' value gets dumped.</p>\n","contentMarkdown":"Crypto-currencies are a hot subject today. From seeing multiple bull-runs, to governments trying to destroy the movement of sovereign independence,  to countries adopting Bitcoin as a legal tender, cryptocurrencies have come a long way. I have been holding crypto-currencies since 2019, but it was only at the start of this year that I actually started trading and buying them.\n\nNow, if you ask anyone online about which crypto to buy, you will be frequently met with the term #DYOR - Do Your Own Research. Same was with me as well, whenever I've asked people on tips, I was told to #DYOR, but there were not many tips online about what to do in DYOR. Like many in the beginning, I've had my shares of success and failures in crypto hodling and trading. Here are a few tips I follow when looking to buy tokens.\n\n## Initial Research and Filtering Bad Assets\n\nBefore I hodl or trade any tokens, I make sure to do some initial research with a few pointers. I'd feel great about those tokens that meet this initial criteria, while others become a big no-go for the rest of my life (unless something drastically changes in that particular crypto's tech, but would be unlikely).\n\nThe first thing I do is visit CoinMarketCap website, search for the particular crypto I'm looking to hodl or invest. Every major crypto asset listed on CoinMarketCap will have its own website, and that is the first thing I always look at. Within the website, the first thing you should read is the **Whitepaper** of the token. When you read through the various pages on a particular crypto's website, I am able to mostly detect any non-sense or BS. If it uses any terms or protocols that you find it hard to comprehend - like it \"**promises**\" a huge payout or claims to have some tech that seems to good to be true (like self-mining) - immediately avoid it.\n\nYou should also look for some more things like Roadmap of features for the particular project and the track record on how it has delivered so far on all those features. If a project has consistently failed or lagged behind to deliver new features, you should treat it as another yellow flag. I'd also look at how the crypto's tech functions and the value a token is trying to create. If there are no unique use-cases or if the crypto does not require/benefit from the use of blockchain fundamentals, I'd give it a red flag and move on.\n\nAnother thing that you should really look at is the Blockchain Explorer for a given crypto. First thing I'd check here is the max supply for the given crypto. Needless to say, stablecoins are a no-go here. If there's no max supply for a token, it is usually a Red Flag from my side, although there are a very few exceptions for this - like Ethereum. If you still want to go ahead and deal with cryptos without a max supply, you should do it at your own risk and must usually look to own it only for the short-term and not hodl them.\n\nNext thing you should look at is the distribution of tokens across all wallet holders of the given token. If you see that one wallet holds more than 15-20% of the total current supply, I'd raise a red flag here. The moment a big whale dumps (sells) all those coins, the entire crypto will start reeling. Best example would be Vitalik Buterin [dumping 45% of the entire Shiba Inu coins in supply](https://www.nzherald.co.nz/business/ethereum-co-founder-vitalik-buterin-destroys-410-trillion-shiba-inu-coins/VCNH2FDFQYRVDD6U3Q6VFYZ2XQ/?ref=localhost), causing a massive drop in the price of the Shiba Inu coin. (More surprising in the case of Shiba Inu is that the Whitepaper of the coin still refers Buterin as a visionary - \"like its anonymous founder\" - even after he dumped the project's worth)\n\nSome other pointers that you can consider to research would be browsing the source code of a given asset on GitHub and the amount of activity in its repos in the recent past. As an alternate means, try going through the blogs and subreddit of the given token and look for any threads that look skeptical to you.\n\n## Avoid Scams\n\nWhen you start off dealing with cryptos, you would be looking at ways to maximize money instantly. While I'd say it is not impossible, but I would advise you to not do that. Lured by the opportunity of making quick money, people might fall into the trap of crypto scams.\n\nMost of these scams happen on Telegram within groups which usually advertise quick money making schemes in the form of Token Airdrops. They will mostly look to lure you with \"verified\" token deposit screenshots from customers. These \"customers\" are either running the scam along with the admins of the group, or are accounts managed by the admins themselves. If you look to participate in such airdrops, you will end up losing all your life savings.\n\nHowever, I'm not saying all airdrops are bad. Some of them that have happened - like the Stellar Airdrops in 2017 and 2019. But that was done by a verified entity - the Stellar Foundation. Here we are talking about Telegram groups that are run by Anonymous Users. Such groups are always Bait and Scam, and I would recommend you to avoid them.\n\n## Fill out an Investment Checklist\n\nOnce I'm done filtering out the coins I invest in, I look to create an investment checklist where I have noted certain questions that I ask before I invest in a coin. Here are the details of the questions:\n\n* **What is the problem that a crypto is trying to solve?** Like I mentioned in the previous section, if a token does not serve a purpose or does not solve a problem - not just with blockchains or the financial sector, but any sector, say Education or Supply Chain - I believe there is no reason for that coin to exist. Such coins are only hype driven and only good for short-term trading. I will call such hype-driven coins as **Shitcoins** from now. Hodling them for a long term will leave you reeling.\n    \n* **What is the Dev Team like? What is their track record? How are they funded, organized?** I will look for is the history of some of the Lead members on a project and see what they have worked on previously - via information they post online (say on LinkedIn). If they are anonymous members (exception: Satoshi Nakamoto, the creator of Bitcoin), I'll automatically raise a Red flag on that crypto and move on. Then, I will also look at how they are funded. Whether they have partnerships with Enterprises or they have solved a critical problem for any pillar of the society - say government or law - or any other major piece of news regarding any advancement that was made possible because of a crypto.\n    \n* **Who is their competition and how big is the market they're targeting?** What is the roadmap they created? Like I've mentioned in the previous section, you should always have a look at the roadmap for a given token. No roadmap -&gt; No progress -&gt; Red Flag. Also you need to look at the other coins being offered in the market and how do they compete with the token you're looking to buy. Because healthy competition always leads to success, unless you're looking for a shitcoin, or the competitors of a given token are all shitcoins.\n    \n* **Is there a staking mechanism or is it transactional?** There are cryptos which rely on various types of consensus mechanisms - Proof of Work (PoW), Proof of Stake (PoS), Proof of Time and Space etc.\n    \n* **How does the token/coin actually derive value for the holder?**\n    \n* **What are the weaknesses or problems with this crypto?** Of course there can never be some shortcoming associated with a given crypto. If there are none, it sounds too good to be true. (Even for Bitcoin, there's only one disadvantage that I can think about - Electricity consumption. But that too is definitely lesser than electricity used for mining actual Gold, or by the entire banking system around the world)\n    \n\n## Create a Valuation Framework for a token\n\nWith the boom that crypto trading has seen since November 2020, you must always be sure of what coins you want to invest in. I've been a part of various crypto groups on multiple sites like Facebook and Reddit. In it, I've seen a lot of people complain about the losses they've had to made while dealing with crypto, because they either bought high and then the market went bearish, or they invested in the pump-and-dump shitcoins.\n\nTo avoid becoming one among such people, you need to have a certain valuation model for a given crypto. Even if you create a basic one, you'll go miles ahead of your peers/other people. Here are some simple things you can consider doing:\n\n* Look at the total market cap of the coin and compare it with the size of the market it is trying to address. Market cap here includes not only the circulating supply, but also the max supply possible for the crypto.\n    \n* Check for the total number of users of a given token. I believe that the value of a given crypto would be proportional to the number of users using the crypto. The best known crypto out there is Bitcoin and there are almost 100 Million people already using it. Compounded with its scarcity, its scale and community is why Bitcoin carries a huge value.\n    \n\nThese were 2 very basic checks that I do for any crypto. I might add some other checks in the evaluation framework as well. Once you have a model setup, you can then evaluate one crypto against another, and also see why you would want to own this coin rather than do short-term trading. Doing this will lead you to think long term about dealing with a given crypto and think more about the \"value\" it provides.\n\nOnce you do this, you will have more mental peace and have good confidence for your decision making. You would also not panic when there are any short-term price dips.\n\n## Portfolio Allocation\n\nThis is one of the crucial aspects of your journey with crypto. You should think on how much fiat you can use to buy crypto, as well as how do you want to allocate your crypto portfolio between \"safe\" and \"rigged\" cryptos. (planned pump-and-dump, shitcoins etc.). If you're just starting out, I would recommend you to not go with shitcoins to begin with. I have seen a few of my friends who started their crypto journeys because of celebrities who rig coins like Elon Musk and co. The peak of this came during Elon's SNL appearance. Despite my advice against it, most of my friends bought Dogecoin only because of Elon's appearance and thinking it's price will keep going up if they bought then. Little did they know that it was the starting point for dumping Dogecoin, whose effects can still be felt today. Many of my friends felt cheated, and some of them have left the crypto space despite my assurances that not all cryptos are bad.\n\nSo if you're just starting out, I'd recommend having 80-90% of your portfolio filled with safe coins. Once you become more informed and confident, you can start dealing with Shitcoins and vary your portfolio allocation. You should also think in terms of crypto categories as well as the percentage of your portfolio in each of these segments. For starters, I categorise crypto into following categories: (You may disagree with how I'm grouping the cryptos, but we can agree to disagree)\n\n* Core Holdings: Bitcoin (BTC), Litecoin (LTC)\n    \n* Smart Contracts: Ethereum (ETH), Cardano (ADA), Polkadot (DOT), ALGO, Solana etc.\n    \n* Crypto with Privacy?: Monero (XMR), ZCash\n    \n* Intermediary with fiat dealings/Bank Settlement: Stellar (XLM), Ripple (XRP)\n    \n* Enterprise Solutions: VeChain etc.\n    \n* Promising: NANO, IOTA, RVN, Algo etc.\n    \n* Coins without intrinsic value (Shitcoin): DOGE + the army of dog coins (Shiba, Kishu) etc.\n    \n\nYou should also have a fair idea about the market conditions as there is a lot of uncertainty today, mostly due to policies+governments and others due to rigging shitcoins. Due to this uncertainty, you should best stick to the core holdings and then pick up coins in segments you are knowledgeable enough about. Example, if you don't know about Smart Contracts, how can you be sure that ALGO is a game changer?\n\nThis is where portfolio diversification and allocation comes into place. You should look to diversify, but in the ever-changing world of crypto you shouldn't look to diversify way too much. It would be difficult for you to keep up with all the changes that have occurred across cryptos. I wouldn't recommend you to have more than 10-12 cryptos. If you have more, I would recommend you to consolidate to the few segments you are well knowledgeable about.\n\n## Learn Everyday\n\nIf you aren't doing this already, read a bit daily on cryptocurrencies. There are decent YouTubers that talk about the market movements in the crypto space. You should also learn more about the underlying principles in the crypto space. More specifically, if you are not aware of basics like Proof-of-Work (PoW), Proof-of-Space (PoS), learn about it first.\n\nIf you invest in stocks, one factor you would look for is what are the core offerings of a given company and how it performs against other peers. If you don't know about how the underlying technology of a crypto works, learn about it as well. That will increase your belief if you want to buy that crypto. If you don't care about the underlying technology or find reading about it very tedious, I believe you shouldn't be in this crypto space at all and shouldn't look to invest here, otherwise you will feel betrayed after your coins' value gets dumped.","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713118284841/5cdf225b-aaaf-466b-9284-076eea5b15aa.jpeg","brief":"Crypto-currencies are a hot subject today. From seeing multiple bull-runs, to governments trying to destroy the movement of sovereign independence,  to countries adopting Bitcoin as a legal tender, cryptocurrencies have come a long way. I have been h...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/factors-to-look-dealing-crypto/","readTime":11,"tags":[],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T18:19:17.169Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":false,"stickCoverToBottom":true,"subtitle":"Ever wondered how to research crypto tokens before you buy them, but have no idea where to start? You've ended your search at the right place.","viewsUpdatedOn":1713119435048,"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c08055610fb416dbc1885"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c080c8442574e70467574","createdAt":"2024-04-14T16:45:00.786Z","updatedAt":"2024-04-14T17:12:07.349Z","views":2,"isActive":true,"hasLatex":false,"popularity":4496.924,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Is the state of targeted digital advertising broken?","cuid":"cluzrb4ds000j08l4ch525o24","dateAdded":"2021-01-23T03:33:00.000Z","hasCustomDate":true,"slug":"health-targeted-digital-advertising-today","content":"<p>Advertisements are everywhere - You see ads on your newspaper, your family sees ads on TV channels, there are ads on billboards seen by people in and around an area, and you too see ads on almost any website you visit.</p>\n<p>But, internet advertising industry is broken. It's failing the users and the advertisers themselves. Internet advertising majorly uses targeted/personalized ads to go after you and cater products you would most likely want. This ends up collecting as much data about you as it can.</p>\n<p>In this blog post, I will argue why the current model of internet advertising is bad, and how can you save yourself from being a victim of personalized ad targeting.</p>\n<h2 id=\"heading-a-regular-users-perspective-on-advertising\">A Regular User's Perspective on Advertising</h2>\n<p>If you ask me what are the problems with the current model of advertising online, here are a few things I might suggest:</p>\n<ul>\n<li><p>Ads violate privacy: There's no secret to this, internet advertising scoops up as much information about you from the services you visit and use.</p>\n</li>\n<li><p>Ads are disruptive: As an example, sometimes you click on a blank area in a website, you then see a new pop-up window with an ad, despite your browser blocking pop-ups</p>\n</li>\n<li><p>Ads are annoying: Sometimes you visit an interesting website, and the very next moment when you open a social media website, you start seeing ads about this almost everytime.</p>\n</li>\n<li><p>Malicious Ads: A vast majority of the people of my generation shouldn't be worried about Malicious ads, as our generation is aware about websites and malware, and we'd only visit website after due diligence. But our previous generations are not so well-informed about websites, they would click on any website and that site may end up spreading malware.</p>\n</li>\n</ul>\n<p>What I'm worried about is the first point - Digital Advertising violating our privacy. While our previous generations are not much aware about their Data Privacy, our current generation does worry about it.</p>\n<p>While we sit here, worrying about our privacy, IMF has \"suggested\" that a person's <a target=\"_blank\" href=\"https://gizmodo.com/your-credit-score-should-be-based-on-your-web-history-1845912592?ref=localhost\">credit history should be based on their Web History</a>. That's how ridiculous things may get in the future if things are not corrected today. A 2018 study by researchers at Data and Society <a target=\"_blank\" href=\"https://datasociety.net/wp-content/uploads/2018/10/DS_Digital_Influence_Machine.pdf?ref=localhost\">concluded</a> that “today’s digital advertising infrastructure creates disturbing new opportunities for political manipulation and other forms of antidemocratic strategic communication.”</p>\n<p>Even without concerns of privacy violations, there have been many efforts to try and fix some of the issues:</p>\n<ul>\n<li><p><a target=\"_blank\" href=\"https://www.betterads.org/?ref=localhost\">Coalition for Better Ads</a></p>\n</li>\n<li><p><a target=\"_blank\" href=\"https://acceptableads.com/?ref=localhost\">Acceptable Ads</a></p>\n</li>\n<li><p>Brave</p>\n</li>\n</ul>\n<p>These only fix some of the problems with Advertising in general, not the entire problem.</p>\n<h2 id=\"heading-attention-economy\">Attention Economy</h2>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113097050/0539926e-20df-47e5-b1d2-d29b2f29c14b.jpeg\" alt /></p>\n<p>Multiple advertisements craving for your attention</p>\n<p><a target=\"_blank\" href=\"https://medium.com/rsa-journal/democracy-distracted-cf3272ceb3c4?ref=localhost\">Herbert Simon argued in the 70s</a> that when information becomes abundant, attention becomes the scarce resource. In today's modern age, we’re living through the pendulum swing of that reversal—yet we consistently overlook its implications.</p>\n<p>When you visit any website or browse through any app, you take some time out of your life - or your <strong>attention</strong> to visit that resource. You are also using some of your attention to read this post (for which I'm eternally grateful). Now, you normally wouldn't take out some of this attention to visit a website that you haven't clicked by yourself. Thus, such websites/apps allow to advertise within itself (mostly as a small banner) via publishers, so that you don't have to take out extra time off your life just to visit the standalone ad. Then, such publishers use your \"actions\", and use such individualized data about you - collected via algorithms - and sell slots to advertisers to display ads.</p>\n<p>Wikipedia has a perfect definition for this - <a target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Attention_economy?ref=localhost\">Attention Economy</a>.</p>\n<p>Who wouldn't love to have an individualized feed of news. Sadly, individualization that happens today is neither for our own benefit nor for getting a peace of mind. Rather such a system only invites more outrage from us - users.</p>\n<p>Now, an incentive driven advertising system is good for the publishers, who earn good money; and advertisers, who get to sell lot more of their products. But this is bad for the user. There are literally billions of dollars being spent to figure out how to persuade you to look at a certain thing over a competitor's; to care about one thing over another. This is the way most of the information in this world is being monetized today.</p>\n<p>We can all see the effects of Attention Economy - Social Media websites like Twitter and Facebook never want people of different groups to stop fighting - be it over religion, sports or their political bias. This is because these networks are optimized in a way to promote fighting, or spread fake news/propaganda very quickly. You may argue that companies are investing to stop fake news, but I believe that it is still relatively minor as they don't really want their revenue streams to go down.</p>\n<h2 id=\"heading-my-take-on-digital-ads\">My take on digital ads</h2>\n<p>I don’t want any relevant ads, or any ad-driven products, ever. Other people might feel differently, but collecting the data is only half the problem. That data can be abused, even if only client-side - for example targeting could exploit you and persuade to buy stuff you don’t need. The whole point of ads is to change your behavior, if only slightly, with advertisers literally bidding for your attention, and then playing mind tricks, which work because of how our critical thinking often fails us a majority of the times.</p>\n<p>I believe great products have often been successful via word of mouth referrals. A great example would be <strong>Cred</strong>. Only a few credit card users in India were aware of the Cred before September 2020. That month, a delayed IPL 2020 started, and Cred ads - which a majority of the Indians never understood - was everywhere on TV, getting people's interest in knowing about the product, and eventually end up using it. There are tactics that don’t involve tricking people into changing their behavior. Conventional advertising is better than the targeted ones, because it’s not individualized. At least everybody else is seeing the same shit that you’re seeing.</p>\n<p>That brings us to the most important question - What should companies do? Honestly speaking, I don't think that's our problem. I don't think any company should be entitled to our data or our attention. When was the last time you ever saw an ad that made you feel this is the real deal. I haven't, have you?</p>\n<p>You know how the unethical behavior of companies is always excused via the requirement of company stakeholders to make money? Well, this goes both ways. We, the consumers, aren’t running any charity. I strongly feel it isn’t our job to save such dying business models.</p>\n<h3 id=\"heading-first-party-ads\">First Party Ads</h3>\n<p>One solution to the problem could be the content providers (websites/apps) serving ads based on content that is being viewed right now. This might ensure there is no need to keep user's profile and history. Your data will no longer be shared to third-parties and hence the quality of ads shown will get better - which also means no scam ads and no malvertising.</p>\n<p>This too has a problem. Even if there is a whitelist for “acceptable ads”, the problem is those ads are still downloaded Javascript code, with no way to review what they do. Further, third-party requests could get disguised as first-party ones. In such cases, you have to trust the publishers, which I'd usually find a hard time to do.</p>\n<h3 id=\"heading-then-wouldnt-ad-blocking-affect-the-internet\">Then, Wouldn't Ad-Blocking affect the Internet?</h3>\n<p>Given a choice between receiving ads, and no ads, sane people would obviously choose no ads. Nobody likes ads. If its forced, we have to gulp it down our throat, because either there's no clear alternative (Facebook), or the price of no-ads option is way too high (Youtube, Spotify, Apple Music, Hotstar et al.).</p>\n<p>Almost no browser ships with an aggressive ad-blocker enabled by default. This is because somewhere or the other, their business model is also dependent on ads, even if they don't serve ads directly. It will only make the end user's experience much better. Many browsers that claim to do aggressive ad-blocking like Microsoft Edge, Brave, Samsung, Vivaldi et al. earn a lot of money from advertising.</p>\n<p>Now, wouldn't ad-blocking affect the Internet's health? Yes, it will. Negatively, on the advertisers and publishers' wallets; Positively on the rest of the internet, because it can only get better from there on.</p>\n<h2 id=\"heading-solutions\">Solutions</h2>\n<h2 id=\"heading-pay-for-the-things-you-use\">Pay for the things you use</h2>\n<p>A wise man once said,</p>\n<blockquote>\n<p>\"If you are not paying for a product, <strong>you are the product</strong>\".</p>\n</blockquote>\n<p>If I really enjoy something, I don't mind paying for it. For example, I've been using <strong>Hey email</strong> since July. It did not catch my attention because of all the amazing features it brings, but rather because of its infamous <a target=\"_blank\" href=\"https://hey.com/apple/?ref=localhost\">feud with Apple</a>. In short, Hey is a radical re-thinking of what an Email client should be. As one Twitter user puts it:</p>\n<blockquote>\n<p>In positive news, <a target=\"_blank\" href=\"https://t.co/lwKSOQNcFe?ref=localhost\">https://t.co/lwKSOQNcFe</a> seems to have finally solved email (!!!). Been using it several weeks and no longer dealing with spam, long lists of “unread” messages, or sorting out annoying but important docs. The relief is so real 🙌🏼</p>\n<p>— Dr. Darya Rose 🇺🇸 (@summertomato) <a target=\"_blank\" href=\"https://twitter.com/summertomato/status/1270816132102930433?ref_src=twsrc%5Etfw&amp;ref=localhost\">June 10, 2020</a></p>\n</blockquote>\n<p>I've been using it so far without any major problems. All advertising mails are now screened out, so that they never take my attention again. I've changed emails for all my online accounts to reflect to my hey.com email address. Now there are certain services like stock and mutual fund brokers, whose email change process has to be offline. Once all of my services are moved over to Hey, I'm deleting all my non Hey mail accounts (except primary Google Play Store and Microsoft Store accounts, because all my app/in-app purchase history is sitting in those 2 accounts).</p>\n<p>Similarly, I'm also using <strong>Spotify Premium</strong> because I don't want myself to be exposed to their ads right after one song.</p>\n<p>I also pay for <strong>Xbox Game Pass for PC</strong>. It has more than 100 AAA PC games that I can easily play on my Lenovo Legion Y740 laptop. There are no ads in the games that are played via XGP. I regularly play Age of Empires 2: DE, Flight Simulator, Doom Eternal, Moto GP20 and The Outer Worlds. Buying all those games individually would've cost me a fortune, but at Rs 489/month (577 if you include taxes) it is a killer deal, specially for gamers like me. I am also using <strong>Kindle Unlimited</strong> for Reading as many Books as I can.</p>\n<p>With all the information I'm unearthing every single day about the shady practices of all developers, I'm removing all ads-enabled apps from my mobiles. Moreover, if I find that any app is sharing data that is unwanted, I promptly uninstall that app. If at all I really need to use the app's services which provide ads, I would find a browser-based alternative for it - Eg. Youtube, Twitter, Facebook, IG, Amazon + Entertainment apps.</p>\n<h2 id=\"heading-block-all-ads\">Block All Ads</h2>\n<p>Even if you may think that some ads are fine, but do you know whether those are targeted specifically to you or not? Even if there's a whitelist of \"acceptable ads\", it's still Javascript code downloaded from the internet, which I have no idea about its functionality. It's still intrusive, and drives you to buy things you don't really want.</p>\n<p>I really think it is wrong that Publishers think they can run code on our devices. If publishers think otherwise, they can feel free to block me from using their services. If I see any website that serves me ads (and gets caught by my ad blockers), I'd really start looking for alternatives.</p>\n<h3 id=\"heading-blocking-for-all-devices\">Blocking for all devices</h3>\n<p>DNS blocking has worked well so far. That is until apps/sites starting using DNS-over-HTTPS over their own servers. Still there are techniques to circumvent this too.</p>\n<p><strong>PiHole</strong>: I had a Raspberry Pi 3B sitting idle at home for the last 1 year or so. When I got to know that I could run a service like Pihole on it, I wasted no time to set it up. Ever since Christmas eve, I've been using Pihole to block ads for all the devices my family uses. And the stats are great too:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113098092/69ede8a4-a0cd-486d-9d56-7f128890c177.png\" alt /></p>\n<p>Pihole stats since December 23, 2020</p>\n<p>Though the only downside to this is that I've had to change my router to use static IP address assignment. There was some initial hassle in setting up my router and the devices, but once that was done, ads were a thing of the past (except Youtube ads, for which there is no working solution in 2021. Screw you, Google).</p>\n<p><strong>Hosted services</strong>: 3 months before trying out Pihole, I tried using NextDNS. While the results were incredible, I felt that giving away Rs. 159 every month (187 including taxes) was a bit too much for me. I've also heard about Adguard DNS, but I haven't used it so far.</p>\n<h2 id=\"heading-individual-devices\">Individual Devices</h2>\n<h3 id=\"heading-desktoplaptop-android-devices\">Desktop/Laptop + Android devices</h3>\n<p>Even before I've been using PiHole, I had experimented with ad blocking via browser extensions. The best combination I've found is Firefox + uBlock Origin + Privacy Badger. It simply works.</p>\n<p>uBlock Origin is by far the best ad blocker I've ever used. Ever since installing it, I've noticed far better loading speeds, because there are lesser resources to be loaded. It also protects against CNAME cloaking, where 3rd party requests masquerade as 1st party ones and you might not even notice it.</p>\n<p>Sadly, this won't work with Google Chrome and other Chromium forked browsers in the near future. This is because Manifest v3 for Chrome extensions will be deployed in Google Chrome sometime in January (with the release of v88). Simply put, Manifest is something any extension developer will have to follow while developing an extension. This particular Manifest v3 changes the way ad-blocking extensions function. This negatively impacts ad-blockers and uBlock is one of them.</p>\n<p>My take on this will be to ditch Chrome/Chromium forked browsers ASAP. Switch to Firefox while you still can, because Mozilla's financials aren't great, and the browser could go kaput anytime.</p>\n<p>The same combination also works well for Android as well, just that you will have to update the Firefox browser to whichever latest version is available.</p>\n<h3 id=\"heading-what-about-brave-browser\">What about Brave Browser?</h3>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113098974/3f42d5de-d923-4f65-8f9c-7d9aff8de5f4.jpeg\" alt /></p>\n<p>Brave browser displaying ads from Brave Network via OS notifications</p>\n<p>Brave is yet another Chromium fork which focuses on user privacy by blocking trackers, scripts and ads by default. So inside some pages where ads don't load properly, you might be forced to turn down Brave Shields, which will then open up the website to show you ads.</p>\n<p>By the time you've reached here, you must've realised that internet is up and running, all thanks to advertisements. The content you might be seeing for free is able to remain free because of advertising. This is profitable for both advertisers and publishers, but not the users.</p>\n<p>Brave attempts to change the advertising model by flipping the pyramid upside down. What I mean is, users get paid for getting advertisements on their devices. It allows users to opt-in to its own Brave rewards system (in other words, another advertising system). Brave serves ads after blocking ads from third party providers on websites, and then start showing ads from their own advertising platform via OS level notifications.</p>\n<p>Once you've opted-in, Brave will display you 'privacy-respecting' ads (it's still an advertisement btw 😂)  and if you receive an ad, you will be rewarded with a BAT cryptocurrency (BAT = Basic Attention Token), which you can use to support Brave verified creators (You can't withdraw those tokens to your crypto wallet yet, that's coming soon though).</p>\n<p>Brave intends to serve ads as per user interests, in an anonymised way. This could be either via client-side profiling, or simply piggybacking what a user is currently viewing. While rewards and ads maybe opt-in for users, they are not for publishers, leaving us in a very awkward position. If a publisher wants a cut of the rewards, they need to be a part of the Brave Partner program.</p>\n<p>With this behaviour, I feel that Brave is yet another middleman between the user and the advertiser. Other companies also have the same model of running their business. You are trusting an advertising company (Brave) - just like Google - to preserve your privacy. What an irony.</p>\n<h3 id=\"heading-conclusion\">Conclusion</h3>\n<p>I want the targeted advertisement system to die. I will go to all lengths to block all ads. I feel companies are not entitled to my data or my time ('attention').</p>\n<p>Read More:</p>\n<ul>\n<li><p><a target=\"_blank\" href=\"https://practicaltypography.com/the-cowardice-of-brave.html?ref=localhost\">The cowardice of Brave</a></p>\n</li>\n<li><p><a target=\"_blank\" href=\"https://openlibrary.org/works/OL19744680W/Ten_arguments_for_deleting_your_social_media_accounts_right_now?ref=localhost\">Ten arguments for deleting your Social Media account right now</a></p>\n</li>\n<li><p><a target=\"_blank\" href=\"https://news.ycombinator.com/item?id=18734999&amp;ref=localhost\">Brave taking Cryptocurrency donations \"for me\" without my consent</a></p>\n</li>\n</ul>\n","contentMarkdown":"Advertisements are everywhere - You see ads on your newspaper, your family sees ads on TV channels, there are ads on billboards seen by people in and around an area, and you too see ads on almost any website you visit.\n\nBut, internet advertising industry is broken. It's failing the users and the advertisers themselves. Internet advertising majorly uses targeted/personalized ads to go after you and cater products you would most likely want. This ends up collecting as much data about you as it can.\n\nIn this blog post, I will argue why the current model of internet advertising is bad, and how can you save yourself from being a victim of personalized ad targeting.\n\n## A Regular User's Perspective on Advertising\n\nIf you ask me what are the problems with the current model of advertising online, here are a few things I might suggest:\n\n* Ads violate privacy: There's no secret to this, internet advertising scoops up as much information about you from the services you visit and use.\n    \n* Ads are disruptive: As an example, sometimes you click on a blank area in a website, you then see a new pop-up window with an ad, despite your browser blocking pop-ups\n    \n* Ads are annoying: Sometimes you visit an interesting website, and the very next moment when you open a social media website, you start seeing ads about this almost everytime.\n    \n* Malicious Ads: A vast majority of the people of my generation shouldn't be worried about Malicious ads, as our generation is aware about websites and malware, and we'd only visit website after due diligence. But our previous generations are not so well-informed about websites, they would click on any website and that site may end up spreading malware.\n    \n\nWhat I'm worried about is the first point - Digital Advertising violating our privacy. While our previous generations are not much aware about their Data Privacy, our current generation does worry about it.\n\nWhile we sit here, worrying about our privacy, IMF has \"suggested\" that a person's [credit history should be based on their Web History](https://gizmodo.com/your-credit-score-should-be-based-on-your-web-history-1845912592?ref=localhost). That's how ridiculous things may get in the future if things are not corrected today. A 2018 study by researchers at Data and Society [concluded](https://datasociety.net/wp-content/uploads/2018/10/DS_Digital_Influence_Machine.pdf?ref=localhost) that “today’s digital advertising infrastructure creates disturbing new opportunities for political manipulation and other forms of antidemocratic strategic communication.”\n\nEven without concerns of privacy violations, there have been many efforts to try and fix some of the issues:\n\n* [Coalition for Better Ads](https://www.betterads.org/?ref=localhost)\n    \n* [Acceptable Ads](https://acceptableads.com/?ref=localhost)\n    \n* Brave\n    \n\nThese only fix some of the problems with Advertising in general, not the entire problem.\n\n## Attention Economy\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113097050/0539926e-20df-47e5-b1d2-d29b2f29c14b.jpeg align=\"left\")\n\nMultiple advertisements craving for your attention\n\n[Herbert Simon argued in the 70s](https://medium.com/rsa-journal/democracy-distracted-cf3272ceb3c4?ref=localhost) that when information becomes abundant, attention becomes the scarce resource. In today's modern age, we’re living through the pendulum swing of that reversal—yet we consistently overlook its implications.\n\nWhen you visit any website or browse through any app, you take some time out of your life - or your **attention** to visit that resource. You are also using some of your attention to read this post (for which I'm eternally grateful). Now, you normally wouldn't take out some of this attention to visit a website that you haven't clicked by yourself. Thus, such websites/apps allow to advertise within itself (mostly as a small banner) via publishers, so that you don't have to take out extra time off your life just to visit the standalone ad. Then, such publishers use your \"actions\", and use such individualized data about you - collected via algorithms - and sell slots to advertisers to display ads.\n\nWikipedia has a perfect definition for this - [Attention Economy](https://en.wikipedia.org/wiki/Attention_economy?ref=localhost).\n\nWho wouldn't love to have an individualized feed of news. Sadly, individualization that happens today is neither for our own benefit nor for getting a peace of mind. Rather such a system only invites more outrage from us - users.\n\nNow, an incentive driven advertising system is good for the publishers, who earn good money; and advertisers, who get to sell lot more of their products. But this is bad for the user. There are literally billions of dollars being spent to figure out how to persuade you to look at a certain thing over a competitor's; to care about one thing over another. This is the way most of the information in this world is being monetized today.\n\nWe can all see the effects of Attention Economy - Social Media websites like Twitter and Facebook never want people of different groups to stop fighting - be it over religion, sports or their political bias. This is because these networks are optimized in a way to promote fighting, or spread fake news/propaganda very quickly. You may argue that companies are investing to stop fake news, but I believe that it is still relatively minor as they don't really want their revenue streams to go down.\n\n## My take on digital ads\n\nI don’t want any relevant ads, or any ad-driven products, ever. Other people might feel differently, but collecting the data is only half the problem. That data can be abused, even if only client-side - for example targeting could exploit you and persuade to buy stuff you don’t need. The whole point of ads is to change your behavior, if only slightly, with advertisers literally bidding for your attention, and then playing mind tricks, which work because of how our critical thinking often fails us a majority of the times.\n\nI believe great products have often been successful via word of mouth referrals. A great example would be **Cred**. Only a few credit card users in India were aware of the Cred before September 2020. That month, a delayed IPL 2020 started, and Cred ads - which a majority of the Indians never understood - was everywhere on TV, getting people's interest in knowing about the product, and eventually end up using it. There are tactics that don’t involve tricking people into changing their behavior. Conventional advertising is better than the targeted ones, because it’s not individualized. At least everybody else is seeing the same shit that you’re seeing.\n\nThat brings us to the most important question - What should companies do? Honestly speaking, I don't think that's our problem. I don't think any company should be entitled to our data or our attention. When was the last time you ever saw an ad that made you feel this is the real deal. I haven't, have you?\n\nYou know how the unethical behavior of companies is always excused via the requirement of company stakeholders to make money? Well, this goes both ways. We, the consumers, aren’t running any charity. I strongly feel it isn’t our job to save such dying business models.\n\n### First Party Ads\n\nOne solution to the problem could be the content providers (websites/apps) serving ads based on content that is being viewed right now. This might ensure there is no need to keep user's profile and history. Your data will no longer be shared to third-parties and hence the quality of ads shown will get better - which also means no scam ads and no malvertising.\n\nThis too has a problem. Even if there is a whitelist for “acceptable ads”, the problem is those ads are still downloaded Javascript code, with no way to review what they do. Further, third-party requests could get disguised as first-party ones. In such cases, you have to trust the publishers, which I'd usually find a hard time to do.\n\n### Then, Wouldn't Ad-Blocking affect the Internet?\n\nGiven a choice between receiving ads, and no ads, sane people would obviously choose no ads. Nobody likes ads. If its forced, we have to gulp it down our throat, because either there's no clear alternative (Facebook), or the price of no-ads option is way too high (Youtube, Spotify, Apple Music, Hotstar et al.).\n\nAlmost no browser ships with an aggressive ad-blocker enabled by default. This is because somewhere or the other, their business model is also dependent on ads, even if they don't serve ads directly. It will only make the end user's experience much better. Many browsers that claim to do aggressive ad-blocking like Microsoft Edge, Brave, Samsung, Vivaldi et al. earn a lot of money from advertising.\n\nNow, wouldn't ad-blocking affect the Internet's health? Yes, it will. Negatively, on the advertisers and publishers' wallets; Positively on the rest of the internet, because it can only get better from there on.\n\n## Solutions\n\n## Pay for the things you use\n\nA wise man once said,\n\n> \"If you are not paying for a product, **you are the product**\".\n\nIf I really enjoy something, I don't mind paying for it. For example, I've been using **Hey email** since July. It did not catch my attention because of all the amazing features it brings, but rather because of its infamous [feud with Apple](https://hey.com/apple/?ref=localhost). In short, Hey is a radical re-thinking of what an Email client should be. As one Twitter user puts it:\n\n> In positive news, [https://t.co/lwKSOQNcFe](https://t.co/lwKSOQNcFe?ref=localhost) seems to have finally solved email (!!!). Been using it several weeks and no longer dealing with spam, long lists of “unread” messages, or sorting out annoying but important docs. The relief is so real 🙌🏼\n> \n> — Dr. Darya Rose 🇺🇸 (@summertomato) [June 10, 2020](https://twitter.com/summertomato/status/1270816132102930433?ref_src=twsrc%5Etfw&ref=localhost)\n\nI've been using it so far without any major problems. All advertising mails are now screened out, so that they never take my attention again. I've changed emails for all my online accounts to reflect to my hey.com email address. Now there are certain services like stock and mutual fund brokers, whose email change process has to be offline. Once all of my services are moved over to Hey, I'm deleting all my non Hey mail accounts (except primary Google Play Store and Microsoft Store accounts, because all my app/in-app purchase history is sitting in those 2 accounts).\n\nSimilarly, I'm also using **Spotify Premium** because I don't want myself to be exposed to their ads right after one song.\n\nI also pay for **Xbox Game Pass for PC**. It has more than 100 AAA PC games that I can easily play on my Lenovo Legion Y740 laptop. There are no ads in the games that are played via XGP. I regularly play Age of Empires 2: DE, Flight Simulator, Doom Eternal, Moto GP20 and The Outer Worlds. Buying all those games individually would've cost me a fortune, but at Rs 489/month (577 if you include taxes) it is a killer deal, specially for gamers like me. I am also using **Kindle Unlimited** for Reading as many Books as I can.\n\nWith all the information I'm unearthing every single day about the shady practices of all developers, I'm removing all ads-enabled apps from my mobiles. Moreover, if I find that any app is sharing data that is unwanted, I promptly uninstall that app. If at all I really need to use the app's services which provide ads, I would find a browser-based alternative for it - Eg. Youtube, Twitter, Facebook, IG, Amazon + Entertainment apps.\n\n## Block All Ads\n\nEven if you may think that some ads are fine, but do you know whether those are targeted specifically to you or not? Even if there's a whitelist of \"acceptable ads\", it's still Javascript code downloaded from the internet, which I have no idea about its functionality. It's still intrusive, and drives you to buy things you don't really want.\n\nI really think it is wrong that Publishers think they can run code on our devices. If publishers think otherwise, they can feel free to block me from using their services. If I see any website that serves me ads (and gets caught by my ad blockers), I'd really start looking for alternatives.\n\n### Blocking for all devices\n\nDNS blocking has worked well so far. That is until apps/sites starting using DNS-over-HTTPS over their own servers. Still there are techniques to circumvent this too.\n\n**PiHole**: I had a Raspberry Pi 3B sitting idle at home for the last 1 year or so. When I got to know that I could run a service like Pihole on it, I wasted no time to set it up. Ever since Christmas eve, I've been using Pihole to block ads for all the devices my family uses. And the stats are great too:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113098092/69ede8a4-a0cd-486d-9d56-7f128890c177.png align=\"left\")\n\nPihole stats since December 23, 2020\n\nThough the only downside to this is that I've had to change my router to use static IP address assignment. There was some initial hassle in setting up my router and the devices, but once that was done, ads were a thing of the past (except Youtube ads, for which there is no working solution in 2021. Screw you, Google).\n\n**Hosted services**: 3 months before trying out Pihole, I tried using NextDNS. While the results were incredible, I felt that giving away Rs. 159 every month (187 including taxes) was a bit too much for me. I've also heard about Adguard DNS, but I haven't used it so far.\n\n## Individual Devices\n\n### Desktop/Laptop + Android devices\n\nEven before I've been using PiHole, I had experimented with ad blocking via browser extensions. The best combination I've found is Firefox + uBlock Origin + Privacy Badger. It simply works.\n\nuBlock Origin is by far the best ad blocker I've ever used. Ever since installing it, I've noticed far better loading speeds, because there are lesser resources to be loaded. It also protects against CNAME cloaking, where 3rd party requests masquerade as 1st party ones and you might not even notice it.\n\nSadly, this won't work with Google Chrome and other Chromium forked browsers in the near future. This is because Manifest v3 for Chrome extensions will be deployed in Google Chrome sometime in January (with the release of v88). Simply put, Manifest is something any extension developer will have to follow while developing an extension. This particular Manifest v3 changes the way ad-blocking extensions function. This negatively impacts ad-blockers and uBlock is one of them.\n\nMy take on this will be to ditch Chrome/Chromium forked browsers ASAP. Switch to Firefox while you still can, because Mozilla's financials aren't great, and the browser could go kaput anytime.\n\nThe same combination also works well for Android as well, just that you will have to update the Firefox browser to whichever latest version is available.\n\n### What about Brave Browser?\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113098974/3f42d5de-d923-4f65-8f9c-7d9aff8de5f4.jpeg align=\"left\")\n\nBrave browser displaying ads from Brave Network via OS notifications\n\nBrave is yet another Chromium fork which focuses on user privacy by blocking trackers, scripts and ads by default. So inside some pages where ads don't load properly, you might be forced to turn down Brave Shields, which will then open up the website to show you ads.\n\nBy the time you've reached here, you must've realised that internet is up and running, all thanks to advertisements. The content you might be seeing for free is able to remain free because of advertising. This is profitable for both advertisers and publishers, but not the users.\n\nBrave attempts to change the advertising model by flipping the pyramid upside down. What I mean is, users get paid for getting advertisements on their devices. It allows users to opt-in to its own Brave rewards system (in other words, another advertising system). Brave serves ads after blocking ads from third party providers on websites, and then start showing ads from their own advertising platform via OS level notifications.\n\nOnce you've opted-in, Brave will display you 'privacy-respecting' ads (it's still an advertisement btw 😂)  and if you receive an ad, you will be rewarded with a BAT cryptocurrency (BAT = Basic Attention Token), which you can use to support Brave verified creators (You can't withdraw those tokens to your crypto wallet yet, that's coming soon though).\n\nBrave intends to serve ads as per user interests, in an anonymised way. This could be either via client-side profiling, or simply piggybacking what a user is currently viewing. While rewards and ads maybe opt-in for users, they are not for publishers, leaving us in a very awkward position. If a publisher wants a cut of the rewards, they need to be a part of the Brave Partner program.\n\nWith this behaviour, I feel that Brave is yet another middleman between the user and the advertiser. Other companies also have the same model of running their business. You are trusting an advertising company (Brave) - just like Google - to preserve your privacy. What an irony.\n\n### Conclusion\n\nI want the targeted advertisement system to die. I will go to all lengths to block all ads. I feel companies are not entitled to my data or my time ('attention').\n\nRead More:\n\n* [The cowardice of Brave](https://practicaltypography.com/the-cowardice-of-brave.html?ref=localhost)\n    \n* [Ten arguments for deleting your Social Media account right now](https://openlibrary.org/works/OL19744680W/Ten_arguments_for_deleting_your_social_media_accounts_right_now?ref=localhost)\n    \n* [Brave taking Cryptocurrency donations \"for me\" without my consent](https://news.ycombinator.com/item?id=18734999&ref=localhost)","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713114675308/290104bd-13f1-45ac-b4c2-8f2e477027bf.jpeg","brief":"Advertisements are everywhere - You see ads on your newspaper, your family sees ads on TV channels, there are ads on billboards seen by people in and around an area, and you too see ads on almost any website you visit.\nBut, internet advertising indus...","author":"5cdceddff961be4c61f8a021","sB":true,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/health-targeted-digital-advertising-today/","readTime":13,"tags":["56744721958ef13879b94a5c","5800cc3a174c9bd278905438","64b4db158b091fa9f5f2de16","576faa873d3400d08866009c"],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T17:12:07.347Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":true,"stickCoverToBottom":true,"subtitle":"Advertisements are everywhere - newspapers, TV channels, billboards, and digital. But is the current state of digital advertising good for the end use","viewsUpdatedOn":1713214836027,"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c080c8442574e70467574"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c08139bb70e9dac2bfee1","createdAt":"2024-04-14T16:45:07.253Z","updatedAt":"2024-04-14T17:15:55.761Z","views":142,"isActive":true,"hasLatex":false,"popularity":4255.0187,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"How to run Spark 3.0 applications on your GPU","cuid":"cluzrb9dg000408jw01qj4sj4","dateAdded":"2020-09-19T03:44:00.000Z","hasCustomDate":true,"slug":"run-spark-3-applications-on-gpu","content":"<p>In one of my previous blog posts, I'd mentioned that Spark 3.0 is coming with Native GPU support. A few days after that, Spark 3.0 released on 18th June 2020. While it did release, there were no mentions of how to run your Spark 3.0 code on a GPU anywhere on the internet. <strong>It changes now.</strong></p>\n<p>In this post, you'll see the prerequisites for running Spark on GPU on a local machine, as well as all installation instructions.</p>\n<h3 id=\"heading-prerequisites\">Prerequisites</h3>\n<p>To run Spark applications on your GPU, it is recommended that you have an <strong>Nvidia GPU</strong> of <strong>Pascal Architecture</strong> or better. This means that you will need an <strong>Nvidia Geforce GTX 1050 or better</strong>. Other requirements are the same as Apache Spark requirements.</p>\n<p><em>(PS. I don't have an AMD GPU, so can't really test and confirm whether this will work with it or not, but chances are very slim as you need a tool called</em> <code>nvidia-smi</code>, which works only with Nvidia GPUs)</p>\n<p>You will also need to install <a target=\"_blank\" href=\"https://spark.apache.org/downloads.html?ref=localhost\">Apache Spark 3.0</a>, <a target=\"_blank\" href=\"https://developer.nvidia.com/cuda-downloads?ref=localhost\">Nvidia CUDA</a> on your machine.</p>\n<p>Other than these, you will also need 2 JARs: <a target=\"_blank\" href=\"https://mvnrepository.com/artifact/com.nvidia/rapids-4-spark_2.12?ref=localhost\">Rapids Accelerator</a> and <a target=\"_blank\" href=\"https://repo1.maven.org/maven2/ai/rapids/cudf/0.15/?ref=localhost\">NVIDIA CUDF</a> (for CUDA 11).</p>\n<p>You will also need a Linux system to run your jobs. This won't work on Windows as CUDF isn't supported on that platform. However, the CUDF team says they will support CUDA Running on WSL 2.0. To get CUDA Running with WSL, you'll need to be a part of the Windows Insider Program.</p>\n<p>You will also need a GPU Discovery script which tells the program the addresses of GPUs available on your system. Fortunately, the Spark repo has a <a target=\"_blank\" href=\"https://github.com/apache/spark/blob/master/examples/src/main/scripts/getGpusResources.sh?ref=localhost\">GPU discovery script</a> handy which can be readily used.</p>\n<h3 id=\"heading-running\">Running</h3>\n<p>For Spark 3.0 to recognize that you will be running your jobs on a GPU, you need to pass a few parameters as Spark confs:</p>\n<ul>\n<li><p><code>spark.rapids.sql.enabled</code> as <code>true</code></p>\n</li>\n<li><p><code>spark.plugins</code> as <code>com.nvidia.spark.SQLPlugin</code></p>\n</li>\n<li><p><code>spark.driver.resource.gpu.discoveryScript</code> as &lt;The location where you have downloaded the GPU discovery script from above&gt;</p>\n</li>\n</ul>\n<p>You can either run this with <code>spark-shell</code> or you can create your own JAR and run it using <code>spark-submit</code> and then pass these configurations.</p>\n<h3 id=\"heading-performance\">Performance</h3>\n<p>In order to illustrate the performance difference between running your Spark program on a CPU vs GPU, I will be using a very simple program which is very much self explanatory:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> values: <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">Int</span>] = <span class=\"hljs-type\">List</span>(<span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">500</span>, <span class=\"hljs-number\">1000</span>, <span class=\"hljs-number\">5000</span>, <span class=\"hljs-number\">10000</span>, <span class=\"hljs-number\">50000</span>, <span class=\"hljs-number\">100000</span>, <span class=\"hljs-number\">500000</span>, <span class=\"hljs-number\">1000000</span>, <span class=\"hljs-number\">5000000</span>, <span class=\"hljs-number\">10000000</span>, <span class=\"hljs-number\">50000000</span>, <span class=\"hljs-number\">100000000</span>, <span class=\"hljs-number\">500000000</span>, <span class=\"hljs-number\">1000000000</span>)\n\n<span class=\"hljs-keyword\">for</span> (upperBound &lt;- values) {\n    <span class=\"hljs-keyword\">val</span> df = sc.makeRDD(<span class=\"hljs-number\">1</span> to upperBound).toDF(<span class=\"hljs-string\">\"a\"</span>)\n    <span class=\"hljs-keyword\">val</span> df2 = sc.makeRDD(<span class=\"hljs-number\">1</span> to upperBound).toDF(<span class=\"hljs-string\">\"b\"</span>)\n    println(df.join(df2, $<span class=\"hljs-string\">\"a\"</span> === $<span class=\"hljs-string\">\"b\"</span> / <span class=\"hljs-number\">2</span>).count())\n}\n</code></pre>\n<p>Spark program for testing performance: CPU vs GPU</p>\n<p>Further, in order to level the playing field between the 2 runs, I'm setting certain common configs:</p>\n<ul>\n<li><p><code>spark.locality.wait</code> = <code>0s</code></p>\n</li>\n<li><p><code>spark.driver.memory</code> = <code>10G</code></p>\n</li>\n<li><p><code>spark.sql.files.maxPartitionBytes</code> = <code>512 * 1024 * 1024</code></p>\n</li>\n<li><p><code>spark.sql.shuffle.partitions</code> = <code>10</code></p>\n</li>\n</ul>\n<p>Here are the specs of the laptop which I used to perform this test:</p>\n<ul>\n<li><p>6-core Intel Core i7-8750H</p>\n</li>\n<li><p>16GB DDR4 RAM, 256GB NVME SSD</p>\n</li>\n<li><p>8GB Nvidia Geforce RTX 2080 Graphics Card</p>\n</li>\n</ul>\n<p>Here are two plots showing the <code>upperBound</code> against time taken:</p>\n<p>chart created with amCharts | amChartschart created with amCharts | amCharts</p>\n<p>As you can see from the graphs above, for very less records - with sizes within a few Megabytes - it is faster on the CPU than on the GPU because of the less time taken to propagate the results.</p>\n<p>But things change for the better, when a high volume of records have to start processing. For very high records, you can see a difference of almost 3x.</p>\n<p>Moreover, for 1000000000 records (the last one), my Spark program crashed when run against the CPU. So the 13 minutes that you see above was until when it was successfully running.</p>\n<h3 id=\"heading-conclusion\">Conclusion</h3>\n<p>To confirm whether your program is running against the GPU or not, you can go to the SQL tab, select your job, and then you will see something like <code>GpuRowToColumnar</code>, indicating that the job is running against the GPU.</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113105203/874ebbca-5a3f-4902-a421-16112adc8d2f.png\" alt /></p>\n<p>Spark running on GPU</p>\n<p>So if you've got heavy workloads, try and offload them to the GPU as much as you can :)</p>\n","contentMarkdown":"In one of my previous blog posts, I'd mentioned that Spark 3.0 is coming with Native GPU support. A few days after that, Spark 3.0 released on 18th June 2020. While it did release, there were no mentions of how to run your Spark 3.0 code on a GPU anywhere on the internet. **It changes now.**\n\nIn this post, you'll see the prerequisites for running Spark on GPU on a local machine, as well as all installation instructions.\n\n### Prerequisites\n\nTo run Spark applications on your GPU, it is recommended that you have an **Nvidia GPU** of **Pascal Architecture** or better. This means that you will need an **Nvidia Geforce GTX 1050 or better**. Other requirements are the same as Apache Spark requirements.\n\n*(PS. I don't have an AMD GPU, so can't really test and confirm whether this will work with it or not, but chances are very slim as you need a tool called* `nvidia-smi`, which works only with Nvidia GPUs)\n\nYou will also need to install [Apache Spark 3.0](https://spark.apache.org/downloads.html?ref=localhost), [Nvidia CUDA](https://developer.nvidia.com/cuda-downloads?ref=localhost) on your machine.\n\nOther than these, you will also need 2 JARs: [Rapids Accelerator](https://mvnrepository.com/artifact/com.nvidia/rapids-4-spark_2.12?ref=localhost) and [NVIDIA CUDF](https://repo1.maven.org/maven2/ai/rapids/cudf/0.15/?ref=localhost) (for CUDA 11).\n\nYou will also need a Linux system to run your jobs. This won't work on Windows as CUDF isn't supported on that platform. However, the CUDF team says they will support CUDA Running on WSL 2.0. To get CUDA Running with WSL, you'll need to be a part of the Windows Insider Program.\n\nYou will also need a GPU Discovery script which tells the program the addresses of GPUs available on your system. Fortunately, the Spark repo has a [GPU discovery script](https://github.com/apache/spark/blob/master/examples/src/main/scripts/getGpusResources.sh?ref=localhost) handy which can be readily used.\n\n### Running\n\nFor Spark 3.0 to recognize that you will be running your jobs on a GPU, you need to pass a few parameters as Spark confs:\n\n* `spark.rapids.sql.enabled` as `true`\n    \n* `spark.plugins` as `com.nvidia.spark.SQLPlugin`\n    \n* `spark.driver.resource.gpu.discoveryScript` as &lt;The location where you have downloaded the GPU discovery script from above&gt;\n    \n\nYou can either run this with `spark-shell` or you can create your own JAR and run it using `spark-submit` and then pass these configurations.\n\n### Performance\n\nIn order to illustrate the performance difference between running your Spark program on a CPU vs GPU, I will be using a very simple program which is very much self explanatory:\n\n```scala\nval values: List[Int] = List(100, 500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000, 10000000, 50000000, 100000000, 500000000, 1000000000)\n\nfor (upperBound <- values) {\n    val df = sc.makeRDD(1 to upperBound).toDF(\"a\")\n    val df2 = sc.makeRDD(1 to upperBound).toDF(\"b\")\n    println(df.join(df2, $\"a\" === $\"b\" / 2).count())\n}\n```\n\nSpark program for testing performance: CPU vs GPU\n\nFurther, in order to level the playing field between the 2 runs, I'm setting certain common configs:\n\n* `spark.locality.wait` = `0s`\n    \n* `spark.driver.memory` = `10G`\n    \n* `spark.sql.files.maxPartitionBytes` = `512 * 1024 * 1024`\n    \n* `spark.sql.shuffle.partitions` = `10`\n    \n\nHere are the specs of the laptop which I used to perform this test:\n\n* 6-core Intel Core i7-8750H\n    \n* 16GB DDR4 RAM, 256GB NVME SSD\n    \n* 8GB Nvidia Geforce RTX 2080 Graphics Card\n    \n\nHere are two plots showing the `upperBound` against time taken:\n\nchart created with amCharts | amChartschart created with amCharts | amCharts\n\nAs you can see from the graphs above, for very less records - with sizes within a few Megabytes - it is faster on the CPU than on the GPU because of the less time taken to propagate the results.\n\nBut things change for the better, when a high volume of records have to start processing. For very high records, you can see a difference of almost 3x.\n\nMoreover, for 1000000000 records (the last one), my Spark program crashed when run against the CPU. So the 13 minutes that you see above was until when it was successfully running.\n\n### Conclusion\n\nTo confirm whether your program is running against the GPU or not, you can go to the SQL tab, select your job, and then you will see something like `GpuRowToColumnar`, indicating that the job is running against the GPU.\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113105203/874ebbca-5a3f-4902-a421-16112adc8d2f.png align=\"left\")\n\nSpark running on GPU\n\nSo if you've got heavy workloads, try and offload them to the GPU as much as you can :)","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713114774074/a3ed7bba-a3a9-4206-a130-42e66eb24014.png","brief":"In one of my previous blog posts, I'd mentioned that Spark 3.0 is coming with Native GPU support. A few days after that, Spark 3.0 released on 18th June 2020. While it did release, there were no mentions of how to run your Spark 3.0 code on a GPU any...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/run-spark-3-applications-on-gpu/","readTime":4,"tags":["5c8112202f7753512125933c","578378ebfcb4d586db19492c","57960642c691eeb2473cc9c0","56744723958ef13879b952a7","56744722958ef13879b95180"],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T17:15:55.759Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":true,"stickCoverToBottom":true,"subtitle":"Wanted to run your Spark job on a GPU but didn't know how? Well, your search ends here :)","viewsUpdatedOn":1714030241989,"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c08139bb70e9dac2bfee1"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c082397510b44fe969e47","createdAt":"2024-04-14T16:45:23.331Z","updatedAt":"2024-04-14T17:20:05.059Z","views":71,"isActive":true,"hasLatex":false,"popularity":4053.7627,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Cool Spark ML - Part 2: Preprocessing of Data","cuid":"cluzrbls2000a08lbavacdcjz","dateAdded":"2020-06-06T08:02:00.000Z","hasCustomDate":true,"slug":"spark-ml-data-preprocessing","content":"<p><em>Note: This is the second article of the series: Cool Spark ML. The other parts can be found below:</em></p>\n<ul>\n<li><p><a target=\"_blank\" href=\"https://blog.sparker0i.me/spark-machine-learning-knn/\">Part 1: K Nearest Neighbours</a></p>\n</li>\n<li><p>Part 2: Preprocessing of Data (current)</p>\n</li>\n</ul>\n<p>People who have been performing Machine Learning for quite a long time know that Data Preprocessing is a key step before running any algorithms on the data. In a majority of datasets, you might always find null, or incomplete values. The data would also be inconsistent across columns, which directly affects algorithms using distance measures.</p>\n<p>This is where Data Preprocessing comes in. It is a crucial step which involves cleaning and organizing the data to make it suitable for building models. In other words, if you don't perform Preprocessing, your models may not be accurate.</p>\n<p>While there are quite a lot of articles online about Data Preprocessing in Python, there aren't a lot of them in Spark, or even Scala. In this post, I will be dealing with the ways you can perform Data Preprocessing in Spark on Scala.</p>\n<p><em>PS. You might be asking why I'm dealing with this now when I have actually written KNN in Spark before. The truth is, KNN isn't officially supported inside Spark ML module. What I wrote in the previous article was a top-to-bottom version of KNN performed using Spark. You can also say that I'm doing a complete reset of this series 😅</em></p>\n<p>Just like always, the codes for all posts in this series will be available on <a target=\"_blank\" href=\"https://github.com/Sparker0i/Cool-Spark-ML?ref=localhost\">my GitHub repo</a>.</p>\n<h2 id=\"heading-types-of-preprocessing-in-spark\">Types of Preprocessing in Spark</h2>\n<p>There are two types of preprocessing:</p>\n<ul>\n<li><p>Numeric Data</p>\n</li>\n<li><p>Text Data</p>\n</li>\n</ul>\n<h2 id=\"heading-numeric-data\">Numeric Data</h2>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113110757/013c380e-319f-4422-a230-92cd5dce8c9e.png\" alt /></p>\n<p>There are three ways you can preprocess numeric data in Spark:</p>\n<ul>\n<li><p>Normalize</p>\n</li>\n<li><p>Standardize</p>\n</li>\n<li><p>Bucketize</p>\n</li>\n</ul>\n<p>To illustrate Normalize and Standardize, I'll be using some Scala magic which will generate my points as a Vector. Each vector represents a point in a 3-Dimensional Space.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> points = <span class=\"hljs-keyword\">for</span> (i &lt;- <span class=\"hljs-number\">1</span> to <span class=\"hljs-number\">1000</span>) <span class=\"hljs-keyword\">yield</span> (i, <span class=\"hljs-type\">Vectors</span>.dense(\n    <span class=\"hljs-type\">Array</span>(\n        (math.random * (<span class=\"hljs-number\">10</span> - <span class=\"hljs-number\">1</span>)) * i + <span class=\"hljs-number\">1.0</span>,\n        (math.random * (<span class=\"hljs-number\">10000</span> - <span class=\"hljs-number\">1000</span>)) + <span class=\"hljs-number\">1000.0</span>,\n        math.random * i\n    )\n))\n\n<span class=\"hljs-keyword\">val</span> featuresDf = points.toDF(<span class=\"hljs-string\">\"id\"</span>, <span class=\"hljs-string\">\"features\"</span>)\n</code></pre>\n<p>Doing the above results in the following <code>DataFrame</code>:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113111710/cef59b8a-1ff3-44fe-ab23-93a073b574e3.png\" alt /></p>\n<p>Each element inside Features column represents a point in a 3-D space.</p>\n<h3 id=\"heading-normalize\">Normalize</h3>\n<p>Normalization is the process of mapping numeric data from their original range into a range of 0 to 1. The lowest value of the original range gets value of 0, and the highest gets the value 1. All the other values in the original range will fall between these two.</p>\n<p>This is important because there may be multiple attributes with different ranges. <em>E.g. Salary values may range between 3 and 8+ digit numbers, years in company will be between 1- and 2-digit numbers.</em> The reason we want to normalize those attributes in a <code>[0,1]</code> range is so that when algorithms that use distance as a measure, they don't weigh some attributes like salary more heavily than others.</p>\n<p>The formula to convert values in an un-normalized column to a normalized form is given by:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113112668/03103cb8-0d5d-4960-b635-33c1a62ec52c.png\" alt /></p>\n<p>Normalization Formula</p>\n<p>Where:</p>\n<ul>\n<li><p><code>x</code> is the value inside a column to be normalized,</p>\n</li>\n<li><p><code>x(new)</code> is the normalized value,</p>\n</li>\n<li><p><code>x(min)</code> is the minimum value of that column, and</p>\n</li>\n<li><p><code>x(max)</code> is the maximum value of that column</p>\n</li>\n</ul>\n<p>Working on the <code>featuresDf</code> created above, we will import <code>MinMaxScaler</code> from the <code>org.apache.spark.ml.feature</code> package. We now have to create an instance of the <code>MinMaxScaler</code>. It will take two parameters: Input column name, and an Output Column name. This object will transform the contents of the input column vectors into a scaled version, and save it into the output column.</p>\n<p>In our case, we will be using our <code>features</code> column inside <code>featuresDf</code> as the input column, and our output column will be named <code>sFeatures</code>. We create the instance in this manner:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> featureScaler = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">MinMaxScaler</span>()\n    .setInputCol(<span class=\"hljs-string\">\"features\"</span>)\n    .setOutputCol(<span class=\"hljs-string\">\"sfeatures\"</span>)\n</code></pre>\n<p>Next, we have to <code>fit</code> the data present in our <code>featuresDf</code> inside this <code>featureScaler</code> and later <code>transform</code> to create the scaled data. This is done using the code below:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> scaledDf = featureScaler.fit(featuresDf)\n    .transform(featuresDf)\n</code></pre>\n<p>Transforming original values into normalized ones</p>\n<p>Now, if we have a look at our transformed data:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113113503/58d6eebe-732e-499e-8cb9-08961bd34c03.png\" alt /></p>\n<p>Normalized <code>DataFrame</code></p>\n<p>You can then use this new <code>sFeatures</code> to calculate distances among points.</p>\n<h3 id=\"heading-standardize\">Standardize</h3>\n<p>Now, we may have data whose values can be mapped to a bell-shaped curve, or normally distributed but maybe not exactly. With standardization, we map our data and transform it, which has a variance of 1 and/or a mean value of 0. This is done because some machine learning algorithms, like SVM, work better this way.</p>\n<p>Thus, what happens is when we apply standardization, our data is slightly shifted in its shape so that it becomes more normalized, or more like a bell curve. The formula to convert values in a non-standardized column to a standardized form is given by:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113114555/af201ed8-65e8-4341-8861-fde84255b7ea.png\" alt /></p>\n<p>Standardization Formula</p>\n<p>Where:</p>\n<ul>\n<li><p><code>x</code> is the value to be standardized</p>\n</li>\n<li><p><code>x(new)</code> is the standardized value</p>\n</li>\n<li><p><code>μ</code> is the mean of the column</p>\n</li>\n<li><p><code>σ</code> is the standard deviation of the column.</p>\n</li>\n</ul>\n<p>Again, we will be using the <code>featuresDf</code> created above. We will import <code>StandardScaler</code> from the <code>org.apache.spark.ml.feature</code> package. Just like <code>MinMaxScaler</code>, an instance of <code>StandardScaler</code> will require an input column and an output column. In our case, we will still continue with <code>features</code> and <code>sFeatures</code>. We will then <code>fit</code> the data inside the scaler and later <code>transform</code> the data. I've combined both these steps into a single code snippet:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> featureStandardScaler = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">StandardScaler</span>()\n    .setInputCol(<span class=\"hljs-string\">\"features\"</span>)\n    .setOutputCol(<span class=\"hljs-string\">\"sfeatures\"</span>)\n    .setWithStd(<span class=\"hljs-literal\">true</span>)\n    .setWithMean(<span class=\"hljs-literal\">true</span>)\n\n<span class=\"hljs-keyword\">val</span> standardizedDf = featureStandardScaler.fit(featuresDf)\n    .transform(featuresDf)\n</code></pre>\n<p>Now if we have a look at our transformed data:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113115358/069f19b3-5a7d-4b8a-bb0f-6875947e17ff.png\" alt /></p>\n<p>Standardized Numeric Data</p>\n<p>Wait, weren't the values supposed to be scaled within the range of <code>[-1, 1]</code>? Well, that's the surprise associated with the <code>StandardScaler</code>. It uses the unbiased sample standard deviation instead of the population standard deviation.</p>\n<p>In other words, while the standard deviation will be 1 (or very close to 1), the mean may not be necessarily 0. To scale your data in a way that the range of numbers is between <code>[-1,1]</code> and the standard deviation is 1 and mean 0, you will have to follow <a target=\"_blank\" href=\"https://stackoverflow.com/a/51755387/2451763?ref=localhost\">this accepted StackOverflow answer</a>. Even otherwise with this process, the data has been standardized.</p>\n<h3 id=\"heading-bucketize\">Bucketize</h3>\n<p>Bucketization is done when we have to organize continuous ranges of data into different buckets. <code>Bucketizer</code> allows us to group data based on boundaries, so a list of boundaries has to be provided. I will call it <code>splits</code> with the domain of all buckets when added looks like: <code>{(-∞, -500.0) ⋃ [-500.0, -100.0) ⋃ [-100.0, -10.0) ⋃ [-10.0, 0.0) ⋃ [0.0, 10.0) ⋃ [10.0, 100.0) ⋃ [100.0, 500.0) ⋃ [500.0, ∞)}</code>.</p>\n<p>Then I'll generate 1000 random points that fall in the range of <code>[-10000.0, 10000.0]</code> and save it in a <code>DataFrame</code> with column name as <code>features</code>. This is done using the below code:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> splits = <span class=\"hljs-type\">Array</span>(<span class=\"hljs-type\">Float</span>.<span class=\"hljs-type\">NegativeInfinity</span>, <span class=\"hljs-number\">-500.0</span>, <span class=\"hljs-number\">-100.0</span>, <span class=\"hljs-number\">-10.0</span>, <span class=\"hljs-number\">0.0</span>, <span class=\"hljs-number\">10.0</span>, <span class=\"hljs-number\">100.0</span>, <span class=\"hljs-number\">500.0</span>, <span class=\"hljs-type\">Float</span>.<span class=\"hljs-type\">PositiveInfinity</span>)\n\n<span class=\"hljs-keyword\">val</span> bucketData = (<span class=\"hljs-keyword\">for</span> (i &lt;- <span class=\"hljs-number\">0</span> to <span class=\"hljs-number\">10000</span>) <span class=\"hljs-keyword\">yield</span> math.random * <span class=\"hljs-number\">10000.0</span> * (<span class=\"hljs-keyword\">if</span> (math.random &lt; <span class=\"hljs-number\">0.5</span>) <span class=\"hljs-number\">-1</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-number\">1</span>))\n<span class=\"hljs-keyword\">val</span> bucketDf = bucketData.toDF(<span class=\"hljs-string\">\"features\"</span>)\n</code></pre>\n<p>Now, our <code>Bucketizer</code> needs three inputs: the splits, input column name, and output column name. Then I'll <code>transform</code> that data which would then give me the element and which bucket it belongs to:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> bucketizer = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">Bucketizer</span>()\n    .setSplits(splits)\n    .setInputCol(<span class=\"hljs-string\">\"features\"</span>)\n    .setOutputCol(<span class=\"hljs-string\">\"bfeatures\"</span>)\n\n<span class=\"hljs-keyword\">val</span> bucketedDf = bucketizer.transform(bucketDf)\n</code></pre>\n<p>Notice that I didn't have to do a <code>fit</code> operation before doing a <code>transform</code>. This is because Bucketizing is fairly simple and you only need to find which bucket a number belongs to. Thus, there are no operations like scaling which happened in the other 2 sections, and hence you don't need to <code>fit</code> your data. Now if we have a look at the created <code>DataFrame</code>:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113116620/0fb28aab-611f-48ed-8abe-1c8794d3c20f.png\" alt /></p>\n<p>Bucketized DataFrame</p>\n<p>Now you might also want to know how many numbers are there in a particular bucket. So, I will do a <code>groupBy</code> on <code>bFeatures</code> column and retrieve the count of occurrences. The following code does that and displays my generated data:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113117463/5ae7705a-2089-45b7-8f55-be6804bdda60.png\" alt /></p>\n<p>Fairly easy, isn't it?</p>\n<h2 id=\"heading-text\">Text</h2>\n<p>There are two ways in which you can preprocess text-based data in Spark:</p>\n<ul>\n<li><p>Tokenize</p>\n</li>\n<li><p>TF-IDF</p>\n</li>\n</ul>\n<p>To illustrate both of them, I will be using <code>sentencesDf</code> created using this code:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> sentencesDf = <span class=\"hljs-type\">Seq</span>(\n    (<span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">\"This is an introduction to Spark ML\"</span>),\n    (<span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">\"MLLib includes libraries for classification and regression\"</span>),\n    (<span class=\"hljs-number\">3</span>, <span class=\"hljs-string\">\"It also contains supporting tools for pipelines\"</span>)\n).toDF(<span class=\"hljs-string\">\"id\"</span>, <span class=\"hljs-string\">\"sentence\"</span>)\n</code></pre>\n<h3 id=\"heading-tokenize\">Tokenize</h3>\n<p>In tokenization, you map your string containing a sentence into a set of tokens, or words. As an Example, the sentence <em>\"This is an introduction to Spark ML\"</em> can be mapped into a list of 7 words - <code>{This, is, an, introduction, to, Spark, ML}</code>.</p>\n<p>We will first import <code>Tokenizer</code> from the <code>org.apache.spark.ml.feature</code> package. Now an instance of this will need two parameters - input column and output column. Our input will be <code>sentence</code> and the output will be <code>words</code>, because that is what the <code>Tokenizer</code> will produce. Then we will apply <code>transform</code> on the sentences above.</p>\n<p>Now, just like bucketing, we are not <code>fit</code>ting any data here. <code>Tokenizer</code> already knows its job - Split strings into the separate words. The above process is illustrated in the code below:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> sentenceToken = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">Tokenizer</span>()\n    .setInputCol(<span class=\"hljs-string\">\"sentence\"</span>)\n    .setOutputCol(<span class=\"hljs-string\">\"words\"</span>)\n\n<span class=\"hljs-keyword\">val</span> sentenceTokenizedDf = sentenceToken.transform(sentencesDf)\n</code></pre>\n<p>Now, if we have a look at our data:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113118300/34e46d62-61a0-4814-aa63-461ded227671.png\" alt /></p>\n<p>The <code>words</code> column contains lists of words that have been broken up in the ways you would expect a regular expression pattern matching to break up a sentence into words - based on white space, punctuation, etc.</p>\n<p>Easy, isn't it?</p>\n<h3 id=\"heading-term-frequency-inverse-document-frequency-tf-idf\">Term Frequency-Inverse Document Frequency (TF-IDF)</h3>\n<p>Here we map text from a single, typically long string, to a vector, indicating the frequency of each word in a text relative to a group of texts such as a corpus. This transformation is widely used in text classification.</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113119489/932f49cd-4e0a-403b-918d-968c1151c804.png\" alt /></p>\n<p>TF-IDF captures the intuition that infrequently used words are more useful for distinguishing categories of text than frequently used words. Considering the above figure as an example, <em>Normalizing</em> appears only once, <em>to</em> appears twice and so on. Like this, we go through all the documents in our corpus, which is nothing but a collection of documents. Then we count up how often a term appears across all of the documents. In this example <em>normalizing</em> is a very rare word. Whereas other words like <em>maps, data</em> and <em>to</em> show up more frequently. We use these two sets of counts and feed those two into the term frequency-inverse document frequency calculation. And that gives us our TF-IDF measures.</p>\n<p>I will use the same <code>sentenceTokenizedDf</code> created above for this exercise as well. Just like other processes mentioned above, we will need to import a few things from <code>org.apache.spark.ml.feature</code> package - <code>HashingTF</code> (for hashing Term Frequency), <code>IDF</code> (for Inverse Document Frequency), <code>Tokenizer</code>.</p>\n<p>First, I will create a <code>HashingTF</code> instance - which takes an input column (<code>words</code>), an output column (<code>rawFeatures</code>)  and the number of features to keep track of (<code>20</code>) as the parameters. Now we apply our <code>transform</code>ation on this and get a new <code>DataFrame</code>:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> hashingTF = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">HashingTF</span>()\n    .setInputCol(<span class=\"hljs-string\">\"words\"</span>)\n    .setOutputCol(<span class=\"hljs-string\">\"rawFeatures\"</span>)\n    .setNumFeatures(<span class=\"hljs-number\">20</span>)\n\n<span class=\"hljs-keyword\">val</span> sentenceHashingFunctionTermFrequencyDf = hashingTF.transform(sentenceTokenizedDf)\nsentenceHashingFunctionTermFrequencyDf.show()\n</code></pre>\n<p>Now if we have a look at our data, it has added an extra column which is of <code>Vector</code> type. It has mapped each word to an index, so for example, <em>this</em> maps to 1, <em>is</em> maps to 4, <em>an</em> -&gt; 5, and so on.</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113120590/5a42bed0-8330-4ea2-9c07-50730eacf3d8.png\" alt /></p>\n<p>Now we're going to scale the <code>rawFeatures</code> vector values and we're going to scale them based on how often the words appear in the entire collection of sentences. To do this we're going to create an <code>IDF</code> instance. Again, we have to specify an input column (<code>rawFeatures</code>) and an output column (<code>idfFeatures</code>) as parameters.</p>\n<p>Let's use the term frequency data we just calculated to <code>fit</code> the inverse document frequency model. And to do that I'm going to create an <code>idfModel</code>, and we're going to call the <code>idf</code> object I just created, and I'm going to fit it using our term frequency data. Then we apply the IDF <code>transform</code>ation to create a new <code>DataFrame</code> that has both the term frequency and the inverse document frequency transformations applied.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">val</span> idf = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-type\">IDF</span>()\n    .setInputCol(<span class=\"hljs-string\">\"rawFeatures\"</span>)\n    .setOutputCol(<span class=\"hljs-string\">\"idfFeatures\"</span>)\n\n<span class=\"hljs-keyword\">val</span> idfModel = idf.fit(sentenceHashingFunctionTermFrequencyDf)\n<span class=\"hljs-keyword\">val</span> tfIdfDf = idfModel.transform(sentenceHashingFunctionTermFrequencyDf)\n</code></pre>\n<p>Now if we have a look at our data (I'm selecting only the <code>rawFeatures</code> and <code>idfFeatures</code> columns to fit in the screen):</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113121472/14c44800-1c47-461b-84cf-084d26a3606a.png\" alt /></p>\n<p>Now we have a new column which contains the inverse document frequency features. These are measures of each word relative to how frequently they occur in the entire corpus. In our case our corpus is just three sentences.</p>\n<h2 id=\"heading-conclusion\">CONCLUSION</h2>\n<p>Preprocessing is indeed a tough challenge where you will have to know what kinds of data you might get and what kinds of processing you want to apply on your data. If not done properly, your machine learning models might not be of much use.</p>\n","contentMarkdown":"*Note: This is the second article of the series: Cool Spark ML. The other parts can be found below:*\n\n* [Part 1: K Nearest Neighbours](https://blog.sparker0i.me/spark-machine-learning-knn/)\n    \n* Part 2: Preprocessing of Data (current)\n    \n\nPeople who have been performing Machine Learning for quite a long time know that Data Preprocessing is a key step before running any algorithms on the data. In a majority of datasets, you might always find null, or incomplete values. The data would also be inconsistent across columns, which directly affects algorithms using distance measures.\n\nThis is where Data Preprocessing comes in. It is a crucial step which involves cleaning and organizing the data to make it suitable for building models. In other words, if you don't perform Preprocessing, your models may not be accurate.\n\nWhile there are quite a lot of articles online about Data Preprocessing in Python, there aren't a lot of them in Spark, or even Scala. In this post, I will be dealing with the ways you can perform Data Preprocessing in Spark on Scala.\n\n*PS. You might be asking why I'm dealing with this now when I have actually written KNN in Spark before. The truth is, KNN isn't officially supported inside Spark ML module. What I wrote in the previous article was a top-to-bottom version of KNN performed using Spark. You can also say that I'm doing a complete reset of this series 😅*\n\nJust like always, the codes for all posts in this series will be available on [my GitHub repo](https://github.com/Sparker0i/Cool-Spark-ML?ref=localhost).\n\n## Types of Preprocessing in Spark\n\nThere are two types of preprocessing:\n\n* Numeric Data\n    \n* Text Data\n    \n\n## Numeric Data\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113110757/013c380e-319f-4422-a230-92cd5dce8c9e.png align=\"left\")\n\nThere are three ways you can preprocess numeric data in Spark:\n\n* Normalize\n    \n* Standardize\n    \n* Bucketize\n    \n\nTo illustrate Normalize and Standardize, I'll be using some Scala magic which will generate my points as a Vector. Each vector represents a point in a 3-Dimensional Space.\n\n```scala\nval points = for (i <- 1 to 1000) yield (i, Vectors.dense(\n    Array(\n        (math.random * (10 - 1)) * i + 1.0,\n        (math.random * (10000 - 1000)) + 1000.0,\n        math.random * i\n    )\n))\n\nval featuresDf = points.toDF(\"id\", \"features\")\n```\n\nDoing the above results in the following `DataFrame`:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113111710/cef59b8a-1ff3-44fe-ab23-93a073b574e3.png align=\"left\")\n\nEach element inside Features column represents a point in a 3-D space.\n\n### Normalize\n\nNormalization is the process of mapping numeric data from their original range into a range of 0 to 1. The lowest value of the original range gets value of 0, and the highest gets the value 1. All the other values in the original range will fall between these two.\n\nThis is important because there may be multiple attributes with different ranges. *E.g. Salary values may range between 3 and 8+ digit numbers, years in company will be between 1- and 2-digit numbers.* The reason we want to normalize those attributes in a `[0,1]` range is so that when algorithms that use distance as a measure, they don't weigh some attributes like salary more heavily than others.\n\nThe formula to convert values in an un-normalized column to a normalized form is given by:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113112668/03103cb8-0d5d-4960-b635-33c1a62ec52c.png align=\"left\")\n\nNormalization Formula\n\nWhere:\n\n* `x` is the value inside a column to be normalized,\n    \n* `x(new)` is the normalized value,\n    \n* `x(min)` is the minimum value of that column, and\n    \n* `x(max)` is the maximum value of that column\n    \n\nWorking on the `featuresDf` created above, we will import `MinMaxScaler` from the `org.apache.spark.ml.feature` package. We now have to create an instance of the `MinMaxScaler`. It will take two parameters: Input column name, and an Output Column name. This object will transform the contents of the input column vectors into a scaled version, and save it into the output column.\n\nIn our case, we will be using our `features` column inside `featuresDf` as the input column, and our output column will be named `sFeatures`. We create the instance in this manner:\n\n```scala\nval featureScaler = new MinMaxScaler()\n    .setInputCol(\"features\")\n    .setOutputCol(\"sfeatures\")\n```\n\nNext, we have to `fit` the data present in our `featuresDf` inside this `featureScaler` and later `transform` to create the scaled data. This is done using the code below:\n\n```scala\nval scaledDf = featureScaler.fit(featuresDf)\n\t.transform(featuresDf)\n```\n\nTransforming original values into normalized ones\n\nNow, if we have a look at our transformed data:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113113503/58d6eebe-732e-499e-8cb9-08961bd34c03.png align=\"left\")\n\nNormalized `DataFrame`\n\nYou can then use this new `sFeatures` to calculate distances among points.\n\n### Standardize\n\nNow, we may have data whose values can be mapped to a bell-shaped curve, or normally distributed but maybe not exactly. With standardization, we map our data and transform it, which has a variance of 1 and/or a mean value of 0. This is done because some machine learning algorithms, like SVM, work better this way.\n\nThus, what happens is when we apply standardization, our data is slightly shifted in its shape so that it becomes more normalized, or more like a bell curve. The formula to convert values in a non-standardized column to a standardized form is given by:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113114555/af201ed8-65e8-4341-8861-fde84255b7ea.png align=\"left\")\n\nStandardization Formula\n\nWhere:\n\n* `x` is the value to be standardized\n    \n* `x(new)` is the standardized value\n    \n* `μ` is the mean of the column\n    \n* `σ` is the standard deviation of the column.\n    \n\nAgain, we will be using the `featuresDf` created above. We will import `StandardScaler` from the `org.apache.spark.ml.feature` package. Just like `MinMaxScaler`, an instance of `StandardScaler` will require an input column and an output column. In our case, we will still continue with `features` and `sFeatures`. We will then `fit` the data inside the scaler and later `transform` the data. I've combined both these steps into a single code snippet:\n\n```scala\nval featureStandardScaler = new StandardScaler()\n    .setInputCol(\"features\")\n    .setOutputCol(\"sfeatures\")\n    .setWithStd(true)\n    .setWithMean(true)\n    \nval standardizedDf = featureStandardScaler.fit(featuresDf)\n    .transform(featuresDf)\n```\n\nNow if we have a look at our transformed data:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113115358/069f19b3-5a7d-4b8a-bb0f-6875947e17ff.png align=\"left\")\n\nStandardized Numeric Data\n\nWait, weren't the values supposed to be scaled within the range of `[-1, 1]`? Well, that's the surprise associated with the `StandardScaler`. It uses the unbiased sample standard deviation instead of the population standard deviation.\n\nIn other words, while the standard deviation will be 1 (or very close to 1), the mean may not be necessarily 0. To scale your data in a way that the range of numbers is between `[-1,1]` and the standard deviation is 1 and mean 0, you will have to follow [this accepted StackOverflow answer](https://stackoverflow.com/a/51755387/2451763?ref=localhost). Even otherwise with this process, the data has been standardized.\n\n### Bucketize\n\nBucketization is done when we have to organize continuous ranges of data into different buckets. `Bucketizer` allows us to group data based on boundaries, so a list of boundaries has to be provided. I will call it `splits` with the domain of all buckets when added looks like: `{(-∞, -500.0) ⋃ [-500.0, -100.0) ⋃ [-100.0, -10.0) ⋃ [-10.0, 0.0) ⋃ [0.0, 10.0) ⋃ [10.0, 100.0) ⋃ [100.0, 500.0) ⋃ [500.0, ∞)}`.\n\nThen I'll generate 1000 random points that fall in the range of `[-10000.0, 10000.0]` and save it in a `DataFrame` with column name as `features`. This is done using the below code:\n\n```scala\nval splits = Array(Float.NegativeInfinity, -500.0, -100.0, -10.0, 0.0, 10.0, 100.0, 500.0, Float.PositiveInfinity)\n\nval bucketData = (for (i <- 0 to 10000) yield math.random * 10000.0 * (if (math.random < 0.5) -1 else 1))\nval bucketDf = bucketData.toDF(\"features\")\n```\n\nNow, our `Bucketizer` needs three inputs: the splits, input column name, and output column name. Then I'll `transform` that data which would then give me the element and which bucket it belongs to:\n\n```scala\nval bucketizer = new Bucketizer()\n    .setSplits(splits)\n    .setInputCol(\"features\")\n    .setOutputCol(\"bfeatures\")\n\nval bucketedDf = bucketizer.transform(bucketDf)\n```\n\nNotice that I didn't have to do a `fit` operation before doing a `transform`. This is because Bucketizing is fairly simple and you only need to find which bucket a number belongs to. Thus, there are no operations like scaling which happened in the other 2 sections, and hence you don't need to `fit` your data. Now if we have a look at the created `DataFrame`:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113116620/0fb28aab-611f-48ed-8abe-1c8794d3c20f.png align=\"left\")\n\nBucketized DataFrame\n\nNow you might also want to know how many numbers are there in a particular bucket. So, I will do a `groupBy` on `bFeatures` column and retrieve the count of occurrences. The following code does that and displays my generated data:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113117463/5ae7705a-2089-45b7-8f55-be6804bdda60.png align=\"left\")\n\nFairly easy, isn't it?\n\n## Text\n\nThere are two ways in which you can preprocess text-based data in Spark:\n\n* Tokenize\n    \n* TF-IDF\n    \n\nTo illustrate both of them, I will be using `sentencesDf` created using this code:\n\n```scala\nval sentencesDf = Seq(\n    (1, \"This is an introduction to Spark ML\"),\n    (2, \"MLLib includes libraries for classification and regression\"),\n    (3, \"It also contains supporting tools for pipelines\")\n).toDF(\"id\", \"sentence\")\n```\n\n### Tokenize\n\nIn tokenization, you map your string containing a sentence into a set of tokens, or words. As an Example, the sentence *\"This is an introduction to Spark ML\"* can be mapped into a list of 7 words - `{This, is, an, introduction, to, Spark, ML}`.\n\nWe will first import `Tokenizer` from the `org.apache.spark.ml.feature` package. Now an instance of this will need two parameters - input column and output column. Our input will be `sentence` and the output will be `words`, because that is what the `Tokenizer` will produce. Then we will apply `transform` on the sentences above.\n\nNow, just like bucketing, we are not `fit`ting any data here. `Tokenizer` already knows its job - Split strings into the separate words. The above process is illustrated in the code below:\n\n```scala\nval sentenceToken = new Tokenizer()\n    .setInputCol(\"sentence\")\n    .setOutputCol(\"words\")\n\nval sentenceTokenizedDf = sentenceToken.transform(sentencesDf)\n```\n\nNow, if we have a look at our data:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113118300/34e46d62-61a0-4814-aa63-461ded227671.png align=\"left\")\n\nThe `words` column contains lists of words that have been broken up in the ways you would expect a regular expression pattern matching to break up a sentence into words - based on white space, punctuation, etc.\n\nEasy, isn't it?\n\n### Term Frequency-Inverse Document Frequency (TF-IDF)\n\nHere we map text from a single, typically long string, to a vector, indicating the frequency of each word in a text relative to a group of texts such as a corpus. This transformation is widely used in text classification.\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113119489/932f49cd-4e0a-403b-918d-968c1151c804.png align=\"left\")\n\nTF-IDF captures the intuition that infrequently used words are more useful for distinguishing categories of text than frequently used words. Considering the above figure as an example, *Normalizing* appears only once, *to* appears twice and so on. Like this, we go through all the documents in our corpus, which is nothing but a collection of documents. Then we count up how often a term appears across all of the documents. In this example *normalizing* is a very rare word. Whereas other words like *maps, data* and *to* show up more frequently. We use these two sets of counts and feed those two into the term frequency-inverse document frequency calculation. And that gives us our TF-IDF measures.\n\nI will use the same `sentenceTokenizedDf` created above for this exercise as well. Just like other processes mentioned above, we will need to import a few things from `org.apache.spark.ml.feature` package - `HashingTF` (for hashing Term Frequency), `IDF` (for Inverse Document Frequency), `Tokenizer`.\n\nFirst, I will create a `HashingTF` instance - which takes an input column (`words`), an output column (`rawFeatures`)  and the number of features to keep track of (`20`) as the parameters. Now we apply our `transform`ation on this and get a new `DataFrame`:\n\n```scala\nval hashingTF = new HashingTF()\n    .setInputCol(\"words\")\n    .setOutputCol(\"rawFeatures\")\n    .setNumFeatures(20)\n\nval sentenceHashingFunctionTermFrequencyDf = hashingTF.transform(sentenceTokenizedDf)\nsentenceHashingFunctionTermFrequencyDf.show()\n```\n\nNow if we have a look at our data, it has added an extra column which is of `Vector` type. It has mapped each word to an index, so for example, *this* maps to 1, *is* maps to 4, *an* -&gt; 5, and so on.\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113120590/5a42bed0-8330-4ea2-9c07-50730eacf3d8.png align=\"left\")\n\nNow we're going to scale the `rawFeatures` vector values and we're going to scale them based on how often the words appear in the entire collection of sentences. To do this we're going to create an `IDF` instance. Again, we have to specify an input column (`rawFeatures`) and an output column (`idfFeatures`) as parameters.\n\nLet's use the term frequency data we just calculated to `fit` the inverse document frequency model. And to do that I'm going to create an `idfModel`, and we're going to call the `idf` object I just created, and I'm going to fit it using our term frequency data. Then we apply the IDF `transform`ation to create a new `DataFrame` that has both the term frequency and the inverse document frequency transformations applied.\n\n```scala\nval idf = new IDF()\n    .setInputCol(\"rawFeatures\")\n    .setOutputCol(\"idfFeatures\")\n\nval idfModel = idf.fit(sentenceHashingFunctionTermFrequencyDf)\nval tfIdfDf = idfModel.transform(sentenceHashingFunctionTermFrequencyDf)\n```\n\nNow if we have a look at our data (I'm selecting only the `rawFeatures` and `idfFeatures` columns to fit in the screen):\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113121472/14c44800-1c47-461b-84cf-084d26a3606a.png align=\"left\")\n\nNow we have a new column which contains the inverse document frequency features. These are measures of each word relative to how frequently they occur in the entire corpus. In our case our corpus is just three sentences.\n\n## CONCLUSION\n\nPreprocessing is indeed a tough challenge where you will have to know what kinds of data you might get and what kinds of processing you want to apply on your data. If not done properly, your machine learning models might not be of much use.","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713114981934/d786d13a-a48d-4acf-9cc9-46ce8114e006.jpeg","brief":"Note: This is the second article of the series: Cool Spark ML. The other parts can be found below:\n\nPart 1: K Nearest Neighbours\n\nPart 2: Preprocessing of Data (current)\n\n\nPeople who have been performing Machine Learning for quite a long time know th...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/spark-ml-data-preprocessing/","readTime":10,"tags":["56744722958ef13879b95180"],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T17:20:05.057Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":true,"stickCoverToBottom":true,"subtitle":"Data preprocessing is the process of detecting and correcting inaccurate records from a dataset. It is more important when it comes to big data.","viewsUpdatedOn":1713794442389,"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c082397510b44fe969e47"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c08335ae500253ce7927e","createdAt":"2024-04-14T16:45:38.999Z","updatedAt":"2024-04-14T17:37:13.818Z","views":9,"isActive":true,"hasLatex":false,"popularity":4018.1637,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"My journey to 10k post views on LinkedIn","cuid":"cluzrbxva000508l722tccr88","dateAdded":"2020-05-18T19:02:45.000Z","hasCustomDate":true,"slug":"journey-10k-post-views-linkedin","content":"<p>\"Going Viral\" and \"Trending\" are probably two words which are a big deal in today's world and use networking platforms to connect and grow.</p>\n<p>It's an even bigger deal for a software developer like me who just started a career almost 1.5 years back. I would have never thought that one of my posts on LinkedIn would ever be trending.</p>\n<p>But it has happened, and here I am putting out my story.</p>\n<h2 id=\"heading-how-did-i-perform-on-linkedin-earlier\">How did I perform on LinkedIn earlier?</h2>\n<p>Before May 2020 started, I used to have around 200 connections. Whenever I used to share something on my LinkedIn profile, it would mostly go unnoticed.</p>\n<p>Views would never cross the double-digit mark. Likes were usually single digit numbers, if not 0. 0 Comments. Period.</p>\n<p>Whereas, the people I was following, had a lot of likes and comments on their posts. When I had a look at their posts, their content was very well structured. Their posts were written as if they were telling a story. Then I realized they used to like and comment on these posts because they were able to relate themselves to it.</p>\n<p>Later, when I had a look at my posts on LinkedIn, they never had content. They used to be mostly reshares of someone else's content. You can see a few examples below, along with the view count of that post:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113126922/f2fc9696-7a54-476b-b903-fcebd9fc6270.png\" alt /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113128069/312cd67a-021d-48df-9eef-6abfba4b1e3b.png\" alt /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113129145/673ea854-8919-4610-9a1b-c621b761807e.png\" alt /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113130482/249bb93a-9554-4e5e-a533-9914337a3639.png\" alt /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113131648/a9c1a2b3-6807-4016-823c-9cf24d65ef61.png\" alt /></p>\n<h2 id=\"heading-what-triggered-a-change\">What triggered a change?</h2>\n<p>Around March 2020, I saw an amazing article on a website which gave a glimpse on the new features coming to Spark 3.0 (You can find that post <a target=\"_blank\" href=\"https://towardsdatascience.com/glimpse-into-spark-3-0-early-access-c1854327d6c?ref=localhost\">here</a>). This time around, while sharing this post on LinkedIn, I decided to put in my thoughts on what I felt about the release of Spark 3. Find this post below:</p>\n<iframe src=\"https://www.linkedin.com/embed/feed/update/urn:li:share:6645553272264491009\" height=\"376\" width=\"504\"></iframe>\n\n<p>This was the first time the View count on any of my posts stepped into the triple-figure mark. This was also the first time the Reaction count on my posts touched 5 (the previous best at this point was 3, as shown in the screenshot above).</p>\n<p>Because there's always a first time for everything ;)</p>\n<p>This was the time I realized that if I put my thoughts on what I felt about something, I would surely gain more views and likes. I definitely wanted to grow more on LinkedIn and realized that I had to put my content in a better way that people don't find crowded. (That embedded post above had only 1 paragraph which felt cluttered).</p>\n<h2 id=\"heading-the-guru\">The Guru</h2>\n<p>Around a month later, I saw one of my connections, Vaibhav Sisinty commenting on people's posts about his 5-Day LinkedIn workshop. That's not just once. I saw his comments on multiple people's posts.</p>\n<p>While reading the posts, I actually felt that this isn't promotion going on. People are telling their experiences out of the workshop. People were telling the steps they executed and were also showing the results they achieved.</p>\n<p>The cost of the workshop was a measly Rs. 500. It isn't a huge amount where we would have to empty our pockets to grow. I actually contemplated on whether to join his workshop or not a lot. I was in a dilemma because I was just another (inexperienced) software developer on LinkedIn, amongst 1000s of others. I also had other thoughts on my mind - whether this will workshop will help me as a software developer or not.</p>\n<p>Then I took a leap of faith... and joined his 5-Day LinkedIn Workshop.</p>\n<h2 id=\"heading-the-workshop\">The workshop</h2>\n<p>I was a part of Batch 3 of his workshop, which ran from 5th-11th May. In short, the content of the workshop was divided into a few parts, each taken over a period of 5 days (actually 6, because he gave one extra day off to complete one of the tasks):</p>\n<ul>\n<li><p>Understanding Target Audience</p>\n</li>\n<li><p>Optimizing LinkedIn profile</p>\n</li>\n<li><p>Connect with the target audience</p>\n</li>\n<li><p>Create good content</p>\n</li>\n</ul>\n<p>The content for each of those points in the workshop was well defined. He had recorded sessions for each of those 5 days, and at 9PM he used to have a Live Q&amp;A session of that day's topic. Despite all of the above, execution is key.</p>\n<p>\"No Execution, No Results\".</p>\n<p>This is one of the golden words Vaibhav used to frequently tell inside his videos and the Facebook and WhatsApp groups {Yes, he used to engage with us on WhatsApp as well ;) }. He would also send reminder emails (I guess he sent around 50-70 such mails) to me (and I guess each participant).</p>\n<h2 id=\"heading-the-content-boom\">The content boom</h2>\n<p>Ever since the workshop, I posted few contents, whose views and Reaction count were significantly higher than any of my previous posts. Have a look at the two screenshots below:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113132554/aac13273-f1b6-4b27-be17-bc4fddb02c25.png\" alt /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113133449/225549e6-79b8-4578-9a8c-e74b17a38cd5.png\" alt /></p>\n<p>Views and Reaction count on my posts after executing the contents of the workshop</p>\n<p>At least 3x the usual reaction counts and 5-8x views of my posts. I was definitely improving in my LinkedIn game.</p>\n<p>Profile views and search appearances were up as well:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113134655/0815abb9-ffb1-469d-bbeb-f09559201b7b.png\" alt /></p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113135544/adcdb721-be59-4492-be3a-46de7de6eb3c.png\" alt /></p>\n<p>Profile views after executing contents of the workshop</p>\n<p>Then came the blockbuster. On May 15th 2020 at around 10:15pm, I put up a post on LinkedIn regarding native GPU support for Spark. This was a recent news, and Spark was something I'm working on at my workplace. Posting my thoughts on that news definitely made sense. Have a look at that post below:</p>\n<iframe src=\"https://www.linkedin.com/embed/feed/update/urn:li:share:6667102362034933760\" height=\"775\" width=\"504\"></iframe>\n\n<p>This was the post where I've got the best results on inside LinkedIn. Look at the counts below. These numbers are insane for a software developer who had just started out his career:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113136576/3d403e88-0170-4760-a586-1acfd560151b.png\" alt /></p>\n<p>View and Reaction count for the above post</p>\n<p>Oh yes, and the \"Trending on LinkedIn\" happened as well, 2.5 days after putting up that post:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113137383/e79bc1dc-4722-4547-beaf-d7abd0df817d.png\" alt /></p>\n<p>The Trending part</p>\n<p>Couldn't expect more for myself.</p>\n<h2 id=\"heading-conclusion\">Conclusion</h2>\n<p>While I did start to see great numbers after executing contents in the workshop, complacency isn't allowed. The workshop contents are supposed to be executed for long (unless LinkedIn detects you are a Super User and stops you from executing for the rest of the day).</p>\n<p>Vaibhav's workshop is a great place to get started whoever you are - from an entry level Software Developer, to a Digital Marketer, to someone finding the next job - this workshop is for everyone who wants to improve their LinkedIn profile.</p>\n<p>Do visit <a target=\"_blank\" href=\"https://www.linkedin.com/in/vaibhavsisinty/?ref=localhost\">Vaibhav's profile on LinkedIn</a>.</p>\n<p>Until another post, ciao.</p>\n<p><em>(PS. Not a promotional post. These are definitely my experiences out of this workshop. You can see the results for yourselves)</em></p>\n","contentMarkdown":"\"Going Viral\" and \"Trending\" are probably two words which are a big deal in today's world and use networking platforms to connect and grow.\n\nIt's an even bigger deal for a software developer like me who just started a career almost 1.5 years back. I would have never thought that one of my posts on LinkedIn would ever be trending.\n\nBut it has happened, and here I am putting out my story.\n\n## How did I perform on LinkedIn earlier?\n\nBefore May 2020 started, I used to have around 200 connections. Whenever I used to share something on my LinkedIn profile, it would mostly go unnoticed.\n\nViews would never cross the double-digit mark. Likes were usually single digit numbers, if not 0. 0 Comments. Period.\n\nWhereas, the people I was following, had a lot of likes and comments on their posts. When I had a look at their posts, their content was very well structured. Their posts were written as if they were telling a story. Then I realized they used to like and comment on these posts because they were able to relate themselves to it.\n\nLater, when I had a look at my posts on LinkedIn, they never had content. They used to be mostly reshares of someone else's content. You can see a few examples below, along with the view count of that post:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113126922/f2fc9696-7a54-476b-b903-fcebd9fc6270.png align=\"left\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113128069/312cd67a-021d-48df-9eef-6abfba4b1e3b.png align=\"left\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113129145/673ea854-8919-4610-9a1b-c621b761807e.png align=\"left\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113130482/249bb93a-9554-4e5e-a533-9914337a3639.png align=\"left\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113131648/a9c1a2b3-6807-4016-823c-9cf24d65ef61.png align=\"left\")\n\n## What triggered a change?\n\nAround March 2020, I saw an amazing article on a website which gave a glimpse on the new features coming to Spark 3.0 (You can find that post [here](https://towardsdatascience.com/glimpse-into-spark-3-0-early-access-c1854327d6c?ref=localhost)). This time around, while sharing this post on LinkedIn, I decided to put in my thoughts on what I felt about the release of Spark 3. Find this post below:\n\n<iframe src=\"https://www.linkedin.com/embed/feed/update/urn:li:share:6645553272264491009\" height=\"376\" width=\"504\"></iframe>\n\nThis was the first time the View count on any of my posts stepped into the triple-figure mark. This was also the first time the Reaction count on my posts touched 5 (the previous best at this point was 3, as shown in the screenshot above).\n\nBecause there's always a first time for everything ;)\n\nThis was the time I realized that if I put my thoughts on what I felt about something, I would surely gain more views and likes. I definitely wanted to grow more on LinkedIn and realized that I had to put my content in a better way that people don't find crowded. (That embedded post above had only 1 paragraph which felt cluttered).\n\n## The Guru\n\nAround a month later, I saw one of my connections, Vaibhav Sisinty commenting on people's posts about his 5-Day LinkedIn workshop. That's not just once. I saw his comments on multiple people's posts.\n\nWhile reading the posts, I actually felt that this isn't promotion going on. People are telling their experiences out of the workshop. People were telling the steps they executed and were also showing the results they achieved.\n\nThe cost of the workshop was a measly Rs. 500. It isn't a huge amount where we would have to empty our pockets to grow. I actually contemplated on whether to join his workshop or not a lot. I was in a dilemma because I was just another (inexperienced) software developer on LinkedIn, amongst 1000s of others. I also had other thoughts on my mind - whether this will workshop will help me as a software developer or not.\n\nThen I took a leap of faith... and joined his 5-Day LinkedIn Workshop.\n\n## The workshop\n\nI was a part of Batch 3 of his workshop, which ran from 5th-11th May. In short, the content of the workshop was divided into a few parts, each taken over a period of 5 days (actually 6, because he gave one extra day off to complete one of the tasks):\n\n* Understanding Target Audience\n    \n* Optimizing LinkedIn profile\n    \n* Connect with the target audience\n    \n* Create good content\n    \n\nThe content for each of those points in the workshop was well defined. He had recorded sessions for each of those 5 days, and at 9PM he used to have a Live Q&A session of that day's topic. Despite all of the above, execution is key.\n\n\"No Execution, No Results\".\n\nThis is one of the golden words Vaibhav used to frequently tell inside his videos and the Facebook and WhatsApp groups {Yes, he used to engage with us on WhatsApp as well ;) }. He would also send reminder emails (I guess he sent around 50-70 such mails) to me (and I guess each participant).\n\n## The content boom\n\nEver since the workshop, I posted few contents, whose views and Reaction count were significantly higher than any of my previous posts. Have a look at the two screenshots below:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113132554/aac13273-f1b6-4b27-be17-bc4fddb02c25.png align=\"left\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113133449/225549e6-79b8-4578-9a8c-e74b17a38cd5.png align=\"left\")\n\nViews and Reaction count on my posts after executing the contents of the workshop\n\nAt least 3x the usual reaction counts and 5-8x views of my posts. I was definitely improving in my LinkedIn game.\n\nProfile views and search appearances were up as well:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113134655/0815abb9-ffb1-469d-bbeb-f09559201b7b.png align=\"left\")\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113135544/adcdb721-be59-4492-be3a-46de7de6eb3c.png align=\"left\")\n\nProfile views after executing contents of the workshop\n\nThen came the blockbuster. On May 15th 2020 at around 10:15pm, I put up a post on LinkedIn regarding native GPU support for Spark. This was a recent news, and Spark was something I'm working on at my workplace. Posting my thoughts on that news definitely made sense. Have a look at that post below:\n\n<iframe src=\"https://www.linkedin.com/embed/feed/update/urn:li:share:6667102362034933760\" height=\"775\" width=\"504\"></iframe>\n\nThis was the post where I've got the best results on inside LinkedIn. Look at the counts below. These numbers are insane for a software developer who had just started out his career:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113136576/3d403e88-0170-4760-a586-1acfd560151b.png align=\"left\")\n\nView and Reaction count for the above post\n\nOh yes, and the \"Trending on LinkedIn\" happened as well, 2.5 days after putting up that post:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113137383/e79bc1dc-4722-4547-beaf-d7abd0df817d.png align=\"left\")\n\nThe Trending part\n\nCouldn't expect more for myself.\n\n## Conclusion\n\nWhile I did start to see great numbers after executing contents in the workshop, complacency isn't allowed. The workshop contents are supposed to be executed for long (unless LinkedIn detects you are a Super User and stops you from executing for the rest of the day).\n\nVaibhav's workshop is a great place to get started whoever you are - from an entry level Software Developer, to a Digital Marketer, to someone finding the next job - this workshop is for everyone who wants to improve their LinkedIn profile.\n\nDo visit [Vaibhav's profile on LinkedIn](https://www.linkedin.com/in/vaibhavsisinty/?ref=localhost).\n\nUntil another post, ciao.\n\n*(PS. Not a promotional post. These are definitely my experiences out of this workshop. You can see the results for yourselves)*","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713115232946/c8cec371-3fbd-435a-980c-23a9765f457d.jpeg","brief":"\"Going Viral\" and \"Trending\" are probably two words which are a big deal in today's world and use networking platforms to connect and grow.\nIt's an even bigger deal for a software developer like me who just started a career almost 1.5 years back. I w...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/journey-10k-post-views-linkedin/","readTime":5,"tags":["575ebcbada600b8ef43e51c4"],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T17:37:13.816Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":true,"stickCoverToBottom":true,"subtitle":"My LinkedIn posts' Views and Reaction Count went up by 100x and 20x respectively. See my experiences here.","pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c08335ae500253ce7927e"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c08375610fb416dbc1887","createdAt":"2024-04-14T16:45:43.155Z","updatedAt":"2024-04-14T17:38:22.175Z","views":10,"isActive":true,"hasLatex":false,"popularity":4014.2421,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Spark 3.0 adds native GPU integration: Why that matters?","cuid":"cluzrc12q000f08js6xuyh759","dateAdded":"2020-05-16T18:01:34.000Z","hasCustomDate":true,"slug":"spark-3-native-gpu-integration","content":"<p>You can soon run your Apache Spark programs natively on your GPU. This became possible thanks to collaboration between Nvidia and Databricks. At the GPU Technology Conference, both the companies have presented a solution that brings GPU Acceleration to Spark 3.0 without major code changes.</p>\n<h2 id=\"heading-how-things-were-before\">How things were before?</h2>\n<p>GPU based solutions have existed for Spark for a long time, so what has changed?</p>\n<p>Such GPU integrations into Spark were provided by either third party libraries in Java/Scala, or you had to depend on Cloud Providers which would provide such an infrastructure to run Spark on GPU. Also, programs would usually be restricted to applications based on Spark ML, thus they generally couldn't be applied to other Big Data uses on Scale.</p>\n<p>When it comes to Spark/Python, you had to use custom tools like Horovod, which would also end up using popular Python based libraries like Numpy and Tensorflow. Thus, this approach severely limits the performance of the Spark Programs due to the nature of Python, where programs are dynamically interpreted.</p>\n<p>Don't get me wrong, Python has its very own unique use-cases which Scala doesn't provide (yet), but because Spark was built to do Big Data operations effectively, Python severely restricts the performance.</p>\n<h2 id=\"heading-what-happened-now\">What happened now?</h2>\n<p>With the release of Spark 3.0, native GPU based acceleration will be provided within Spark. This acceleration is based on the open source <a target=\"_blank\" href=\"https://www.anrdoezrs.net/links/9041660/type/dlg/sid/zd-ad14a02e5d404bd4822065953dda157b--%7Cxid:fr1589641152241fef/https://developer.nvidia.com/rapids?ref=localhost\">RAPIDS</a> suite of software libraries, Nvidia built on <a target=\"_blank\" href=\"https://www.anrdoezrs.net/links/9041660/type/dlg/sid/zd-ad14a02e5d404bd4822065953dda157b--%7Cxid:fr1589641152241dce/https://developer.nvidia.com/machine-learning?ref=localhost\">CUDA-X AI</a>. This will allow developers to run Spark code without any modifications on GPUs - thereby alleviating load off the CPU.</p>\n<p>This also benefits Spark SQL and <code>DataFrame</code> operations, thereby making the GPU acceleration benefits available for non-Machine Learning workloads as well. This will also bring capabilities where we don't have to provision a dedicated Spark Cluster for AI and ML based jobs.</p>\n<p>In an advanced briefing for members of the press, NVidia CEO Jensen Huang explained that users of Spark clusters on <a target=\"_blank\" href=\"https://click.linksynergy.com/deeplink?id=IokOf8qagZo&amp;mid=24542&amp;u1=zd-ad14a02e5d404bd4822065953dda157b--%7Cxid%3Afr1589641152241ghb&amp;murl=https%3A%2F%2Fazure.microsoft.com%2Fservices%2Fmachine-learning%2F&amp;ref=localhost\">Azure Machine Learning</a> or <a target=\"_blank\" href=\"https://aws.amazon.com/sagemaker/?ref=localhost\">Amazon SageMaker</a> can benefit from the GPU acceleration as well. This means that the infrastructure is already in place, it is now upon other cloud providers to provide the necessary infrastructure, and upon developers to adopt and build their workloads to the new changes.</p>\n<h2 id=\"heading-adobe-spark-gpu-acceleration\">Adobe + Spark GPU Acceleration</h2>\n<p>Adobe and Nvidia had signed a <a target=\"_blank\" href=\"https://news.adobe.com/news/news-details/2018/Adobe-and-NVIDIA-Announce-Partnership-to-Deliver-New-AI-Services-for-Creativity-and-Digital-Experiences/default.aspx?ref=localhost\">deal</a> in 2018 where they will utilize Nvidia's AI capabilities for their solutions. Building upon this deal, Adobe has been an early adopter for this new GPU Acceleration on Spark, and they have shown a 7x improvement in performance of their workloads, while saving up to 90% of the costs.</p>\n<p>These are serious numbers. Imagine, if a company as huge as Adobe is able to bring down costs while improving performance, other companies too can follow suit and we could see Profits and Performance for everyone. Period.</p>\n<h2 id=\"heading-conclusion\">Conclusion</h2>\n<p>Imagine how game changing this can prove to be for the Big Data community overall. No longer will we have to wait for operations to complete when we can utilize the GPU, we have on our local Gaming PCs and laptops. We will also be able to utilize GPU servers on Cloud for Spark without doing major changes.</p>\n<p>This can also encourage many people to start using Scala for AI and Machine Learning instead of Python. While I do realize that there are no major visualization libraries supporting Spark available in Scala, an encouragement to do machine learning with Spark shall bring more enthusiasm for Scala, due to the disadvantages I mentioned for Python above. This in turn will lead to a growth in the Scala community, which will further result in availability of more and more libraries.</p>\n<p>For now, there is a Scala visualization library that supports Spark, in active development, which when released to MVN Repository could be a game changer. Head over to <a target=\"_blank\" href=\"https://github.com/MarkCLewis/SwiftVis2?ref=localhost\">SwiftViz2's GitHub repo</a> for more info. You can place safe bets on this one :)</p>\n<p>In short, this is a win-win situation for everyone involved in this ecosystem.</p>\n<p>Until another blog post, Ciao.</p>\n<h3 id=\"heading-sources\">SOURCES</h3>\n<p><a target=\"_blank\" href=\"https://www.zdnet.com/article/nvidia-and-databricks-announce-gpu-acceleration-for-spark-3-0/?ref=localhost\">ZdNet</a>, <a target=\"_blank\" href=\"https://nvidianews.nvidia.com/news/nvidia-accelerates-apache-spark-worlds-leading-data-analytics-platform?ref=localhost\">Nvidia Newsroom</a></p>\n","contentMarkdown":"You can soon run your Apache Spark programs natively on your GPU. This became possible thanks to collaboration between Nvidia and Databricks. At the GPU Technology Conference, both the companies have presented a solution that brings GPU Acceleration to Spark 3.0 without major code changes.\n\n## How things were before?\n\nGPU based solutions have existed for Spark for a long time, so what has changed?\n\nSuch GPU integrations into Spark were provided by either third party libraries in Java/Scala, or you had to depend on Cloud Providers which would provide such an infrastructure to run Spark on GPU. Also, programs would usually be restricted to applications based on Spark ML, thus they generally couldn't be applied to other Big Data uses on Scale.\n\nWhen it comes to Spark/Python, you had to use custom tools like Horovod, which would also end up using popular Python based libraries like Numpy and Tensorflow. Thus, this approach severely limits the performance of the Spark Programs due to the nature of Python, where programs are dynamically interpreted.\n\nDon't get me wrong, Python has its very own unique use-cases which Scala doesn't provide (yet), but because Spark was built to do Big Data operations effectively, Python severely restricts the performance.\n\n## What happened now?\n\nWith the release of Spark 3.0, native GPU based acceleration will be provided within Spark. This acceleration is based on the open source [RAPIDS](https://www.anrdoezrs.net/links/9041660/type/dlg/sid/zd-ad14a02e5d404bd4822065953dda157b--%7Cxid:fr1589641152241fef/https://developer.nvidia.com/rapids?ref=localhost) suite of software libraries, Nvidia built on [CUDA-X AI](https://www.anrdoezrs.net/links/9041660/type/dlg/sid/zd-ad14a02e5d404bd4822065953dda157b--%7Cxid:fr1589641152241dce/https://developer.nvidia.com/machine-learning?ref=localhost). This will allow developers to run Spark code without any modifications on GPUs - thereby alleviating load off the CPU.\n\nThis also benefits Spark SQL and `DataFrame` operations, thereby making the GPU acceleration benefits available for non-Machine Learning workloads as well. This will also bring capabilities where we don't have to provision a dedicated Spark Cluster for AI and ML based jobs.\n\nIn an advanced briefing for members of the press, NVidia CEO Jensen Huang explained that users of Spark clusters on [Azure Machine Learning](https://click.linksynergy.com/deeplink?id=IokOf8qagZo&mid=24542&u1=zd-ad14a02e5d404bd4822065953dda157b--%7Cxid%3Afr1589641152241ghb&murl=https%3A%2F%2Fazure.microsoft.com%2Fservices%2Fmachine-learning%2F&ref=localhost) or [Amazon SageMaker](https://aws.amazon.com/sagemaker/?ref=localhost) can benefit from the GPU acceleration as well. This means that the infrastructure is already in place, it is now upon other cloud providers to provide the necessary infrastructure, and upon developers to adopt and build their workloads to the new changes.\n\n## Adobe + Spark GPU Acceleration\n\nAdobe and Nvidia had signed a [deal](https://news.adobe.com/news/news-details/2018/Adobe-and-NVIDIA-Announce-Partnership-to-Deliver-New-AI-Services-for-Creativity-and-Digital-Experiences/default.aspx?ref=localhost) in 2018 where they will utilize Nvidia's AI capabilities for their solutions. Building upon this deal, Adobe has been an early adopter for this new GPU Acceleration on Spark, and they have shown a 7x improvement in performance of their workloads, while saving up to 90% of the costs.\n\nThese are serious numbers. Imagine, if a company as huge as Adobe is able to bring down costs while improving performance, other companies too can follow suit and we could see Profits and Performance for everyone. Period.\n\n## Conclusion\n\nImagine how game changing this can prove to be for the Big Data community overall. No longer will we have to wait for operations to complete when we can utilize the GPU, we have on our local Gaming PCs and laptops. We will also be able to utilize GPU servers on Cloud for Spark without doing major changes.\n\nThis can also encourage many people to start using Scala for AI and Machine Learning instead of Python. While I do realize that there are no major visualization libraries supporting Spark available in Scala, an encouragement to do machine learning with Spark shall bring more enthusiasm for Scala, due to the disadvantages I mentioned for Python above. This in turn will lead to a growth in the Scala community, which will further result in availability of more and more libraries.\n\nFor now, there is a Scala visualization library that supports Spark, in active development, which when released to MVN Repository could be a game changer. Head over to [SwiftViz2's GitHub repo](https://github.com/MarkCLewis/SwiftVis2?ref=localhost) for more info. You can place safe bets on this one :)\n\nIn short, this is a win-win situation for everyone involved in this ecosystem.\n\nUntil another blog post, Ciao.\n\n### SOURCES\n\n[ZdNet](https://www.zdnet.com/article/nvidia-and-databricks-announce-gpu-acceleration-for-spark-3-0/?ref=localhost), [Nvidia Newsroom](https://nvidianews.nvidia.com/news/nvidia-accelerates-apache-spark-worlds-leading-data-analytics-platform?ref=localhost)","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713116256929/d92fe90a-db78-4f16-afb4-e05a0273d536.jpeg","brief":"You can soon run your Apache Spark programs natively on your GPU. This became possible thanks to collaboration between Nvidia and Databricks. At the GPU Technology Conference, both the companies have presented a solution that brings GPU Acceleration ...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/spark-3-native-gpu-integration/","readTime":4,"tags":["57960642c691eeb2473cc9c0","56744722958ef13879b95180"],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T17:38:22.174Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":true,"stickCoverToBottom":true,"subtitle":"You won't have to depend on your CPU anymore to run Spark based jobs. You will be able to offload them off to the GPU. Learn why it matters","viewsUpdatedOn":1713920433130,"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c08375610fb416dbc1887"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c083cdbf837e5981954ca","createdAt":"2024-04-14T16:45:48.489Z","updatedAt":"2024-04-14T17:41:12.923Z","views":36,"isActive":true,"hasLatex":false,"popularity":3997.1,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Tail Recursion: Why and How-to Use in Scala","cuid":"cluzrc56t000308l8a79s9lpe","dateAdded":"2020-05-07T19:45:00.000Z","hasCustomDate":true,"slug":"tail-recursion-scala-why-how-to","content":"<p>In the below code, I have written a recursive function that multiplies all the natural numbers up to the number passed as a parameter to the function. As you might have guessed, this is nothing but computing the factorial of a particular number.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">recursiveProd</span></span>(x: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">BigInt</span> = {\n    <span class=\"hljs-keyword\">if</span> (x &lt;= <span class=\"hljs-number\">1</span>) \n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span>\n    <span class=\"hljs-keyword\">else</span> \n        <span class=\"hljs-keyword\">return</span> x * recursiveProd(x<span class=\"hljs-number\">-1</span>)\n}\n</code></pre>\n<p>Recursive Factorial Program</p>\n<p>Let us see how this function is being executed as a whole assuming we executed <code>recursiveProd(5)</code>:</p>\n<pre><code class=\"lang-scala\">recursiveProd(<span class=\"hljs-number\">5</span>)  \n<span class=\"hljs-number\">5</span> * recursiveProd(<span class=\"hljs-number\">4</span>)  \n    (<span class=\"hljs-number\">4</span> * recursiveProd(<span class=\"hljs-number\">3</span>))  \n         (<span class=\"hljs-number\">3</span> * recursiveProd(<span class=\"hljs-number\">2</span>))\n              (<span class=\"hljs-number\">2</span> * recursiveProd(<span class=\"hljs-number\">1</span>))  \n                   <span class=\"hljs-number\">1</span> \n<span class=\"hljs-number\">120</span>\n</code></pre>\n<p>From above, each recursive call has to be completed first before the actual work of calculating the product begins. Each recursive call saves the current state, and proceeds to call the next recursive function. This happens repeatedly until the base case is reached. In between, you might also encounter the Stack Overflow error.</p>\n<p>So, in each step you execute 2 steps, retrieve the current value and the value from the next stage (as a recursive call), and then multiply them. Subsequent recursive calls will do the same. If you can visualize this correctly, you will notice this recursive call was completed in <strong>14 computations</strong> (4 multiplications, 5 recursive calls, 5 returning values), with computations happening in each step.</p>\n<h3 id=\"heading-tail-recursion\">Tail Recursion</h3>\n<p>Now let’s consider Tail Recursion. In Tail Recursion, all the processing related to the recursive function must finish before the recursive call takes place. This means that <strong>if a function is tail-recursive, the last action is a call to itself</strong>.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">tailRecursiveProd</span></span>(x: <span class=\"hljs-type\">Int</span>, currentTotal: <span class=\"hljs-type\">BigInt</span>): <span class=\"hljs-type\">BigInt</span> = {\n    <span class=\"hljs-keyword\">if</span> (x &lt;= <span class=\"hljs-number\">1</span>) \n        <span class=\"hljs-keyword\">return</span> currentTotal\n    <span class=\"hljs-keyword\">else</span> \n        <span class=\"hljs-keyword\">return</span> tailRecursiveProd(x - <span class=\"hljs-number\">1</span>, currentTotal * x)\n}\n</code></pre>\n<p>In this scenario, despite there being a multiplication operation, it happens when the argument is passed to the next recursive call. In short, we send the current state of the recursive call to the next state, and the same process will be repeated until the base case is reached. Let us see how this is executed:</p>\n<pre><code class=\"lang-scala\">recursiveProd(<span class=\"hljs-number\">5</span>,<span class=\"hljs-number\">1</span>)\nrecursiveProd(<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">5</span>)\nrecursiveProd(<span class=\"hljs-number\">3</span>,<span class=\"hljs-number\">20</span>)\nrecursiveProd(<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">60</span>)\nrecursiveProd(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">120</span>)\n<span class=\"hljs-number\">120</span>\n</code></pre>\n<p>In this way, we can save up additional stack memory which would've otherwise be wasted to compute the multiplications at every return step. Thus, this implementation only takes 10 computations (5 recursive calls, 5 returning values). This is equivalent of you using a loop to process the factorial.</p>\n<p>Thus, you should always try and convert your recursive function into a tail recursive function wherever possible.</p>\n<h3 id=\"heading-tail-recursion-in-scala\">Tail Recursion in Scala</h3>\n<p>One good thing about Scala is that it automatically recognizes two types of tail-recursive methods automatically and optimizes them. These types are:</p>\n<ol>\n<li><p>Methods within an <code>object</code></p>\n</li>\n<li><p>Methods defined as <code>final</code></p>\n</li>\n</ol>\n<p>Sadly, if you write a non-<code>final</code> tail-recursive function inside a <code>class</code>, or even a <code>case class</code>, it will not be automatically optimized by the Scala Compiler because a <code>class</code> can be <code>extend</code>ed and these methods can be <code>override</code>n. Consider my code given below:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">object</span> <span class=\"hljs-title\">Bm</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">nTailRecursion</span></span>(n: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">Int</span> = {\n        <span class=\"hljs-keyword\">if</span> (n == <span class=\"hljs-number\">0</span>) <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> nTailRecursion(n - <span class=\"hljs-number\">1</span>)\n    }\n}\n\n<span class=\"hljs-keyword\">case</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Bm</span>(<span class=\"hljs-params\"></span>) </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">tailRecursion</span></span>(n: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">Int</span> = {\n        <span class=\"hljs-keyword\">if</span> (n == <span class=\"hljs-number\">0</span>) <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> tailRecursion(n - <span class=\"hljs-number\">1</span>)\n    }\n\n    <span class=\"hljs-keyword\">final</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">tailsRecursion</span></span>(n: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">Int</span> = {\n        <span class=\"hljs-keyword\">if</span> (n == <span class=\"hljs-number\">0</span>) <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> tailsRecursion(n - <span class=\"hljs-number\">1</span>)\n    }\n}\n</code></pre>\n<p>You can see that all these functions are doing the same task. Now:</p>\n<ol>\n<li><p>Start a Scala REPL (Install Scala on your machine, then type <code>scala</code> on your command line/terminal and press Enter)</p>\n</li>\n<li><p>Type <code>:paste</code> and press Enter</p>\n</li>\n<li><p>Paste the code snippet above</p>\n</li>\n<li><p>Press <code>Ctrl-D</code> to exit the paste mode</p>\n</li>\n</ol>\n<p>Then, try running <code>Bm.nTailRecursion(60000)</code> and <code>Bm().tailsRecursion(60000)</code>. I've tried that on my current laptop with an Intel i7-8750H processor and 16GB RAM, and both of them worked fine. Now, when you try running <code>Bm().tailRecursion(60000)</code>, you see a familiar <code>java.lang.StackOverflowError</code> which usually occurs with recursive function:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113146798/fb49ff24-b09e-4750-a4a3-655c2362f5bd.png\" alt /></p>\n<p>Sure, you could play around with the JVM memory limits and possibly execute this function properly. You must always remember that memory is an intensive resource, and non-availability of memory might crash other programs, as well as your current program.</p>\n<p>Fortunately, Scala provides the <code>@tailrec</code> annotation to denote that a method is actually tail-recursive. First you will have to import <code>scala.annotation.tailrec</code> and place that annotation before the function you want to mark as tail-recursive. Place this annotation before <code>tailRecursion()</code> inside the <code>case class</code> and now copy-paste inside the REPL and try again. This time it won't throw the dreaded <code>`java.lang.StackOverflowError` </code> Exception.</p>\n<h3 id=\"heading-convert-a-recursive-function-to-a-tail-recursive-function\">Convert a recursive function to a tail-recursive function</h3>\n<p>In some cases, you might want to retain the original method's signature (eg. Factorial). This can be done using the following steps:</p>\n<p>1. Create a second function</p>\n<p>Within the <code>recursiveProd</code> as defined in the first code piece above, we now define another method, <code>cumulativeRecursion</code> with two parameters: <code>n</code>, our number and <code>res</code>, the result of recursion. We retain the algorithm of the first method as is. At this point our new method looks like:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">recursiveProd</span></span>(n: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">Int</span> = {\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">cumulativeRecursion</span></span>(n: <span class=\"hljs-type\">Int</span>, res: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">Int</span> = {\n        <span class=\"hljs-keyword\">if</span> (n &lt;= <span class=\"hljs-number\">1</span>) <span class=\"hljs-number\">1</span>\n        <span class=\"hljs-keyword\">else</span> n * recursiveProd(n - <span class=\"hljs-number\">1</span>)\n    }\n}\n</code></pre>\n<p>2. Modify the second method's algorithm</p>\n<p>We will now utilize the accumulator we've just created, <code>res</code> and modify the function such that the base case returns the accumulated value and the other case recursively calls the new method again:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">recursiveProd</span></span>(n: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">Int</span> = {\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">cumulativeRecursion</span></span>(n: <span class=\"hljs-type\">Int</span>, res: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">Int</span> = {\n        <span class=\"hljs-keyword\">if</span> (n &lt;= <span class=\"hljs-number\">1</span>) res\n        <span class=\"hljs-keyword\">else</span> cumulativeRecursion(n - <span class=\"hljs-number\">1</span>, res * n)\n    }\n}\n</code></pre>\n<p>3. Annotate the second method and call the new method</p>\n<p>We will now annotate our new method with <code>@tailrec</code> as shown earlier and we will now call this method from our original method:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">recursiveProd</span></span>(n: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">Int</span> = {\n    <span class=\"hljs-meta\">@tailrec</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">cumulativeRecursion</span></span>(n: <span class=\"hljs-type\">Int</span>, res: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">Int</span> = {\n        <span class=\"hljs-keyword\">if</span> (n &lt;= <span class=\"hljs-number\">1</span>) res\n        <span class=\"hljs-keyword\">else</span> cumulativeRecursion(n - <span class=\"hljs-number\">1</span>, res * n)\n    }\n    cumulativeRecursion(n, <span class=\"hljs-number\">1</span>)\n}\n</code></pre>\n<p>Hence, you retain your method's original signature, as well as converted it into a tail-recursive call (Though this will add 1 extra stack call to the new function).</p>\n<h3 id=\"heading-conclusion\">CONCLUSION</h3>\n<p>In this post, I have:</p>\n<ul>\n<li><p>Defined Tail Recursion</p>\n</li>\n<li><p>Introduced <code>@tailrec</code> annotation</p>\n</li>\n<li><p>Shown a formula to convert a recursive function into a tail-recursive one.</p>\n</li>\n</ul>\n<p>Hope you have enjoyed this post. Do follow my profiles on <a target=\"_blank\" href=\"https://www.linkedin.com/in/sparker0i?ref=localhost\">LinkedIn</a>, <a target=\"_blank\" href=\"https://github.com/Sparker0i?ref=localhost\">GitHub</a> and <a target=\"_blank\" href=\"https://twiiter.com/Sparker0i?ref=localhost\">Twitter</a>.</p>\n<p>Ciao, until the next post.</p>\n<p>Reference: <a target=\"_blank\" href=\"https://alvinalexander.com/scala/fp-book/tail-recursive-algorithms/?ref=localhost\">Tail Recursive Algorithms</a></p>\n","contentMarkdown":"In the below code, I have written a recursive function that multiplies all the natural numbers up to the number passed as a parameter to the function. As you might have guessed, this is nothing but computing the factorial of a particular number.\n\n```scala\ndef recursiveProd(x: Int): BigInt = {\n    if (x <= 1) \n        return 1\n    else \n        return x * recursiveProd(x-1)\n}\n```\n\nRecursive Factorial Program\n\nLet us see how this function is being executed as a whole assuming we executed `recursiveProd(5)`:\n\n```scala\nrecursiveProd(5)  \n5 * recursiveProd(4)  \n    (4 * recursiveProd(3))  \n         (3 * recursiveProd(2))\n              (2 * recursiveProd(1))  \n                   1 \n120\n```\n\nFrom above, each recursive call has to be completed first before the actual work of calculating the product begins. Each recursive call saves the current state, and proceeds to call the next recursive function. This happens repeatedly until the base case is reached. In between, you might also encounter the Stack Overflow error.\n\nSo, in each step you execute 2 steps, retrieve the current value and the value from the next stage (as a recursive call), and then multiply them. Subsequent recursive calls will do the same. If you can visualize this correctly, you will notice this recursive call was completed in **14 computations** (4 multiplications, 5 recursive calls, 5 returning values), with computations happening in each step.\n\n### Tail Recursion\n\nNow let’s consider Tail Recursion. In Tail Recursion, all the processing related to the recursive function must finish before the recursive call takes place. This means that **if a function is tail-recursive, the last action is a call to itself**.\n\n```scala\ndef tailRecursiveProd(x: Int, currentTotal: BigInt): BigInt = {\n    if (x <= 1) \n        return currentTotal\n    else \n        return tailRecursiveProd(x - 1, currentTotal * x)\n}\n```\n\nIn this scenario, despite there being a multiplication operation, it happens when the argument is passed to the next recursive call. In short, we send the current state of the recursive call to the next state, and the same process will be repeated until the base case is reached. Let us see how this is executed:\n\n```scala\nrecursiveProd(5,1)\nrecursiveProd(4,5)\nrecursiveProd(3,20)\nrecursiveProd(2,60)\nrecursiveProd(1,120)\n120\n```\n\nIn this way, we can save up additional stack memory which would've otherwise be wasted to compute the multiplications at every return step. Thus, this implementation only takes 10 computations (5 recursive calls, 5 returning values). This is equivalent of you using a loop to process the factorial.\n\nThus, you should always try and convert your recursive function into a tail recursive function wherever possible.\n\n### Tail Recursion in Scala\n\nOne good thing about Scala is that it automatically recognizes two types of tail-recursive methods automatically and optimizes them. These types are:\n\n1. Methods within an `object`\n    \n2. Methods defined as `final`\n    \n\nSadly, if you write a non-`final` tail-recursive function inside a `class`, or even a `case class`, it will not be automatically optimized by the Scala Compiler because a `class` can be `extend`ed and these methods can be `override`n. Consider my code given below:\n\n```scala\nobject Bm {\n    def nTailRecursion(n: Int): Int = {\n        if (n == 0) 1 else nTailRecursion(n - 1)\n    }\n}\n\ncase class Bm() {\n    def tailRecursion(n: Int): Int = {\n        if (n == 0) 1 else tailRecursion(n - 1)\n    }\n\n    final def tailsRecursion(n: Int): Int = {\n        if (n == 0) 1 else tailsRecursion(n - 1)\n    }\n}\n```\n\nYou can see that all these functions are doing the same task. Now:\n\n1. Start a Scala REPL (Install Scala on your machine, then type `scala` on your command line/terminal and press Enter)\n    \n2. Type `:paste` and press Enter\n    \n3. Paste the code snippet above\n    \n4. Press `Ctrl-D` to exit the paste mode\n    \n\nThen, try running `Bm.nTailRecursion(60000)` and `Bm().tailsRecursion(60000)`. I've tried that on my current laptop with an Intel i7-8750H processor and 16GB RAM, and both of them worked fine. Now, when you try running `Bm().tailRecursion(60000)`, you see a familiar `java.lang.StackOverflowError` which usually occurs with recursive function:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113146798/fb49ff24-b09e-4750-a4a3-655c2362f5bd.png align=\"left\")\n\nSure, you could play around with the JVM memory limits and possibly execute this function properly. You must always remember that memory is an intensive resource, and non-availability of memory might crash other programs, as well as your current program.\n\nFortunately, Scala provides the `@tailrec` annotation to denote that a method is actually tail-recursive. First you will have to import `scala.annotation.tailrec` and place that annotation before the function you want to mark as tail-recursive. Place this annotation before `tailRecursion()` inside the `case class` and now copy-paste inside the REPL and try again. This time it won't throw the dreaded `` `java.lang.StackOverflowError` `` Exception.\n\n### Convert a recursive function to a tail-recursive function\n\nIn some cases, you might want to retain the original method's signature (eg. Factorial). This can be done using the following steps:\n\n1\\. Create a second function\n\nWithin the `recursiveProd` as defined in the first code piece above, we now define another method, `cumulativeRecursion` with two parameters: `n`, our number and `res`, the result of recursion. We retain the algorithm of the first method as is. At this point our new method looks like:\n\n```scala\ndef recursiveProd(n: Int): Int = {\n    def cumulativeRecursion(n: Int, res: Int): Int = {\n        if (n <= 1) 1\n        else n * recursiveProd(n - 1)\n    }\n}\n```\n\n2\\. Modify the second method's algorithm\n\nWe will now utilize the accumulator we've just created, `res` and modify the function such that the base case returns the accumulated value and the other case recursively calls the new method again:\n\n```scala\ndef recursiveProd(n: Int): Int = {\n    def cumulativeRecursion(n: Int, res: Int): Int = {\n        if (n <= 1) res\n        else cumulativeRecursion(n - 1, res * n)\n    }\n}\n```\n\n3\\. Annotate the second method and call the new method\n\nWe will now annotate our new method with `@tailrec` as shown earlier and we will now call this method from our original method:\n\n```scala\ndef recursiveProd(n: Int): Int = {\n    @tailrec def cumulativeRecursion(n: Int, res: Int): Int = {\n        if (n <= 1) res\n        else cumulativeRecursion(n - 1, res * n)\n    }\n    cumulativeRecursion(n, 1)\n}\n```\n\nHence, you retain your method's original signature, as well as converted it into a tail-recursive call (Though this will add 1 extra stack call to the new function).\n\n### CONCLUSION\n\nIn this post, I have:\n\n* Defined Tail Recursion\n    \n* Introduced `@tailrec` annotation\n    \n* Shown a formula to convert a recursive function into a tail-recursive one.\n    \n\nHope you have enjoyed this post. Do follow my profiles on [LinkedIn](https://www.linkedin.com/in/sparker0i?ref=localhost), [GitHub](https://github.com/Sparker0i?ref=localhost) and [Twitter](https://twiiter.com/Sparker0i?ref=localhost).\n\nCiao, until the next post.\n\nReference: [Tail Recursive Algorithms](https://alvinalexander.com/scala/fp-book/tail-recursive-algorithms/?ref=localhost)","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713116325578/acb5a151-b87e-4b92-9dc9-6efa5340cf4d.png","brief":"In the below code, I have written a recursive function that multiplies all the natural numbers up to the number passed as a parameter to the function. As you might have guessed, this is nothing but computing the factorial of a particular number.\ndef ...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/tail-recursion-scala-why-how-to/","readTime":5,"tags":["56744723958ef13879b952a7"],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T17:41:12.923Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":true,"stickCoverToBottom":true,"subtitle":"Read my blog post to know more about the advantages of tail recursion, and how do you use it in Scala.","viewsUpdatedOn":1713938439630,"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c083cdbf837e5981954ca"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c0843dbf837e5981954cc","createdAt":"2024-04-14T16:45:55.283Z","updatedAt":"2024-04-14T17:43:28.181Z","views":175,"isActive":true,"hasLatex":true,"popularity":3961.4147,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Cool Spark ML: K Nearest Neighbors","cuid":"cluzrcafm000408l80c29h7lc","dateAdded":"2020-04-19T05:41:03.000Z","hasCustomDate":true,"slug":"spark-machine-learning-knn","content":"<p><em>Note: This article is the first of the Series: Cool Spark ML. Other parts are coming soon.</em></p>\n<p>I had taken up a few machine learning courses in my college throughout 2018. Most of the problems there were solved using Python and the necessary libraries - NumPy, Pandas, Scikit-Learn and Matplotlib. With my daily work at IBM now requiring me to use Scala and Spark, I decided to use my free time during the lockdown to try out Spark ML.</p>\n<p><em>Note: All the codes in the Cool Spark ML Series will be available on</em> <a target=\"_blank\" href=\"https://github.com/Sparker0i/Cool-Spark-ML?ref=localhost\"><em>my GitHub repo</em></a></p>\n<h3 id=\"heading-intro-to-spark-ml\">Intro to Spark ML</h3>\n<p>As the name suggests, Spark ML is the Machine Learning library consisting of common Machine learning algorithms - classification, regression, clustering etc.</p>\n<h3 id=\"heading-why-spark-ml\">Why Spark ML?</h3>\n<p>Pandas - a Python library - won’t work every time. It is a single machine tool, so it's constrained by the machine's limits. Moreover, pandas doesn’t have any parallelism built in, which means it uses only one CPU core. You may hit a dead-end on datasets of the size of a few gigabytes. Pandas won't help if you want to work on very big datasets.</p>\n<p>We are now in the Big Data era, where gigabytes of data are generated every few seconds. Such datasets will require powerful systems to run even the basic machine learning algorithms. The cost of getting such a powerful system will be huge, as well as the costs to scale them up. With distributed computers, such calculations can be sent to multiple low-end machines, which prevents the cost of getting a single high-end machine.</p>\n<p>This is where Spark kicks in. Spark has the concept of <code>DataFrame</code> (now deprecated in favor of Datasets), which behaves very similar to how a Pandas <code>DataFrame</code> would do, including having very similar APIs too. The advantage of using Spark <code>DataFrame</code> is that it was designed from ground-up to support Big Data. Spark can also distribute such <code>DataFrame</code>s across multiple machines and collect the calculated results.</p>\n<h3 id=\"heading-knn-k-nearest-neighbors\">KNN: K-Nearest Neighbors</h3>\n<p>The process in KNN is pretty simple. You load your entire dataset first, each of which will have input columns and one output column. This is then split into a training set and a testing set. You then use your training set to train your model, and then use the testing set to predict the output column value by testing it against the model. You then compare the actual and the predicted target values and calculate the accuracy of your model.</p>\n<h3 id=\"heading-problem-definition\">Problem Definition</h3>\n<p>We are going to train a model to predict the famous <a target=\"_blank\" href=\"http://archive.ics.uci.edu/ml/datasets/iris?ref=localhost\">Iris dataset</a>. The Iris Flower Dataset involves predicting the flower species given measurements of iris flowers.</p>\n<p>It is a multiclass classification problem. The number of observations for each class is the same. The dataset is small in size with only 150 rows with 4 input variables and 1 output variable.</p>\n<p>The 4 features are described as follows:</p>\n<ol>\n<li><p>Sepal-Length, in cm</p>\n</li>\n<li><p>Sepal-Width, in cm</p>\n</li>\n<li><p>Petal-Length, in cm</p>\n</li>\n<li><p>Petal-Width, in cm</p>\n</li>\n</ol>\n<h3 id=\"heading-prerequisites\">Prerequisites</h3>\n<ol>\n<li><p>Create a Scala project in IntelliJ IDEA based on SBT</p>\n</li>\n<li><p>Select Scala version 2.11.12</p>\n</li>\n<li><p>Include <code>spark-core</code>, <code>spark-sql</code> and <code>spark-ml</code> 2.4.5 as library dependencies in your <code>build.sbt</code></p>\n</li>\n</ol>\n<h3 id=\"heading-knn-steps\">KNN Steps</h3>\n<p>In this blog post, I will be developing KNN algorithm from scratch. The process to perform KNN can be broken down into 3 easy steps:</p>\n<ol>\n<li><p>Calculate Euclidean Distance</p>\n</li>\n<li><p>Get Nearest Neighbors</p>\n</li>\n<li><p>Make Predictions</p>\n</li>\n</ol>\n<h3 id=\"heading-step-1-calculate-euclidean-distance\">Step 1: Calculate Euclidean Distance</h3>\n<p>The first step will be to calculate the distance between two rows in a Dataset. Rows of data are mostly made up of numbers and an easy way to calculate the distance between two rows or vectors of numbers is to draw a straight line.</p>\n<p>Euclidean Distance is calculated as the square root of the sum of the squared differences between the two vectors, as given in the image below:</p>\n<p><a target=\"_blank\" href=\"https://www.codecogs.com/eqnedit.php?latex=%5Cinline&amp;space%3B%5Cbg_white=&amp;space%3B%7B%5Ccolor%7BRed%7D=&amp;space%3B%24%24dist_%7Bx_1%2Cx_2%7D=&amp;space%3B=&amp;space%3B%5Csqrt%7B%5Csum_%7Bi=0%7D%5E%7BN%7D&amp;space%3B%28%7Bx_1_i=&amp;space%3B-=&amp;space%3Bx_2_i%7D%29%5E2%7D.%24%24%7D=&amp;ref=localhost\"><img src=\"https://latex.codecogs.com/gif.latex?%5Cinline&amp;space;%5Cbg_white&amp;space;%7B%5Ccolor%7BRed%7D&amp;space;$$dist_%7Bx_1,x_2%7D&amp;space;=&amp;space;%5Csqrt%7B%5Csum_%7Bi=0%7D%5E%7BN%7D&amp;space;(%7Bx_1_i&amp;space;-&amp;space;x_2_i%7D)%5E2%7D.$$%7D\" alt /></a></p>\n<p>Where <code>x1</code> is the first row of data, <code>x2</code> is the second row of data, and <code>i</code> is a specific index for a column as we sum across all columns. Smaller the value, more similar will be the two rows.</p>\n<p>Since we will be reading our data and transforming it using Spark, to compute distances between two <code>Row</code>s in a <code>DataFrame</code>, we write the function below in Scala:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">computeEuclideanDistance</span></span>(row1: <span class=\"hljs-type\">Row</span>, row2: <span class=\"hljs-type\">Row</span>): <span class=\"hljs-type\">Double</span> = {\n    <span class=\"hljs-keyword\">var</span> distance = <span class=\"hljs-number\">0.0</span>\n    <span class=\"hljs-keyword\">for</span> (i &lt;- <span class=\"hljs-number\">0</span> until row1.length - <span class=\"hljs-number\">1</span>) {\n        distance += math.pow(row1.getDouble(i) - row2.getDouble(i), <span class=\"hljs-number\">2</span>)\n    }\n    math.sqrt(distance)\n}\n</code></pre>\n<p>You can see that the function assumes that the last column in each row is an output value which is ignored from the distance calculation.</p>\n<h3 id=\"heading-step-2-get-nearest-neighbors\">Step 2: Get Nearest Neighbors</h3>\n<p>Neighbors for a new piece of data in the dataset are the k closest instances, as defined by our distance measure. To locate the neighbors for a new piece of data within a dataset we must first calculate the distance between each record in the dataset to the new piece of data. We can do this using our distance function prepared above.</p>\n<p>We can do this by keeping track of the distance for each record in the dataset as a tuple, sort the list of tuples by the distance, and then retrieve the neighbors. The below function does this job in Scala:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">getNeighbours</span></span>(trainSet: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Row</span>], testRow: <span class=\"hljs-type\">Row</span>, k: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">Row</span>] = {\n    <span class=\"hljs-keyword\">var</span> distances = mutable.<span class=\"hljs-type\">MutableList</span>[(<span class=\"hljs-type\">Row</span>, <span class=\"hljs-type\">Double</span>)]()\n    trainSet.foreach{trainRow =&gt;\n        <span class=\"hljs-keyword\">val</span> dist = computeEuclideanDistance(trainRow, testRow)\n        <span class=\"hljs-keyword\">val</span> x = (trainRow, dist)\n        distances += x\n    }\n    distances = distances.sortBy(_._2)\n    <span class=\"hljs-keyword\">var</span> neighbours = mutable.<span class=\"hljs-type\">MutableList</span>[<span class=\"hljs-type\">Row</span>]()\n\n    <span class=\"hljs-keyword\">for</span> (i &lt;- <span class=\"hljs-number\">1</span> to k) {\n        neighbours += distances(i)._1\n    }\n    neighbours.toList\n}\n</code></pre>\n<h3 id=\"heading-step-3-make-predictions\">Step 3: Make Predictions</h3>\n<p>The most similar neighbors collected from the training dataset can be used to make predictions. In the case of classification, we can return the most represented output value (Class) among the neighbors.</p>\n<p>We would first map the class values to the number of times it appears among the neighbors, then sort the counts in descending order and get the most appeared class value. The below function does exactly that in Scala:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">predictClassification</span></span>(trainSet: <span class=\"hljs-type\">Array</span>[<span class=\"hljs-type\">Row</span>], testRow: <span class=\"hljs-type\">Row</span>, k: <span class=\"hljs-type\">Int</span>): <span class=\"hljs-type\">String</span> =\n{\n    <span class=\"hljs-keyword\">val</span> neighbours = getNeighbours(trainSet, testRow, k)\n    <span class=\"hljs-keyword\">val</span> outputValues = <span class=\"hljs-keyword\">for</span> (row &lt;- neighbours) <span class=\"hljs-keyword\">yield</span> row.getString(trainSet(<span class=\"hljs-number\">0</span>).length - <span class=\"hljs-number\">1</span>)\n    outputValues.groupBy(identity)\n        .mapValues(_.size)\n        .toSeq\n        .sortWith(_._2 &gt; _._2)\n        .head._1\n}\n</code></pre>\n<h3 id=\"heading-apply-the-above-concepts-to-iris-dataset\">Apply the above concepts to Iris Dataset</h3>\n<p>We will now apply the concepts above to perform KNN on the Iris Dataset.</p>\n<p>First, we have to load the dataset into the program. This is done using the <code>readCsv</code> function I've written below:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">readCsv</span></span>(fileName: <span class=\"hljs-type\">String</span>, header: <span class=\"hljs-type\">Boolean</span>): <span class=\"hljs-type\">DataFrame</span> = {\n    spark.read\n        .format(<span class=\"hljs-string\">\"csv\"</span>)\n        .option(<span class=\"hljs-string\">\"header\"</span>, header)\n        .option(<span class=\"hljs-string\">\"inferSchema\"</span>, header)\n        .load(fileName)\n        .repartition($<span class=\"hljs-string\">\"Class\"</span>)\n}\n</code></pre>\n<p>We also have to normalize the data we have. This is because KNN is based on distance between records. Unless data is normalized distance will be incorrectly calculated, because different attributes will not contribute to the distance in a uniform way.  Attributes having a larger value range will have an unduly large influence on the distance, because they make greater contribution to the distance. If the dataset requires that some columns be given a greater preference over others, then normalization isn't recommended, but this is not true in the case of the Iris dataset.</p>\n<p>We use the Z Score Normalization technique. With this, we subtract the mean of the respective column from each cell, and divide that with the standard deviation of that column. <a target=\"_blank\" href=\"https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0?ref=localhost\">This</a> article describes Data Normalization in good detail.</p>\n<p>The following function does our job:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">normalizeData</span></span>(): <span class=\"hljs-type\">Unit</span> = {\n    df.columns.filterNot(e =&gt; e == <span class=\"hljs-string\">\"Class\"</span>).foreach{col =&gt;\n        <span class=\"hljs-keyword\">val</span> (mean_col, stddev_col) = df.select(mean(col), stddev(col))\n            .as[(<span class=\"hljs-type\">Double</span>, <span class=\"hljs-type\">Double</span>)]\n            .first()\n        df = df.withColumn(<span class=\"hljs-string\">s\"<span class=\"hljs-subst\">$col</span>.norm\"</span>, ($<span class=\"hljs-string\">\"$col\"</span> - mean_col) / stddev_col)\n            .drop(col)\n            .withColumnRenamed(<span class=\"hljs-string\">s\"<span class=\"hljs-subst\">$col</span>.norm\"</span>, col)\n    }\n}\n</code></pre>\n<p>As you can see above, we are filtering out the class value, because we will not be using this value to compute the distance. There's one problem with our approach though, our KNN functions written above assume that the class value will be the last column. In the way we've normalized the data, we are dropping the original column, and adding the normalized column in place. This will push the <code>Class</code> column to the beginning. So, I've written another function which will move the column back to where it should actually be:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">moveClassToEnd</span></span>(): <span class=\"hljs-type\">Unit</span> = {\n    <span class=\"hljs-keyword\">val</span> cols = df.columns.filterNot(_ == <span class=\"hljs-string\">\"Class\"</span>) ++ <span class=\"hljs-type\">Array</span>(<span class=\"hljs-string\">\"Class\"</span>)\n    df = df.select(cols.head, cols.tail: _*)\n}\n</code></pre>\n<p>We will evaluate our algorithm using K-fold cross-validation with 5 folds. This means that we will have 150/5 = 30 rows per fold. We will use helper functions <code>evaluateAlgorithm()</code> and <code>accuracyMetric()</code> to evaluate the algorithm for cross-validation and calculate the accuracy of our predictions respectively.</p>\n<p>Since Spark does not allow any of its operations inside a Spark transformation, we will have to perform a <code>collect()</code> on the Train set and Test set <code>DataFrame</code>s every time before passing it to any function. A sample run with <code>k = 3</code> produces the following output:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113152684/1316a779-2e73-40a0-aef1-ae450ca01420.png\" alt class=\"image--center mx-auto\" /></p>\n<p>Let's go one step further and run our program over different values of <code>k</code>. I'm running it for <code>k</code> from <code>1 to 10</code>, and here are some results (this may not be the same everytime):</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113153630/cb17fce4-6f7f-4070-8fc0-ff27ece000e4.png\" alt class=\"image--center mx-auto\" /></p>\n<p>KNN accuracy for a variety of k values</p>\n<p>You can find the entire code below:</p>\n<h3 id=\"heading-conclusion\">CONCLUSION</h3>\n<p>While Spark ideally shouldn't be used smaller datasets like this, you could apply the same thought process and transform this code to use for some larger datasets, and there you will see the magic of Spark over Pandas.</p>\n<p>Inspired heavily from <a target=\"_blank\" href=\"https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/?ref=localhost\">this</a> great article.</p>\n","contentMarkdown":"*Note: This article is the first of the Series: Cool Spark ML. Other parts are coming soon.*\n\nI had taken up a few machine learning courses in my college throughout 2018. Most of the problems there were solved using Python and the necessary libraries - NumPy, Pandas, Scikit-Learn and Matplotlib. With my daily work at IBM now requiring me to use Scala and Spark, I decided to use my free time during the lockdown to try out Spark ML.\n\n*Note: All the codes in the Cool Spark ML Series will be available on* [*my GitHub repo*](https://github.com/Sparker0i/Cool-Spark-ML?ref=localhost)\n\n### Intro to Spark ML\n\nAs the name suggests, Spark ML is the Machine Learning library consisting of common Machine learning algorithms - classification, regression, clustering etc.\n\n### Why Spark ML?\n\nPandas - a Python library - won’t work every time. It is a single machine tool, so it's constrained by the machine's limits. Moreover, pandas doesn’t have any parallelism built in, which means it uses only one CPU core. You may hit a dead-end on datasets of the size of a few gigabytes. Pandas won't help if you want to work on very big datasets.\n\nWe are now in the Big Data era, where gigabytes of data are generated every few seconds. Such datasets will require powerful systems to run even the basic machine learning algorithms. The cost of getting such a powerful system will be huge, as well as the costs to scale them up. With distributed computers, such calculations can be sent to multiple low-end machines, which prevents the cost of getting a single high-end machine.\n\nThis is where Spark kicks in. Spark has the concept of `DataFrame` (now deprecated in favor of Datasets), which behaves very similar to how a Pandas `DataFrame` would do, including having very similar APIs too. The advantage of using Spark `DataFrame` is that it was designed from ground-up to support Big Data. Spark can also distribute such `DataFrame`s across multiple machines and collect the calculated results.\n\n### KNN: K-Nearest Neighbors\n\nThe process in KNN is pretty simple. You load your entire dataset first, each of which will have input columns and one output column. This is then split into a training set and a testing set. You then use your training set to train your model, and then use the testing set to predict the output column value by testing it against the model. You then compare the actual and the predicted target values and calculate the accuracy of your model.\n\n### Problem Definition\n\nWe are going to train a model to predict the famous [Iris dataset](http://archive.ics.uci.edu/ml/datasets/iris?ref=localhost). The Iris Flower Dataset involves predicting the flower species given measurements of iris flowers.\n\nIt is a multiclass classification problem. The number of observations for each class is the same. The dataset is small in size with only 150 rows with 4 input variables and 1 output variable.\n\nThe 4 features are described as follows:\n\n1. Sepal-Length, in cm\n    \n2. Sepal-Width, in cm\n    \n3. Petal-Length, in cm\n    \n4. Petal-Width, in cm\n    \n\n### Prerequisites\n\n1. Create a Scala project in IntelliJ IDEA based on SBT\n    \n2. Select Scala version 2.11.12\n    \n3. Include `spark-core`, `spark-sql` and `spark-ml` 2.4.5 as library dependencies in your `build.sbt`\n    \n\n### KNN Steps\n\nIn this blog post, I will be developing KNN algorithm from scratch. The process to perform KNN can be broken down into 3 easy steps:\n\n1. Calculate Euclidean Distance\n    \n2. Get Nearest Neighbors\n    \n3. Make Predictions\n    \n\n### Step 1: Calculate Euclidean Distance\n\nThe first step will be to calculate the distance between two rows in a Dataset. Rows of data are mostly made up of numbers and an easy way to calculate the distance between two rows or vectors of numbers is to draw a straight line.\n\nEuclidean Distance is calculated as the square root of the sum of the squared differences between the two vectors, as given in the image below:\n\n[![](https://latex.codecogs.com/gif.latex?%5Cinline&space;%5Cbg_white&space;%7B%5Ccolor%7BRed%7D&space;$$dist_%7Bx_1,x_2%7D&space;=&space;%5Csqrt%7B%5Csum_%7Bi=0%7D%5E%7BN%7D&space;(%7Bx_1_i&space;-&space;x_2_i%7D)%5E2%7D.$$%7D align=\"left\")](https://www.codecogs.com/eqnedit.php?latex=%5Cinline&space%3B%5Cbg_white=&space%3B%7B%5Ccolor%7BRed%7D=&space%3B%24%24dist_%7Bx_1%2Cx_2%7D=&space%3B=&space%3B%5Csqrt%7B%5Csum_%7Bi=0%7D%5E%7BN%7D&space%3B%28%7Bx_1_i=&space%3B-=&space%3Bx_2_i%7D%29%5E2%7D.%24%24%7D=&ref=localhost)\n\nWhere `x1` is the first row of data, `x2` is the second row of data, and `i` is a specific index for a column as we sum across all columns. Smaller the value, more similar will be the two rows.\n\nSince we will be reading our data and transforming it using Spark, to compute distances between two `Row`s in a `DataFrame`, we write the function below in Scala:\n\n```scala\ndef computeEuclideanDistance(row1: Row, row2: Row): Double = {\n    var distance = 0.0\n    for (i <- 0 until row1.length - 1) {\n        distance += math.pow(row1.getDouble(i) - row2.getDouble(i), 2)\n    }\n    math.sqrt(distance)\n}\n```\n\nYou can see that the function assumes that the last column in each row is an output value which is ignored from the distance calculation.\n\n### Step 2: Get Nearest Neighbors\n\nNeighbors for a new piece of data in the dataset are the k closest instances, as defined by our distance measure. To locate the neighbors for a new piece of data within a dataset we must first calculate the distance between each record in the dataset to the new piece of data. We can do this using our distance function prepared above.\n\nWe can do this by keeping track of the distance for each record in the dataset as a tuple, sort the list of tuples by the distance, and then retrieve the neighbors. The below function does this job in Scala:\n\n```scala\ndef getNeighbours(trainSet: Array[Row], testRow: Row, k: Int): List[Row] = {\n    var distances = mutable.MutableList[(Row, Double)]()\n    trainSet.foreach{trainRow =>\n        val dist = computeEuclideanDistance(trainRow, testRow)\n        val x = (trainRow, dist)\n        distances += x\n    }\n    distances = distances.sortBy(_._2)\n    var neighbours = mutable.MutableList[Row]()\n\n    for (i <- 1 to k) {\n        neighbours += distances(i)._1\n    }\n    neighbours.toList\n}\n```\n\n### Step 3: Make Predictions\n\nThe most similar neighbors collected from the training dataset can be used to make predictions. In the case of classification, we can return the most represented output value (Class) among the neighbors.\n\nWe would first map the class values to the number of times it appears among the neighbors, then sort the counts in descending order and get the most appeared class value. The below function does exactly that in Scala:\n\n```scala\ndef predictClassification(trainSet: Array[Row], testRow: Row, k: Int): String =\n{\n    val neighbours = getNeighbours(trainSet, testRow, k)\n    val outputValues = for (row <- neighbours) yield row.getString(trainSet(0).length - 1)\n    outputValues.groupBy(identity)\n        .mapValues(_.size)\n        .toSeq\n        .sortWith(_._2 > _._2)\n        .head._1\n}\n```\n\n### Apply the above concepts to Iris Dataset\n\nWe will now apply the concepts above to perform KNN on the Iris Dataset.\n\nFirst, we have to load the dataset into the program. This is done using the `readCsv` function I've written below:\n\n```scala\ndef readCsv(fileName: String, header: Boolean): DataFrame = {\n    spark.read\n        .format(\"csv\")\n        .option(\"header\", header)\n        .option(\"inferSchema\", header)\n        .load(fileName)\n        .repartition($\"Class\")\n}\n```\n\nWe also have to normalize the data we have. This is because KNN is based on distance between records. Unless data is normalized distance will be incorrectly calculated, because different attributes will not contribute to the distance in a uniform way.  Attributes having a larger value range will have an unduly large influence on the distance, because they make greater contribution to the distance. If the dataset requires that some columns be given a greater preference over others, then normalization isn't recommended, but this is not true in the case of the Iris dataset.\n\nWe use the Z Score Normalization technique. With this, we subtract the mean of the respective column from each cell, and divide that with the standard deviation of that column. [This](https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0?ref=localhost) article describes Data Normalization in good detail.\n\nThe following function does our job:\n\n```scala\ndef normalizeData(): Unit = {\n    df.columns.filterNot(e => e == \"Class\").foreach{col =>\n        val (mean_col, stddev_col) = df.select(mean(col), stddev(col))\n            .as[(Double, Double)]\n            .first()\n        df = df.withColumn(s\"$col.norm\", ($\"$col\" - mean_col) / stddev_col)\n            .drop(col)\n            .withColumnRenamed(s\"$col.norm\", col)\n    }\n}\n```\n\nAs you can see above, we are filtering out the class value, because we will not be using this value to compute the distance. There's one problem with our approach though, our KNN functions written above assume that the class value will be the last column. In the way we've normalized the data, we are dropping the original column, and adding the normalized column in place. This will push the `Class` column to the beginning. So, I've written another function which will move the column back to where it should actually be:\n\n```scala\ndef moveClassToEnd(): Unit = {\n    val cols = df.columns.filterNot(_ == \"Class\") ++ Array(\"Class\")\n    df = df.select(cols.head, cols.tail: _*)\n}\n```\n\nWe will evaluate our algorithm using K-fold cross-validation with 5 folds. This means that we will have 150/5 = 30 rows per fold. We will use helper functions `evaluateAlgorithm()` and `accuracyMetric()` to evaluate the algorithm for cross-validation and calculate the accuracy of our predictions respectively.\n\nSince Spark does not allow any of its operations inside a Spark transformation, we will have to perform a `collect()` on the Train set and Test set `DataFrame`s every time before passing it to any function. A sample run with `k = 3` produces the following output:\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113152684/1316a779-2e73-40a0-aef1-ae450ca01420.png align=\"center\")\n\nLet's go one step further and run our program over different values of `k`. I'm running it for `k` from `1 to 10`, and here are some results (this may not be the same everytime):\n\n![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113153630/cb17fce4-6f7f-4070-8fc0-ff27ece000e4.png align=\"center\")\n\nKNN accuracy for a variety of k values\n\nYou can find the entire code below:\n\n### CONCLUSION\n\nWhile Spark ideally shouldn't be used smaller datasets like this, you could apply the same thought process and transform this code to use for some larger datasets, and there you will see the magic of Spark over Pandas.\n\nInspired heavily from [this](https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/?ref=localhost) great article.","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713116495934/a2fb1725-b3e5-43a6-b0b2-04aa0ce1795f.jpeg","brief":"Note: This article is the first of the Series: Cool Spark ML. Other parts are coming soon.\nI had taken up a few machine learning courses in my college throughout 2018. Most of the problems there were solved using Python and the necessary libraries - ...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/spark-machine-learning-knn/","readTime":8,"tags":["56744721958ef13879b94e3b","56744722958ef13879b950a8","56744723958ef13879b952a7","56744722958ef13879b95180"],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T17:43:28.178Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":true,"stickCoverToBottom":true,"subtitle":"Learn how you can write a KNN algorithm from scratch and modify it for use with larger datasets in Spark","viewsUpdatedOn":1713961848676,"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c0843dbf837e5981954cc"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c08479bb70e9dac2bfee3","createdAt":"2024-04-14T16:45:59.821Z","updatedAt":"2024-04-14T17:44:55.122Z","views":22,"isActive":true,"hasLatex":false,"popularity":3945.1329,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Add new functions to existing classes the Scala way","cuid":"cluzrcdxo000508jw5t4db7pv","dateAdded":"2020-04-10T18:09:42.000Z","hasCustomDate":true,"slug":"scala-add-new-functions-to-existing-class","content":"<h3 id=\"heading-background\">Background</h3>\n<p>A <a target=\"_blank\" href=\"https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/package.scala?ref=localhost#L46\">Spark <code>DataFrame</code></a> has a better advantage over a <a target=\"_blank\" href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html?ref=localhost\">Pandas <code>DataFrame</code></a> when it comes to the ability to scale and process it. I'm writing more on this in another blog post which will arrive shortly after this one.</p>\n<p>Functionally, both Spark and Pandas have an almost same set of functionalities, and their APIs are not so different either. There's one function which is used extensively in the data science community with Pandas - <code>[shape()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html?ref=localhost)</code>. This function returns you the return the row and column count coupled inside a Tuple. Sadly, this functionality isn't available with Spark <code>DataFrame</code> (<a target=\"_blank\" href=\"https://issues.apache.org/jira/browse/SPARK-27756?ref=localhost\">and won't come either</a>).</p>\n<h3 id=\"heading-implicit-classes-in-scala\">Implicit classes in Scala</h3>\n<p>Fortunately, we have Implicit classes in Scala for our rescue. Implicit classes enable us to add some new functionality on top of an existing class' functionalities. To know more about Implicit Classes, you can read <a target=\"_blank\" href=\"http://www.lihaoyi.com/post/ImplicitDesignPatternsinScala.html?ref=localhost\">this</a> article for diving deep.</p>\n<p>First, we need to define a new implicit class with the method we want to add. In this case, I want to add the <code>shape()</code> function on top of the Spark <code>DataFrame</code> class.</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">implicit</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">DataFramePlus</span>(<span class=\"hljs-params\">df: <span class=\"hljs-type\">DataFrame</span></span>) </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">shape</span></span>(): (<span class=\"hljs-type\">Long</span>, <span class=\"hljs-type\">Int</span>) = (df.count(), df.columns.length)\n}\n</code></pre>\n<p>Then all you need to do is print the shape of the <code>DataFrame</code>:</p>\n<pre><code class=\"lang-scala\">df = spark.read.format(<span class=\"hljs-string\">\"&lt;something&gt;\"</span>).load(<span class=\"hljs-string\">\"&lt;Filename&gt;\"</span>)\nprintln(df.shape())\n</code></pre>\n<p>This solved a major pain point for me without having to extend an existing class.</p>\n<h3 id=\"heading-best-practice\">Best Practice</h3>\n<p>While writing these codes inside the Scala REPL (Scala/Spark Shell on Terminal) might seem a little easier to implement, openly exposing your code for everyone to use isn't a great idea.</p>\n<p>Instead, you could implement the implicit class in a package object like this:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">package</span> me.sparker0i\n\n<span class=\"hljs-keyword\">import</span> org.apache.spark.sql.<span class=\"hljs-type\">DataFrame</span>\n\n<span class=\"hljs-keyword\">package</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">object</span> <span class=\"hljs-title\">machinelearning</span> </span>{\n    <span class=\"hljs-keyword\">implicit</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">DataFramePlus</span>(<span class=\"hljs-params\">df: <span class=\"hljs-type\">DataFrame</span></span>) </span>{\n        <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">shape</span></span>(): (<span class=\"hljs-type\">Long</span>, <span class=\"hljs-type\">Int</span>) = (df.count(), df.columns.length)\n    }\n}\n</code></pre>\n<p>Then you'll need to add the proper import statement in your class, after which you can use the shape method with any <code>DataFrame</code>:</p>\n<pre><code class=\"lang-scala\"><span class=\"hljs-keyword\">package</span> me.sparker0i.machinelearning.regression\n\n<span class=\"hljs-keyword\">import</span> org.apache.spark.sql.<span class=\"hljs-type\">DataFrame</span>\n<span class=\"hljs-keyword\">import</span> me.sparker0i.machinelearning._\n\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">LinearRegression</span> </span>{\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">function</span></span>(df: <span class=\"hljs-type\">DataFrame</span>): <span class=\"hljs-type\">Unit</span> = {\n        println(df.shape())\n    }\n}\n</code></pre>\n<h3 id=\"heading-conclusion\">CONCLUSION</h3>\n<p>With this approach of using implicit classes in Scala, we no longer have to extend any existing class just to add additional functionality to it. You define the behavior you want, and then add that behavior to existing class instances after adding the proper <code>import</code> statements.</p>\n<p>Inspired heavily from <a target=\"_blank\" href=\"https://alvinalexander.com/scala/scala-2.10-implicit-class-example/?ref=localhost\">Alvin Alexander's article</a></p>\n","contentMarkdown":"### Background\n\nA [Spark `DataFrame`](https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/package.scala?ref=localhost#L46) has a better advantage over a [Pandas `DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html?ref=localhost) when it comes to the ability to scale and process it. I'm writing more on this in another blog post which will arrive shortly after this one.\n\nFunctionally, both Spark and Pandas have an almost same set of functionalities, and their APIs are not so different either. There's one function which is used extensively in the data science community with Pandas - `[shape()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html?ref=localhost)`. This function returns you the return the row and column count coupled inside a Tuple. Sadly, this functionality isn't available with Spark `DataFrame` ([and won't come either](https://issues.apache.org/jira/browse/SPARK-27756?ref=localhost)).\n\n### Implicit classes in Scala\n\nFortunately, we have Implicit classes in Scala for our rescue. Implicit classes enable us to add some new functionality on top of an existing class' functionalities. To know more about Implicit Classes, you can read [this](http://www.lihaoyi.com/post/ImplicitDesignPatternsinScala.html?ref=localhost) article for diving deep.\n\nFirst, we need to define a new implicit class with the method we want to add. In this case, I want to add the `shape()` function on top of the Spark `DataFrame` class.\n\n```scala\nimplicit class DataFramePlus(df: DataFrame) {\n    def shape(): (Long, Int) = (df.count(), df.columns.length)\n}\n```\n\nThen all you need to do is print the shape of the `DataFrame`:\n\n```scala\ndf = spark.read.format(\"<something>\").load(\"<Filename>\")\nprintln(df.shape())\n```\n\nThis solved a major pain point for me without having to extend an existing class.\n\n### Best Practice\n\nWhile writing these codes inside the Scala REPL (Scala/Spark Shell on Terminal) might seem a little easier to implement, openly exposing your code for everyone to use isn't a great idea.\n\nInstead, you could implement the implicit class in a package object like this:\n\n```scala\npackage me.sparker0i\n\nimport org.apache.spark.sql.DataFrame\n\npackage object machinelearning {\n    implicit class DataFramePlus(df: DataFrame) {\n        def shape(): (Long, Int) = (df.count(), df.columns.length)\n    }\n}\n```\n\nThen you'll need to add the proper import statement in your class, after which you can use the shape method with any `DataFrame`:\n\n```scala\npackage me.sparker0i.machinelearning.regression\n\nimport org.apache.spark.sql.DataFrame\nimport me.sparker0i.machinelearning._\n\nclass LinearRegression {\n    def function(df: DataFrame): Unit = {\n    \tprintln(df.shape())\n    }\n}\n```\n\n### CONCLUSION\n\nWith this approach of using implicit classes in Scala, we no longer have to extend any existing class just to add additional functionality to it. You define the behavior you want, and then add that behavior to existing class instances after adding the proper `import` statements.\n\nInspired heavily from [Alvin Alexander's article](https://alvinalexander.com/scala/scala-2.10-implicit-class-example/?ref=localhost)","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713116626866/b2e98984-8bd8-46f4-a428-5564b169e932.png","brief":"Background\nA Spark DataFrame has a better advantage over a Pandas DataFrame when it comes to the ability to scale and process it. I'm writing more on this in another blog post which will arrive shortly after this one.\nFunctionally, both Spark and Pan...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/scala-add-new-functions-to-existing-class/","readTime":2,"tags":["56744723958ef13879b952a7"],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T17:44:55.121Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":true,"stickCoverToBottom":true,"subtitle":"Why extend classes to add a small functionality, when you could just write an implicit class? Read my post on how you too can take advantage of that i","pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c08479bb70e9dac2bfee3"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"toc":[],"_id":"661c084eec6af0386c750e4a","createdAt":"2024-04-14T16:46:06.393Z","updatedAt":"2024-04-14T17:46:18.021Z","views":18,"isActive":true,"hasLatex":false,"popularity":3217.5544,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"MySQL installation inside Docker on Mac","cuid":"cluzrcj07000308l98e5u81i1","dateAdded":"2019-03-28T19:25:50.000Z","hasCustomDate":true,"slug":"mysql-installation-inside-docker-on-mac","content":"<p>I’ve never liked to make changes to my laptop by providing my admin credentials to install various tools, like MySQL because I love doing things at a user level. Programs like VSCode and Atom are good examples of that when all you do is drag the application icon to the Applications folder. Homebrew is also a good example to install command line applications at a user level.</p>\n<p>If you were to install using the official installer, you’d have to give administrator rights. You will also have to make changes to your bash profile to access mysql in terminal. All these problems can be alleviated by installing a MySQL container inside Docker.</p>\n<h3 id=\"heading-install-docker-community-edition\">INSTALL DOCKER COMMUNITY EDITION</h3>\n<p>Download Docker Desktop for Mac by visiting this <a target=\"_blank\" href=\"https://hub.docker.com/search/?type=edition&amp;offering=community&amp;ref=localhost\">link.</a> Then you need to install Docker on your Mac by following the installation steps. It is recommended not to change any defaults if prompted.</p>\n<p>Once you are done with that, we will now proceed with the installation of MySQL container inside Docker. You can either do it inside a terminal, or use a tool like Kitematic using which you can manage multiple containers in your system once you create them.</p>\n<p>Fire up a terminal, and write this command</p>\n<pre><code class=\"lang-plaintext\">docker run --name=mysql -d -p 3306:3306 -e MYSQL_USER=developer -e MYSQL_PASSWORD=mydbpwd -e MYSQL_DATABASE=mydb mysql/mysql-server\n</code></pre>\n<p>Here we will use the <code>mysql/mysql-server</code> image, and our Username, password and Database are <code>developer</code>, <code>mydbpwd</code> and <code>mydb</code> respectively. Then do the port mapping between the container and the host. We bind Container’s port 3306 to the Mac’s port 3306.</p>\n<p>If everything goes fine, you should see a combination of alphabets and numbers as an output. This is the container ID. Type this command:</p>\n<pre><code class=\"lang-plaintext\">docker exec -it mysql bash -c \"mysql -u developer -p\"\n</code></pre>\n<p>Then enter the password you entered while creating the container (In this case <code>mydbpwd</code>). Then you will have an instance up and running inside Docker.</p>\n<h3 id=\"heading-check-mysql-connectivity-inside-mysql-workbench\">CHECK MYSQL CONNECTIVITY INSIDE MYSQL WORKBENCH</h3>\n<p>First up install MySQL Workbench, either using the official installer or using the brew command <code>brew cask install mysqlworkbench</code>. Once you open up the MySQLWorkbench, click on the add connection button, then enter as following:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113163363/196bbda6-607c-4b35-8675-4358657423b4.png\" alt=\"Creating a new connection inside MySQL Workbench\" /></p>\n<p>Creating a new connection inside MySQL Workbench</p>\n<p>Then click the Test Connection button. If everything goes alright, you will get this popup:</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113164513/0988817e-9314-441e-a248-5fd705bdf609.png\" alt=\"Connection established with MySQL Container in Docker\" /></p>\n<p>Connection established with MySQL Container in Docker</p>\n<h3 id=\"heading-conclusion\">CONCLUSION</h3>\n<p>Installing MySQL in Docker on your PC is a safer approach to installing MySQL than providing Admin credentials to install using the official installer. If anything goes wrong, all you have to do is delete the container and create a new one in Docker.</p>\n<h3 id=\"heading-references\">REFERENCES</h3>\n<p><a target=\"_blank\" href=\"https://medium.com/@crmcmullen/how-to-run-mysql-in-a-docker-container-on-macos-with-persistent-local-data-58b89aec496a?ref=localhost\">Run MySQL in a Docker Container – Medium</a></p>\n","contentMarkdown":"I’ve never liked to make changes to my laptop by providing my admin credentials to install various tools, like MySQL because I love doing things at a user level. Programs like VSCode and Atom are good examples of that when all you do is drag the application icon to the Applications folder. Homebrew is also a good example to install command line applications at a user level.\n\nIf you were to install using the official installer, you’d have to give administrator rights. You will also have to make changes to your bash profile to access mysql in terminal. All these problems can be alleviated by installing a MySQL container inside Docker.\n\n### INSTALL DOCKER COMMUNITY EDITION\n\nDownload Docker Desktop for Mac by visiting this [link.](https://hub.docker.com/search/?type=edition&offering=community&ref=localhost) Then you need to install Docker on your Mac by following the installation steps. It is recommended not to change any defaults if prompted.\n\nOnce you are done with that, we will now proceed with the installation of MySQL container inside Docker. You can either do it inside a terminal, or use a tool like Kitematic using which you can manage multiple containers in your system once you create them.\n\nFire up a terminal, and write this command\n\n```plaintext\ndocker run --name=mysql -d -p 3306:3306 -e MYSQL_USER=developer -e MYSQL_PASSWORD=mydbpwd -e MYSQL_DATABASE=mydb mysql/mysql-server\n```\n\nHere we will use the `mysql/mysql-server` image, and our Username, password and Database are `developer`, `mydbpwd` and `mydb` respectively. Then do the port mapping between the container and the host. We bind Container’s port 3306 to the Mac’s port 3306.\n\nIf everything goes fine, you should see a combination of alphabets and numbers as an output. This is the container ID. Type this command:\n\n```plaintext\ndocker exec -it mysql bash -c \"mysql -u developer -p\"\n```\n\nThen enter the password you entered while creating the container (In this case `mydbpwd`). Then you will have an instance up and running inside Docker.\n\n### CHECK MYSQL CONNECTIVITY INSIDE MYSQL WORKBENCH\n\nFirst up install MySQL Workbench, either using the official installer or using the brew command `brew cask install mysqlworkbench`. Once you open up the MySQLWorkbench, click on the add connection button, then enter as following:\n\n![Creating a new connection inside MySQL Workbench](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113163363/196bbda6-607c-4b35-8675-4358657423b4.png align=\"left\")\n\nCreating a new connection inside MySQL Workbench\n\nThen click the Test Connection button. If everything goes alright, you will get this popup:\n\n![Connection established with MySQL Container in Docker](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113164513/0988817e-9314-441e-a248-5fd705bdf609.png align=\"left\")\n\nConnection established with MySQL Container in Docker\n\n### CONCLUSION\n\nInstalling MySQL in Docker on your PC is a safer approach to installing MySQL than providing Admin credentials to install using the official installer. If anything goes wrong, all you have to do is delete the container and create a new one in Docker.\n\n### REFERENCES\n\n[Run MySQL in a Docker Container – Medium](https://medium.com/@crmcmullen/how-to-run-mysql-in-a-docker-container-on-macos-with-persistent-local-data-58b89aec496a?ref=localhost)","coverImage":"https://cdn.hashnode.com/res/hashnode/image/upload/v1713116722498/30f4f0c4-80c3-401d-a613-cf691969b6dc.png","brief":"I’ve never liked to make changes to my laptop by providing my admin credentials to install various tools, like MySQL because I love doing things at a user level. Programs like VSCode and Atom are good examples of that when all you do is drag the appl...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/mysql-installation-inside-docker-on-mac/","readTime":3,"tags":["56744721958ef13879b94b77","56744721958ef13879b94a22","56744721958ef13879b94dff"],"publication":"5cdd04921a7cb8b20267646b","coAuthors":[],"dateUpdated":"2024-04-14T17:46:18.018Z","disableComments":false,"enableToc":false,"isCoverAttributionHidden":false,"slugOverridden":true,"stickCoverToBottom":true,"subtitle":"If you’re using a Mac and want to use MySQL without making many installation changes, you’ve come to the right place.","viewsUpdatedOn":1713173439814,"pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c084eec6af0386c750e4a"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"slugOverridden":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"coAuthors":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"disableComments":false,"enableToc":false,"toc":[],"_id":"661c085f9bb70e9dac2bfee7","createdAt":"2024-04-14T16:46:23.181Z","updatedAt":"2024-04-14T18:18:52.519Z","views":0,"isActive":false,"hasLatex":false,"popularity":1945.0295,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Announcing Simple Weather v4","cuid":"cluzrcvyl000708jwh8hv8g9g","dateAdded":"2017-06-04T00:52:08.000Z","hasCustomDate":true,"slug":"announcing-simple-weather-v4--deleted","content":"<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/tag/android/\">Android</a></p>\n<h1 id=\"heading-announcing-simple-weather-v4\">Announcing Simple Weather v4</h1>\n<ul>\n<li><a target=\"_blank\" href=\"https://blog.sparker0i.me/author/sparker0i/\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113167916/217f53c0-26b9-444e-9435-d467665ac7ef.jpeg\" alt=\"Aaditya Menon\" /></a></li>\n</ul>\n<h4 id=\"heading-aaditya-menonhttpsblogsparker0imeauthorsparker0i\"><a target=\"_blank\" href=\"https://blog.sparker0i.me/author/sparker0i/\">Aaditya Menon</a></h4>\n<p>Jun 4, 2017 • 4 min read</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113168833/8e7a5ad4-7efe-4747-9889-5b745adc763c.png\" alt=\"Announcing Simple Weather v4\" /></p>\n<p>On the eve of my birthday, here’s a surprise – a big update. Welcome to Simple Weather v4. This is a really big release. I’ve heard from the Open Source Community (FDroid , Emails , GitHub issues) and the Play Store Reviews. They all wanted me to add a few new features to the already wonderful app. So without wasting time, I’ll tour you through the new features.</p>\n<h3 id=\"heading-new-features\">NEW FEATURES</h3>\n<ul>\n<li>New weather Screen with minor tweaks</li>\n<li>Weather Widget and Hourly Notifications</li>\n<li>New Weather Graphs and Weather Maps</li>\n<li>View Weather Data in Fahrenheit too</li>\n<li>Use your own custom Open Weather Map key</li>\n<li>Refreshed About Screen</li>\n<li>New Icon</li>\n</ul>\n<h3 id=\"heading-download-the-app\">DOWNLOAD THE APP</h3>\n<p>With this release, you now have two sources to download the app from – the Google Play Store and the F Droid Store. While this update is currently live on the Play Store, it will take some time to arrive on FDroid Store (PS. Do not download v3 from the FDroid store, it was meant for Beta testing) (because FDroid isn’t that great when it comes to scanning through releases, v4 will soon be available there in a few days).</p>\n<p><a target=\"_blank\" href=\"https://f-droid.org/repository/browse/?fdid=com.a5corp.weather&amp;ref=localhost\">F-Droid</a><br /><a target=\"_blank\" href=\"https://play.google.com/store/apps/details?id=com.a5corp.weather&amp;ref=localhost\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113169671/946a7cb9-bcb2-4dc0-b81e-3ba88cd26af6.png\" alt /></a></p>\n<h3 id=\"heading-new-icon\">NEW ICON</h3>\n<p>Ah, sadly yes, this is one of the changes too. I know I had just changed the icon in v2, but I think this was really necessary to convey what my app is trying to deliver. Sadly a Sun over a black background would mean complete darkness. So this was necessary. It is also aligned to the main color of my app. Enjoy the new icon.</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/1-1.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113170576/992478a0-8836-42cf-9d3a-f0494b683489.png\" alt /></a></p>\n<h3 id=\"heading-slightly-tweaked-weather-screen-new-weather-options\">SLIGHTLY TWEAKED WEATHER SCREEN, NEW WEATHER OPTIONS</h3>\n<p>Once you upgrade to this new version, you will now see a slightly tweaked main screen. All the information you need, is now in one place. Right here,</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/2-1.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113171982/b7edc217-7881-4bce-af82-34fa68d3a216.png\" alt /></a></p>\n<p>As you can also see from the picture above, the Search Red Floating Button has now been moved to the toolbar. This was necessary because in lot of the Reviews I had seen that the FAB (floating Button) usually would hide the details of the last weather item. I could not find a replacement in time, thus I had to move the search button to the main toolbar. And also you can see a Drawer toggle in the toolbar, Right? Yay, open that up and you see this:</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/3-1.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113173248/47039963-f605-43a8-a5eb-a810bd3f5eea.png\" alt /></a></p>\n<p>This upgrade adds a big request you have all been asking for, Fahrenheit temperatures. Hit the toggle, and the weather screen (if visible) will show you the new Fahrenheit values. I know this could have been better (rather than always refreshing when hitting that toggle), but I will work on it when I get time .</p>\n<p>You can also see 2 new options under the Home tab – Weather Graphs and Weather Maps. These are 2 new ways to display the weather information:</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/4-1.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113174484/083f3b91-ceab-4b02-a673-6b1ebfbc5061.png\" alt /></a></p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/5-1.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113175754/18a92bf8-09b1-4253-b836-788839cef1c9.png\" alt /></a></p>\n<p>What’s more exciting is that you can launch this from your home screen right away. So you need not visit the app ,open the drawer and select the option. Rather, if you are running Android 7.1.1+, you could do this from your launcher as well.</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/6.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113177289/6df3b107-a0e0-488d-8473-5bad34943961.png\" alt /></a></p>\n<p>On the Weather Graphs screen, if you hit that empty circle on top, it will show the values on the graph. Moreover, you can change between the three states (Rain, Wind, Temperature) in the Weather Maps screen too.</p>\n<h3 id=\"heading-weather-notifications\">WEATHER NOTIFICATIONS</h3>\n<p>You can also opt to see weather notifications on an hourly basis as well. Just hit the “Show Hourly Notifications” toggle, and you will get essential weather updates every hour, like this:</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/7.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113178662/8047852c-5e31-4340-8070-adb8012c2c40.png\" alt /></a></p>\n<h3 id=\"heading-weather-widgets\">WEATHER WIDGETS</h3>\n<p>Here is another big feature request being released today – Weather Widgets. These might be slightly buggy on your phone restart (I will work on this in the near future too), otherwise these should just run fine. There are 2 sizes of this widget – Large and Small, whose size you can increase if your launcher supports that option.</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/8.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113179862/f90ba01f-e2e9-41ff-8cec-10307fd632c6.png\" alt /></a></p>\n<h3 id=\"heading-custom-openweathermap-key\">CUSTOM OPENWEATHERMAP KEY</h3>\n<p>As you can see in the Drawer pic, you can now choose to load the Weather Data with your own Custom OWM Key (I would encourage, not recommend all to perform this daring step). Doing so can help slow down the amount of server crashes happening due to my Key.</p>\n<h3 id=\"heading-a-new-about-screen\">A NEW ABOUT SCREEN</h3>\n<p>Also, here is a slightly tweaked About Screen</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/9.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113181173/1aab7c7f-b733-42b3-992d-96bf4486a1c0.png\" alt /></a></p>\n<h4 id=\"heading-why-is-the-app-v4-and-not-v3\">WHY IS THE APP v4 AND NOT v3</h4>\n<p>Potentially, this question would have arose on seeing the title itself, “Where did v3 go?”. It never went anywhere, I had decided to do Beta testing with v3. Another reason why I didn’t name the Play Store release as v3 was because the number 3 is unlucky for me. In my early school days, I was always ranked #3 , which never excited me. I started to feel #3 was plain and boring right from then (and unlucky too).</p>\n","contentMarkdown":"[Android](https://blog.sparker0i.me/tag/android/)\n\nAnnouncing Simple Weather v4\n============================\n\n*   [![Aaditya Menon](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113167916/217f53c0-26b9-444e-9435-d467665ac7ef.jpeg)](https://blog.sparker0i.me/author/sparker0i/)\n\n#### [Aaditya Menon](https://blog.sparker0i.me/author/sparker0i/)\n\nJun 4, 2017 • 4 min read\n\n![Announcing Simple Weather v4](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113168833/8e7a5ad4-7efe-4747-9889-5b745adc763c.png)\n\nOn the eve of my birthday, here’s a surprise – a big update. Welcome to Simple Weather v4. This is a really big release. I’ve heard from the Open Source Community (FDroid , Emails , GitHub issues) and the Play Store Reviews. They all wanted me to add a few new features to the already wonderful app. So without wasting time, I’ll tour you through the new features.\n\n### NEW FEATURES\n\n*   New weather Screen with minor tweaks\n*   Weather Widget and Hourly Notifications\n*   New Weather Graphs and Weather Maps\n*   View Weather Data in Fahrenheit too\n*   Use your own custom Open Weather Map key\n*   Refreshed About Screen\n*   New Icon\n\n### DOWNLOAD THE APP\n\nWith this release, you now have two sources to download the app from – the Google Play Store and the F Droid Store. While this update is currently live on the Play Store, it will take some time to arrive on FDroid Store (PS. Do not download v3 from the FDroid store, it was meant for Beta testing) (because FDroid isn’t that great when it comes to scanning through releases, v4 will soon be available there in a few days).\n\n[F-Droid](https://f-droid.org/repository/browse/?fdid=com.a5corp.weather&ref=localhost)  \n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113169671/946a7cb9-bcb2-4dc0-b81e-3ba88cd26af6.png)](https://play.google.com/store/apps/details?id=com.a5corp.weather&ref=localhost)\n\n### NEW ICON\n\nAh, sadly yes, this is one of the changes too. I know I had just changed the icon in v2, but I think this was really necessary to convey what my app is trying to deliver. Sadly a Sun over a black background would mean complete darkness. So this was necessary. It is also aligned to the main color of my app. Enjoy the new icon.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113170576/992478a0-8836-42cf-9d3a-f0494b683489.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/1-1.png)\n\n### SLIGHTLY TWEAKED WEATHER SCREEN, NEW WEATHER OPTIONS\n\nOnce you upgrade to this new version, you will now see a slightly tweaked main screen. All the information you need, is now in one place. Right here,\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113171982/b7edc217-7881-4bce-af82-34fa68d3a216.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/2-1.png)\n\nAs you can also see from the picture above, the Search Red Floating Button has now been moved to the toolbar. This was necessary because in lot of the Reviews I had seen that the FAB (floating Button) usually would hide the details of the last weather item. I could not find a replacement in time, thus I had to move the search button to the main toolbar. And also you can see a Drawer toggle in the toolbar, Right? Yay, open that up and you see this:\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113173248/47039963-f605-43a8-a5eb-a810bd3f5eea.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/3-1.png)\n\nThis upgrade adds a big request you have all been asking for, Fahrenheit temperatures. Hit the toggle, and the weather screen (if visible) will show you the new Fahrenheit values. I know this could have been better (rather than always refreshing when hitting that toggle), but I will work on it when I get time .\n\nYou can also see 2 new options under the Home tab – Weather Graphs and Weather Maps. These are 2 new ways to display the weather information:\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113174484/083f3b91-ceab-4b02-a673-6b1ebfbc5061.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/4-1.png)\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113175754/18a92bf8-09b1-4253-b836-788839cef1c9.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/5-1.png)\n\nWhat’s more exciting is that you can launch this from your home screen right away. So you need not visit the app ,open the drawer and select the option. Rather, if you are running Android 7.1.1+, you could do this from your launcher as well.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113177289/6df3b107-a0e0-488d-8473-5bad34943961.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/6.png)\n\nOn the Weather Graphs screen, if you hit that empty circle on top, it will show the values on the graph. Moreover, you can change between the three states (Rain, Wind, Temperature) in the Weather Maps screen too.\n\n### WEATHER NOTIFICATIONS\n\nYou can also opt to see weather notifications on an hourly basis as well. Just hit the “Show Hourly Notifications” toggle, and you will get essential weather updates every hour, like this:\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113178662/8047852c-5e31-4340-8070-adb8012c2c40.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/7.png)\n\n### WEATHER WIDGETS\n\nHere is another big feature request being released today – Weather Widgets. These might be slightly buggy on your phone restart (I will work on this in the near future too), otherwise these should just run fine. There are 2 sizes of this widget – Large and Small, whose size you can increase if your launcher supports that option.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113179862/f90ba01f-e2e9-41ff-8cec-10307fd632c6.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/8.png)\n\n### CUSTOM OPENWEATHERMAP KEY\n\nAs you can see in the Drawer pic, you can now choose to load the Weather Data with your own Custom OWM Key (I would encourage, not recommend all to perform this daring step). Doing so can help slow down the amount of server crashes happening due to my Key.\n\n### A NEW ABOUT SCREEN\n\nAlso, here is a slightly tweaked About Screen\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113181173/1aab7c7f-b733-42b3-992d-96bf4486a1c0.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/9.png)\n\n#### WHY IS THE APP v4 AND NOT v3\n\nPotentially, this question would have arose on seeing the title itself, “Where did v3 go?”. It never went anywhere, I had decided to do Beta testing with v3. Another reason why I didn’t name the Play Store release as v3 was because the number 3 is unlucky for me. In my early school days, I was always ranked #3 , which never excited me. I started to feel #3 was plain and boring right from then (and unlucky too).","coverImage":"https://blog.sparker0i.me/content/images/wordpress/2017/11/weather2-1.png","brief":"Android\nAnnouncing Simple Weather v4\n\n\n\nAaditya Menon\nJun 4, 2017 • 4 min read\n\nOn the eve of my birthday, here’s a surprise – a big update. Welcome to Simple Weather v4. This is a really big release. I’ve heard from the Open Source Community (FDroid...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/announcing-simple-weather-v4/","readTime":4,"tags":["56744723958ef13879b953d0","56744721958ef13879b94c9f","56744721958ef13879b94c7e","5d67b2166b355fa37c325142"],"publication":"5cdd04921a7cb8b20267646b","dateDeleted":"2024-04-14T18:18:52.516Z","pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c085f9bb70e9dac2bfee7"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"slugOverridden":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"coAuthors":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"disableComments":false,"enableToc":false,"toc":[],"_id":"661c086c8442574e70467578","createdAt":"2024-04-14T16:46:36.294Z","updatedAt":"2024-04-14T18:18:49.310Z","views":0,"isActive":false,"hasLatex":false,"popularity":1721.8392,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Remove Ubuntu Bootloader code from Windows 10","cuid":"cluzrd62u000l08l4cot88wox","dateAdded":"2017-02-07T18:59:25.000Z","hasCustomDate":true,"slug":"remove-ubuntu-bootloader-code-from-windows-10--deleted","content":"<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/tag/linux/\">Linux</a></p>\n<h1 id=\"heading-remove-ubuntu-bootloader-code-from-windows-10\">Remove Ubuntu Bootloader code from Windows 10</h1>\n<p>Ever uninstalled Ubuntu from your machine but the GRUB still remains? Know how to remove Ubuntu completely from your machine.</p>\n<ul>\n<li><a target=\"_blank\" href=\"https://blog.sparker0i.me/author/sparker0i/\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113184802/3e6060cc-0ce6-457a-8728-648612330a1b.jpeg\" alt=\"Aaditya Menon\" /></a></li>\n</ul>\n<h4 id=\"heading-aaditya-menonhttpsblogsparker0imeauthorsparker0i\"><a target=\"_blank\" href=\"https://blog.sparker0i.me/author/sparker0i/\">Aaditya Menon</a></h4>\n<p>Feb 8, 2017 • 3 min read</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113185677/2eb5fa3d-0e28-4dcb-9c57-17c9f74ad9e1.png\" alt=\"Remove Ubuntu Bootloader code from Windows 10\" /></p>\n<p>Hello folks, I am back with yet another post in the Solving Technical Series. In certain situations, when a program you want to run does not work properly on an OS, you first blame the program. Then you try to run it on another OS, and find it working without issues. Then you go back and blame the OS. This is what happens to me when I try to run the Android Studio Emulator on Linux. Its screen size remains small despite resizing. Resizing works fine for Windows 10.</p>\n<p>As I am a part of the FOSS Club of my college, I know that I must be embracing Open Source Software, but in certain situations like these, my head just gets fried up.</p>\n<p>So one fine day, I decided to remove Linux from my PC. I removed those Linux partitions, but unfortunately the Ubuntu Bootloader (aka GRUB) was still present on the Boot screen. Then I had to find a way to remove it from Windows. And voila, there is a way out.</p>\n<h3 id=\"heading-steps-to-be-followed\">STEPS TO BE FOLLOWED</h3>\n<ul>\n<li>Open Command Prompt as an Administrator.</li>\n<li>Now enter <code>diskpart</code> on the CMD screen</li>\n</ul>\n<p><a target=\"_blank\" href=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113189319/414b9265-3166-42c6-a702-2ca35126dc2c.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113186630/8ee5925f-4130-4d90-80ce-1c18d260c829.png\" alt /></a></p>\n<ul>\n<li>Now enter <code>list disk</code>. You will see your Hard Disk and the external storage drives connected to your PC. Select the PC Hard Disk Number. It should be 0 by default on all the systems. But still, check your hardware and then do.</li>\n</ul>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/list-disk.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113187615/786cc1fb-4380-4aea-a276-c9796dfc7ae4.png\" alt /></a></p>\n<ul>\n<li>Select Disk 0 (or whatever number it is of your HDD) by typing <code>sel disk 0</code>. Now to check a list of partitions in it, type <code>list vol</code></li>\n</ul>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/list-vol.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113188457/4e4d47bc-f4ae-4747-aa73-50e80f6e6ab9.png\" alt /></a></p>\n<ul>\n<li>On 64 bit systems, it should be a 100 MB FAT32 system that has ‘System’ as the Info in it. Note the volume number. In my case, it is 9</li>\n</ul>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/diskpart.png\"><img src=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/diskpart.png\" alt /></a></p>\n<ul>\n<li>Type <code>sel vol 9</code>.</li>\n</ul>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/sel-vol.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113190423/58f24e1f-ed95-4b6b-9485-608bfe7c5873.png\" alt /></a></p>\n<ul>\n<li>Now this volume has been selected. We now have to assign the disk letter (for which Windows/MS-DOS became famous for). I assigned a letter Z, by typing <code>assign letter=Z:</code>. Then <code>exit</code> diskpart.</li>\n<li>Now you are back to your regular CMD Prompt. Now type <code>cd /d Z:</code>. Note the <code>/d</code> arguement.</li>\n</ul>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/cd-Z.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113191382/8adec456-ec39-4b04-8000-74c82113295d.png\" alt /></a></p>\n<ul>\n<li>Now for this step, there are two ways to approach this. Some systems will have the <code>ls</code> command, while some won’t. While I would recommend using the <code>ls</code> command, for those who don’t have it can use the <code>dir</code> command as well. Type <code>ls</code> or <code>dir</code>, depending on the program you have</li>\n</ul>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/dir.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113192340/ebe7c309-4bd7-4e00-a84b-d342c832ab7e.png\" alt /></a></p>\n<ul>\n<li><code>cd</code> into the EFI folder. Then type <code>ls</code> again. You will now see a <code>Ubuntu</code> option.</li>\n</ul>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/dir2.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113193492/8b838318-836d-41c9-8126-2cd26c6033fc.png\" alt /></a></p>\n<ul>\n<li>To remove this Ubuntu GRUB, type <code>rmdir /s Ubuntu</code>. It will ask for a confirmation Prompt, type <code>Y</code> and press Enter.</li>\n</ul>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/rmdir.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113194400/61fe3ee7-fba2-4504-a06f-24e9a3b23c70.png\" alt /></a></p>\n<ul>\n<li>Voila! Your PC won’t have the Ubuntu Bootloader anymore.</li>\n</ul>\n<h3 id=\"heading-conclusion\">CONCLUSION</h3>\n<p>Sometimes, at any given point of time, any given OS can be frustrating. Choose your OS depending on the features you need.</p>\n<h3 id=\"heading-update\">UPDATE</h3>\n<p>Android Studio 2.3 Update on Linux fixes the issue I had. So I am back on Linux. Hell Yeah!</p>\n","contentMarkdown":"[Linux](https://blog.sparker0i.me/tag/linux/)\n\nRemove Ubuntu Bootloader code from Windows 10\n=============================================\n\nEver uninstalled Ubuntu from your machine but the GRUB still remains? Know how to remove Ubuntu completely from your machine.\n\n*   [![Aaditya Menon](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113184802/3e6060cc-0ce6-457a-8728-648612330a1b.jpeg)](https://blog.sparker0i.me/author/sparker0i/)\n\n#### [Aaditya Menon](https://blog.sparker0i.me/author/sparker0i/)\n\nFeb 8, 2017 • 3 min read\n\n![Remove Ubuntu Bootloader code from Windows 10](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113185677/2eb5fa3d-0e28-4dcb-9c57-17c9f74ad9e1.png)\n\nHello folks, I am back with yet another post in the Solving Technical Series. In certain situations, when a program you want to run does not work properly on an OS, you first blame the program. Then you try to run it on another OS, and find it working without issues. Then you go back and blame the OS. This is what happens to me when I try to run the Android Studio Emulator on Linux. Its screen size remains small despite resizing. Resizing works fine for Windows 10.\n\nAs I am a part of the FOSS Club of my college, I know that I must be embracing Open Source Software, but in certain situations like these, my head just gets fried up.\n\nSo one fine day, I decided to remove Linux from my PC. I removed those Linux partitions, but unfortunately the Ubuntu Bootloader (aka GRUB) was still present on the Boot screen. Then I had to find a way to remove it from Windows. And voila, there is a way out.\n\n### STEPS TO BE FOLLOWED\n\n*   Open Command Prompt as an Administrator.\n*   Now enter `diskpart` on the CMD screen\n    \n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113186630/8ee5925f-4130-4d90-80ce-1c18d260c829.png)](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113189319/414b9265-3166-42c6-a702-2ca35126dc2c.png)\n\n*   Now enter `list disk`. You will see your Hard Disk and the external storage drives connected to your PC. Select the PC Hard Disk Number. It should be 0 by default on all the systems. But still, check your hardware and then do.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113187615/786cc1fb-4380-4aea-a276-c9796dfc7ae4.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/list-disk.png)\n\n*   Select Disk 0 (or whatever number it is of your HDD) by typing `sel disk 0`. Now to check a list of partitions in it, type `list vol`\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113188457/4e4d47bc-f4ae-4747-aa73-50e80f6e6ab9.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/list-vol.png)\n\n*   On 64 bit systems, it should be a 100 MB FAT32 system that has ‘System’ as the Info in it. Note the volume number. In my case, it is 9\n\n[![](https://blog.sparker0i.me/content/images/wordpress/2017/11/diskpart.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/diskpart.png)\n\n*   Type `sel vol 9`.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113190423/58f24e1f-ed95-4b6b-9485-608bfe7c5873.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/sel-vol.png)\n\n*   Now this volume has been selected. We now have to assign the disk letter (for which Windows/MS-DOS became famous for). I assigned a letter Z, by typing `assign letter=Z:`. Then `exit` diskpart.\n*   Now you are back to your regular CMD Prompt. Now type `cd /d Z:`. Note the `/d` arguement.\n    \n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113191382/8adec456-ec39-4b04-8000-74c82113295d.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/cd-Z.png)\n\n*   Now for this step, there are two ways to approach this. Some systems will have the `ls` command, while some won’t. While I would recommend using the `ls` command, for those who don’t have it can use the `dir` command as well. Type `ls` or `dir`, depending on the program you have\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113192340/ebe7c309-4bd7-4e00-a84b-d342c832ab7e.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/dir.png)\n\n*   `cd` into the EFI folder. Then type `ls` again. You will now see a `Ubuntu` option.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113193492/8b838318-836d-41c9-8126-2cd26c6033fc.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/dir2.png)\n\n*   To remove this Ubuntu GRUB, type `rmdir /s Ubuntu`. It will ask for a confirmation Prompt, type `Y` and press Enter.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113194400/61fe3ee7-fba2-4504-a06f-24e9a3b23c70.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/rmdir.png)\n\n*   Voila! Your PC won’t have the Ubuntu Bootloader anymore.\n\n### CONCLUSION\n\nSometimes, at any given point of time, any given OS can be frustrating. Choose your OS depending on the features you need.\n\n### UPDATE\n\nAndroid Studio 2.3 Update on Linux fixes the issue I had. So I am back on Linux. Hell Yeah!","coverImage":"https://blog.sparker0i.me/content/images/wordpress/2017/11/ubuntu.png","brief":"Linux\nRemove Ubuntu Bootloader code from Windows 10\nEver uninstalled Ubuntu from your machine but the GRUB still remains? Know how to remove Ubuntu completely from your machine.\n\n\n\nAaditya Menon\nFeb 8, 2017 • 3 min read\n\nHello folks, I am back with y...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/remove-linux-bootloader-code-from-windows/","readTime":3,"tags":["56744721958ef13879b94b55","56744721958ef13879b94c7e","56744721958ef13879b94d67","56744721958ef13879b94988"],"publication":"5cdd04921a7cb8b20267646b","dateDeleted":"2024-04-14T18:18:49.307Z","pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c086c8442574e70467578"},{"reward":{"type":"xlm"},"sourcedFromGithub":false,"githubAsSourceMeta":null,"isAnonymous":false,"slugOverridden":false,"autoGeneratedCover":"","hasPolls":false,"totalPollVotes":0,"upvotes":0,"downvotes":0,"untaggedFrom":[],"coAuthors":[],"upvotedBy":[],"downvotedBy":[],"responses":[],"followers":[],"answeredByTarget":false,"inviters":[],"duplicatePosts":[],"hasReward":false,"bookmarkedIn":[],"similarPostIds":[],"reactionsByCurrentUser":[],"disableComments":false,"enableToc":false,"toc":[],"_id":"661c087df236c1310e7d3137","createdAt":"2024-04-14T16:46:53.546Z","updatedAt":"2024-04-14T18:18:44.910Z","views":0,"isActive":false,"hasLatex":false,"popularity":1611.694,"discussionScore":0,"type":"story","partOfPublication":true,"responseCount":0,"replyCount":0,"isFeatured":false,"isEngaging":false,"isDelisted":false,"isNotified":false,"numCollapsed":0,"reactions":[],"totalReactions":0,"totalReactionsByCurrentUser":0,"isPinnedToBlog":false,"commentsPaused":false,"syncAlgolia":false,"numUniqueUsersWhoReacted":0,"tweetOptions":{"enabled":false},"title":"Announcing Simple Weather v2.0","cuid":"cluzrdjdz000208jq7o0t7nrp","dateAdded":"2016-12-12T10:10:31.000Z","hasCustomDate":true,"slug":"announcing-simple-weather-v20--deleted","content":"<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/tag/android/\">Android</a></p>\n<h1 id=\"heading-announcing-simple-weather-v20\">Announcing Simple Weather v2.0</h1>\n<ul>\n<li><a target=\"_blank\" href=\"https://blog.sparker0i.me/author/sparker0i/\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113197920/a5b32ff8-26db-43f7-a1d4-baa8b02f30ea.jpeg\" alt=\"Aaditya Menon\" /></a></li>\n</ul>\n<h4 id=\"heading-aaditya-menonhttpsblogsparker0imeauthorsparker0i\"><a target=\"_blank\" href=\"https://blog.sparker0i.me/author/sparker0i/\">Aaditya Menon</a></h4>\n<p>Dec 12, 2016 • 3 min read</p>\n<p><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113198908/2d6c3b2c-f0dc-421d-ba3c-2731ab1ee43d.png\" alt=\"Announcing Simple Weather v2.0\" /></p>\n<p>Hello there. Wishing all a Merry Christmas and a Happy new year. Today I’m writing this blog post to announce the second release of my Simple Weather app. The app was started out as an assignment to the CS With Android Workshop that was held in our college last summer. The app had an intuitive and beautiful UI.</p>\n<p>This second release carries on the same UI from the previous release, with improvements to the app overall. Before I start, here is a stat on the number of downloads till date (until the moment I pushed the app update).</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/stat.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113199787/e5315cec-19ee-4162-832e-73bbb61a2dbb.png\" alt /></a></p>\n<p>Okay, starting off, you will see a new icon in the launcher. I have decided to take a Circular Icon approach for my icon for all versions of Android (unlike Android 7.1 where this is offered as a roundIcon option) :</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/icon.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113200885/45ed7e67-9654-48a0-a683-baa415592b61.png\" alt /></a></p>\n<p>When you start the app, the first thing you will notice is change of app colors (Blue-Red, unlike Purple-Pink from the previous release) and a floating action bar icon for opening up the search box.</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/home.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113202746/966a57e4-937a-4e36-a0c0-52c6ec38cc8f.png\" alt /></a></p>\n<p>In the previous update of the app, whenever you clicked on the City Name or the Weather Icon, the app used to display a Dialog Box showing information in an unsorted way – differently on different devices. This thing has changed in v2.0 . Now when you click on either of them, you will be shown a Snackbar, which tends to be a more modern, “Material”istic approach to show information.</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/snack.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113204129/3f0348a5-c3e2-4078-9c22-2dbb3e489eeb.png\" alt /></a></p>\n<p>In a similar fashion, when you clicked to display a Day’s information, you would be presented with a dialog box, which had rendering problems, just like the one I had mentioned above. This thing is also changing with v2.0 . Now when you click to display a day’s information, you will be taken to a new screen which shows information as icons and texts. Click on any one of them to reveal what that icon/text is for. This will also be shown as a Snackbar.</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/detail.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113205499/28147f1b-2e72-4e45-9ac2-ce65abdd2f3f.png\" alt /></a></p>\n<p>Another thing you’ll notice in the main app is that icon near the 3 dot menu. That is the location icon. Click on it to detect your current location, and the app will display data accordingly.</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/location.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113206944/e3ebfc6d-f464-4a62-ab70-33dfdf8bf130.png\" alt /></a></p>\n<p>If you are using Android 6.0 and above, you’ll be presented with a dialog box to enable location permission. If you click on that location icon on the action bar, you will need to accept the permission for the action to continue.</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/permission.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113208261/dde46be6-4002-43d3-9599-ffbe19d901da.png\" alt /></a></p>\n<p>There’s one more new thing in the app. You now have the ability to search for a city based on its ZIP Code, or what we call in India as the PIN Code. That is what we call an improvement to an existing thing.</p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/search.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113209360/cec6b459-d64c-4ed0-8c69-0b7c9c08df9f.png\" alt /></a></p>\n<p>The app is now rolling all over the globe. Make sure that you download the app today.</p>\n<p><a target=\"_blank\" href=\"https://play.google.com/store/apps/details?id=com.a5corp.weather&amp;utm_source=global_co&amp;utm_medium=prtnr&amp;utm_content=Mar2515&amp;utm_campaign=PartBadge&amp;pcampaignid=MKT-Other-global-all-co-prtnr-py-PartBadge-Mar2515-1\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113210627/3243d177-6a29-4791-b274-dd0a14be99b4.png\" alt=\"Get it on Google Play\" /></a></p>\n<p><a target=\"_blank\" href=\"https://blog.sparker0i.me/content/images/wordpress/2017/11/about.png\"><img src=\"https://cdn.hashnode.com/res/hashnode/image/upload/v1713113211640/b336b56d-2a3f-4f23-8417-36ae1a013fcf.png\" alt /></a></p>\n<p>Until another blog post, Ciao.</p>\n","contentMarkdown":"[Android](https://blog.sparker0i.me/tag/android/)\n\nAnnouncing Simple Weather v2.0\n==============================\n\n*   [![Aaditya Menon](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113197920/a5b32ff8-26db-43f7-a1d4-baa8b02f30ea.jpeg)](https://blog.sparker0i.me/author/sparker0i/)\n\n#### [Aaditya Menon](https://blog.sparker0i.me/author/sparker0i/)\n\nDec 12, 2016 • 3 min read\n\n![Announcing Simple Weather v2.0](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113198908/2d6c3b2c-f0dc-421d-ba3c-2731ab1ee43d.png)\n\nHello there. Wishing all a Merry Christmas and a Happy new year. Today I’m writing this blog post to announce the second release of my Simple Weather app. The app was started out as an assignment to the CS With Android Workshop that was held in our college last summer. The app had an intuitive and beautiful UI.\n\nThis second release carries on the same UI from the previous release, with improvements to the app overall. Before I start, here is a stat on the number of downloads till date (until the moment I pushed the app update).\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113199787/e5315cec-19ee-4162-832e-73bbb61a2dbb.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/stat.png)\n\nOkay, starting off, you will see a new icon in the launcher. I have decided to take a Circular Icon approach for my icon for all versions of Android (unlike Android 7.1 where this is offered as a roundIcon option) :\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113200885/45ed7e67-9654-48a0-a683-baa415592b61.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/icon.png)\n\nWhen you start the app, the first thing you will notice is change of app colors (Blue-Red, unlike Purple-Pink from the previous release) and a floating action bar icon for opening up the search box.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113202746/966a57e4-937a-4e36-a0c0-52c6ec38cc8f.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/home.png)\n\nIn the previous update of the app, whenever you clicked on the City Name or the Weather Icon, the app used to display a Dialog Box showing information in an unsorted way – differently on different devices. This thing has changed in v2.0 . Now when you click on either of them, you will be shown a Snackbar, which tends to be a more modern, “Material”istic approach to show information.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113204129/3f0348a5-c3e2-4078-9c22-2dbb3e489eeb.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/snack.png)\n\nIn a similar fashion, when you clicked to display a Day’s information, you would be presented with a dialog box, which had rendering problems, just like the one I had mentioned above. This thing is also changing with v2.0 . Now when you click to display a day’s information, you will be taken to a new screen which shows information as icons and texts. Click on any one of them to reveal what that icon/text is for. This will also be shown as a Snackbar.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113205499/28147f1b-2e72-4e45-9ac2-ce65abdd2f3f.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/detail.png)\n\nAnother thing you’ll notice in the main app is that icon near the 3 dot menu. That is the location icon. Click on it to detect your current location, and the app will display data accordingly.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113206944/e3ebfc6d-f464-4a62-ab70-33dfdf8bf130.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/location.png)\n\nIf you are using Android 6.0 and above, you’ll be presented with a dialog box to enable location permission. If you click on that location icon on the action bar, you will need to accept the permission for the action to continue.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113208261/dde46be6-4002-43d3-9599-ffbe19d901da.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/permission.png)\n\nThere’s one more new thing in the app. You now have the ability to search for a city based on its ZIP Code, or what we call in India as the PIN Code. That is what we call an improvement to an existing thing.\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113209360/cec6b459-d64c-4ed0-8c69-0b7c9c08df9f.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/search.png)\n\nThe app is now rolling all over the globe. Make sure that you download the app today.\n\n[![Get it on Google Play](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113210627/3243d177-6a29-4791-b274-dd0a14be99b4.png)](https://play.google.com/store/apps/details?id=com.a5corp.weather&utm_source=global_co&utm_medium=prtnr&utm_content=Mar2515&utm_campaign=PartBadge&pcampaignid=MKT-Other-global-all-co-prtnr-py-PartBadge-Mar2515-1)\n\n[![](https://cdn.hashnode.com/res/hashnode/image/upload/v1713113211640/b336b56d-2a3f-4f23-8417-36ae1a013fcf.png)](https://blog.sparker0i.me/content/images/wordpress/2017/11/about.png)\n\nUntil another blog post, Ciao.","coverImage":"https://blog.sparker0i.me/content/images/wordpress/2017/11/weather2.png","brief":"Android\nAnnouncing Simple Weather v2.0\n\n\n\nAaditya Menon\nDec 12, 2016 • 3 min read\n\nHello there. Wishing all a Merry Christmas and a Happy new year. Today I’m writing this blog post to announce the second release of my Simple Weather app. The app was ...","author":"5cdceddff961be4c61f8a021","sB":false,"isRepublished":true,"originalArticleURL":"https://blog.sparker0i.me/simple-weather-v2-now-available/","readTime":3,"tags":["56744723958ef13879b953d0","56744721958ef13879b94c7e"],"publication":"5cdd04921a7cb8b20267646b","dateDeleted":"2024-04-14T18:18:44.906Z","pollOptions":[],"badges":[],"questionReplies":[],"contributors":[],"uniqueReactions":[],"reactionToCountMapUnique":{"any":1},"id":"661c087df236c1310e7d3137"}]}